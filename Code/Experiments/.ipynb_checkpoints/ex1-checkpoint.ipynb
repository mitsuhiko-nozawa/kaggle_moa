{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv score : 0.015197305813776704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, random\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "#from Functions import prepro\n",
    "from Models.DNN import DNN_model\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "%matplotlib inline\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    res = []\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        y = y_true[:,i]\n",
    "        pred = y_pred[:,i]\n",
    "        res.append(log_loss(y, pred))\n",
    "    return np.mean(res)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seeds = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 207)\n",
      "(23814, 402)\n",
      "(23814, 608)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../Data/Raw/train_features.csv\")\n",
    "#train_df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"../Data/Raw/test_features.csv\")\n",
    "#test_df = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "\n",
    "y = pd.read_csv(\"../Data/Raw/train_targets_scored.csv\")\n",
    "#y = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "tag_size = y.shape[1]-1\n",
    "print(y.shape)\n",
    "\n",
    "y_non = pd.read_csv(\"../Data/Raw/train_targets_nonscored.csv\").drop(\"sig_id\", axis=1)\n",
    "print(y_non.shape)\n",
    "#y = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "\n",
    "GENES = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "CELLS = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
    "CELLS_50 = CELLS[:50]\n",
    "BIOS = GENES + CELLS\n",
    "\n",
    "SCORED_MOAS = [col for col in y.columns if col != \"sig_id\"]\n",
    "y = pd.concat([y, y_non], axis=1)\n",
    "MOAS = [col for col in y.columns if col != \"sig_id\"]\n",
    "\n",
    "y = y.drop(\"sig_id\", axis=1).values\n",
    "print(y.shape)\n",
    "\n",
    "# g772, c100, 206クラス、402クラスの分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"cp_type\"] = train_df[\"cp_type\"].map(lambda x : 1 if x == \"trt_cp\" else 0)\n",
    "test_df[\"cp_type\"] = test_df[\"cp_type\"].map(lambda x : 1 if x == \"trt_cp\" else 0)\n",
    "\n",
    "di = {\n",
    "    24 : 0, \n",
    "    48 : 1,\n",
    "    72 : 2,\n",
    "}\n",
    "train_df[\"cp_time\"] = train_df[\"cp_time\"].map(lambda x : di[x])\n",
    "test_df[\"cp_time\"] = test_df[\"cp_time\"].map(lambda x : di[x])\n",
    "\n",
    "train_df[\"cp_dose\"] = train_df[\"cp_dose\"].map(lambda x : 1 if x == \"D1\" else 0)\n",
    "test_df[\"cp_dose\"] = test_df[\"cp_dose\"].map(lambda x : 1 if x == \"D1\" else 0)\n",
    "\n",
    "cols = [col for col in train_df.columns if \"g-\" in col or \"c-\" in col]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([train_df[cols], test_df[cols]]))\n",
    "train_df[cols] = scaler.transform(train_df[cols])\n",
    "test_df[cols] = scaler.transform(test_df[cols])\n",
    "\n",
    "X = train_df.drop(\"sig_id\", axis=1)\n",
    "test_X = test_df.drop(\"sig_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== fold 1 ========================\n",
      "======================== fold 2 ========================\n",
      "======================== fold 3 ========================\n",
      "======================== fold 4 ========================\n",
      "======================== fold 5 ========================\n",
      "======================== fold 6 ========================\n",
      "======================== fold 7 ========================\n",
      "cv score : 0.01575215368851753\n",
      "======================== fold 1 ========================\n",
      "======================== fold 2 ========================\n",
      "======================== fold 3 ========================\n",
      "======================== fold 4 ========================\n",
      "======================== fold 5 ========================\n",
      "======================== fold 6 ========================\n",
      "======================== fold 7 ========================\n",
      "cv score : 0.0158014522934438\n",
      "======================== fold 1 ========================\n",
      "======================== fold 2 ========================\n",
      "======================== fold 3 ========================\n",
      "======================== fold 4 ========================\n",
      "======================== fold 5 ========================\n",
      "======================== fold 6 ========================\n",
      "======================== fold 7 ========================\n",
      "cv score : 0.016129858719962538\n",
      "======================== fold 1 ========================\n",
      "======================== fold 2 ========================\n",
      "======================== fold 3 ========================\n",
      "======================== fold 4 ========================\n",
      "======================== fold 5 ========================\n",
      "======================== fold 6 ========================\n",
      "======================== fold 7 ========================\n",
      "cv score : 0.015464318989524618\n",
      "======================== fold 1 ========================\n",
      "======================== fold 2 ========================\n",
      "======================== fold 3 ========================\n",
      "======================== fold 4 ========================\n",
      "======================== fold 5 ========================\n",
      "======================== fold 6 ========================\n",
      "======================== fold 7 ========================\n",
      "cv score : 0.01563467459803597\n",
      "cv score : 0.015197305813776704\n"
     ]
    }
   ],
   "source": [
    "train_preds = np.zeros(y.shape)\n",
    "preds = np.zeros((test_X.shape[0], y.shape[1]))\n",
    "\n",
    "for seed in seeds:\n",
    "    seed_everything(seed)\n",
    "    K = 7\n",
    "    kf = MultilabelStratifiedKFold(n_splits=K, random_state=seed, shuffle=True)\n",
    "    train_pred = np.zeros(y.shape)\n",
    "    \n",
    "    for itr, (train_index, valid_index) in enumerate(kf.split(X, y)):\n",
    "        print(\"======================== fold {} ========================\".format(itr+1))\n",
    "        train_X = X.iloc[train_index].values\n",
    "        train_y = y[train_index]\n",
    "        valid_X = X.iloc[valid_index].values\n",
    "        valid_y = y[valid_index]\n",
    "        #print(train_X.shape)\n",
    "        #print(train_y.shape)\n",
    "        model = DNN_model(input_size=train_X.shape[1], output_size=train_y.shape[1])\n",
    "        cb = EarlyStopping(monitor='val_loss', patience=1)\n",
    "        model.fit(\n",
    "            train_X, \n",
    "            train_y,\n",
    "            batch_size=128,\n",
    "            epochs=10,\n",
    "            verbose=0,\n",
    "            callbacks=[cb],\n",
    "            validation_data=(valid_X, valid_y),\n",
    "        )\n",
    "        train_pred[valid_index] += model.predict(valid_X, batch_size=128)\n",
    "        preds += model.predict(test_X.values, batch_size=128) / (K*len(seeds))\n",
    "\n",
    "\n",
    "    print(\"cv score : {}\".format(metric(y[:,:tag_size], train_pred[:,:tag_size])))\n",
    "    train_preds += train_pred/len(seeds)\n",
    "\n",
    "print(\"cv score : {}\".format(metric(y[:,:tag_size], train_preds[:,:tag_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [:,:tag_size]\n",
    "sub_df = pd.read_csv(\"../Data/Raw/sample_submission.csv\")\n",
    "#sub_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n",
    "cols = [col for col in sub_df.columns if col != \"sig_id\"]\n",
    "sub_df[cols] = preds\n",
    "#sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train_preds.copy()\n",
    "print(metric(y[:,:tag_size], t[:,:tag_size]))\n",
    "t_ = train_df[train_df[\"cp_type\"] == 0]\n",
    "t[t_.index] = np.zeros((t_.shape[0], t.shape[1]))\n",
    "t = np.where(t > 1, 1, t)\n",
    "print(metric(y[:,:tag_size], t[:,:tag_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "not_li = []\n",
    "for i in range(y.shape[0]):\n",
    "    for j in range(y.shape[1]):\n",
    "        if y[i][j] == 1:\n",
    "            #print(\"====={}, {}====\".format(i,j))\n",
    "            rank = np.where(train_preds[i].argsort()[::-1] == j)[0][0]+1\n",
    "            #print(\"rank {}\".format(rank))\n",
    "            if rank <= 20:\n",
    "                li.append(j)\n",
    "            else:\n",
    "                not_li.append(j)\n",
    "            #print(train_preds[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = list(set(li))\n",
    "not_li = list(set(not_li))\n",
    "for i in li:\n",
    "    if i not in not_li:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.read_csv(\"../Data/Raw/train_targets_nonscored.csv\").columns\n",
    "pd.read_csv(\"../Data/Raw/train_targets_nonscored.csv\")[cols[256-206]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
