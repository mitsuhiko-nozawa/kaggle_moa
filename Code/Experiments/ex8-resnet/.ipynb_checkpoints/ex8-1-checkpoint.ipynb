{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを少し変えたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, random, os, sys, tqdm, time\n",
    "sys.path.append(\"../\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer, RobustScaler\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1200)\n",
    "pd.set_option(\"display.max_rows\", 1200)\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    res = []\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        y = y_true[:,i]\n",
    "        pred = y_pred[:,i]\n",
    "        print(i)\n",
    "        res.append(log_loss(y, pred))\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    res = []\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        y = y_true[:,i]\n",
    "        pred = y_pred[:,i]\n",
    "        if np.sum(pred) <= 0.0:\n",
    "            pre += 1e-15\n",
    "        res.append(log_loss(y, pred))\n",
    "    return np.mean(res)\n",
    "\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "seed_everything(42)\n",
    "        \n",
    "    \n",
    "def make_scaler(flag, seed):\n",
    "    if flag == \"quantile\":\n",
    "        return QuantileTransformer(n_quantiles=100,random_state=seed, output_distribution=\"normal\")\n",
    "    elif flag == \"gauss\":\n",
    "        return GaussRankScaler()\n",
    "    elif flag == \"standard\":\n",
    "        return StandardScaler()\n",
    "    elif flag == \"minmax\":\n",
    "        return MinMaxScaler()\n",
    "    elif flag == \"robust\":\n",
    "        return RobustScaler()\n",
    "    \n",
    "seeds = [7, 8, 9, 10, 11, 12, 13]\n",
    "SCALE = \"quantile\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g772, c100, 206クラス、402クラスの分類\n",
    "\n",
    "train_df = pd.read_csv(\"../../../Data/Raw/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../../../Data/Raw/test_features.csv\")\n",
    "#pub_test_df = pd.read_csv(\"../input/moapublictest/test_features.csv\")\n",
    "pub_test_df = pd.read_csv(\"../../../Data/Raw/test_features.csv\")\n",
    "drug_df = pd.read_csv(\"../../../Data/Raw/train_drug.csv\")#\n",
    "\n",
    "y = pd.read_csv(\"../../../Data/Raw/train_targets_scored.csv\")\n",
    "y_non = pd.read_csv(\"../../../Data/Raw/train_targets_nonscored.csv\")\n",
    "y_all = pd.concat([y, y_non.drop(\"sig_id\", axis=1)], axis=1)\n",
    "y = y.merge(drug_df, on='sig_id', how='left') #\n",
    "\n",
    "GENES = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "CELLS = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
    "BIOS = GENES + CELLS\n",
    "\n",
    "\n",
    "SCORED_MOAS = [col for col in y.columns if col != \"sig_id\" and col != \"drug_id\"]#\n",
    "NONSCORED_MOAS = [col for col in y_non.columns if col != \"sig_id\"]\n",
    "ALL_MOAS = SCORED_MOAS + NONSCORED_MOAS\n",
    "\n",
    "\n",
    "TR_SIZE = train_df.shape[0]\n",
    "TE_SIZE = test_df.shape[0]\n",
    "\n",
    "train_nonvehicle_index = train_df[train_df[\"cp_type\"] != \"ctl_vehicle\"].index\n",
    "test_nonvehicle_index = test_df[test_df[\"cp_type\"] != \"ctl_vehicle\"].index\n",
    "\n",
    "train_df[\"time_dose\"] = train_df[\"cp_time\"].astype(str) + \" * \" + train_df[\"cp_dose\"]\n",
    "test_df[\"time_dose\"] = test_df[\"cp_time\"].astype(str) + \" * \" + test_df[\"cp_dose\"]\n",
    "pub_test_df[\"time_dose\"] = pub_test_df[\"cp_time\"].astype(str) + \" * \" + pub_test_df[\"cp_dose\"]\n",
    "\n",
    "# remove cp_type = ctl_vehicle\n",
    "mask = train_df[\"cp_type\"] != \"ctl_vehicle\"\n",
    "train_df = train_df[mask].drop(\"cp_type\", axis=1).reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cp_type\"] != \"ctl_vehicle\"].drop(\"cp_type\", axis=1).reset_index(drop=True)\n",
    "pub_test_df = pub_test_df[pub_test_df[\"cp_type\"] != \"ctl_vehicle\"].drop(\"cp_type\", axis=1).reset_index(drop=True)\n",
    "y_nonv = y[mask].reset_index(drop=True)#\n",
    "\n",
    "scored = y_nonv.copy()#\n",
    "y_nonv.drop(\"drug_id\", axis=1, inplace=True)#\n",
    "y.drop(\"drug_id\", axis=1, inplace=True)#\n",
    "\n",
    "TR_NONV_SIZE = train_df.shape[0]\n",
    "TE_NONV_SHAPE = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod\n",
    "#prod_p_cols = [['g-722', 'g-655', 'g-707'], ['g-707', 'g-65', 'g-392'], ['g-169', 'g-484', 'g-338'], ['g-417', 'g-100', 'g-707'], ['g-38', 'g-100', 'g-707'], ['g-310', 'g-744', 'g-707'], ['g-100', 'g-0', 'g-123'], ['g-38', 'g-100', 'g-744'], ['g-328', 'g-707', 'g-158'], ['g-100', 'g-744', 'g-38'], ['g-310', 'g-744', 'g-707'], ['g-491', 'g-100', 'g-38'], ['g-135', 'g-392', 'g-512'], ['g-131', 'g-38', 'g-708'], ['g-180', 'g-624', 'g-613'], ['g-707', 'g-133', 'g-392'], ['g-69', 'g-707', 'g-100'], ['g-392', 'g-731', 'g-707'], ['g-759', 'g-392', 'g-65'], ['g-544', 'g-425', 'g-707'], ['g-69', 'g-608', 'g-417'], ['g-441', 'g-703', 'g-491'], ['g-712', 'g-310', 'g-328'], ['g-624', 'g-615', 'g-189'], ['g-57', 'g-729', 'g-130'], ['g-146', 'g-466', 'g-762'], ['g-308', 'g-495', 'g-712'], ['g-181', 'g-707', 'g-38'], ['g-392', 'g-731', 'g-131'], ['g-349', 'g-750', 'g-91'], ['g-541', 'g-748', 'g-38'], ['g-91', 'g-100', 'g-478'], ['g-635', 'g-514', 'g-302'], ['g-419', 'g-676', 'g-130'], ['g-744', 'g-131', 'g-100'], ['g-707', 'g-158', 'g-100'], ['g-127', 'g-749', 'g-380'], ['g-392', 'g-731', 'g-100'], ['g-144', 'g-123', 'g-86'], ['g-732', 'g-744', 'g-707'], ['g-744', 'g-731', 'g-100'], ['g-731', 'g-158', 'g-38'], ['g-158', 'g-100', 'g-707'], ['g-208', 'g-707', 'g-731'], ['g-38', 'g-392', 'g-707'], ['g-744', 'g-721', 'g-707'], ['g-162', 'g-157', 'g-178'], ['g-326', 'g-707', 'g-449'], ['g-504', 'g-392', 'g-707'], ['g-729', 'g-182', 'g-208'], ['g-744', 'g-608', 'g-100'], ['g-452', 'g-391', 'g-413'], ['g-714', 'g-452', 'g-658'], ['g-100', 'g-392', 'g-707'], ['g-640', 'g-266', 'g-310'], ['g-91', 'g-145', 'g-208'], ['g-744', 'g-158', 'g-392'], ['g-16', 'g-714', 'g-707'], ['g-310', 'g-13', 'g-100'], ['g-478', 'g-468', 'g-310'], ['g-689', 'g-100', 'g-707'], ['g-208', 'g-714', 'g-707'], ['g-38', 'g-158', 'g-707'], ['g-484', 'g-392', 'g-544'], ['g-392', 'g-484', 'g-74'], ['g-95', 'g-170', 'g-707'], ['g-91', 'g-130', 'g-707'], ['g-131', 'g-208', 'g-392'], ['g-417', 'g-248', 'g-744'], ['g-707', 'g-607', 'g-358'], ['g-392', 'g-707', 'g-158'], ['g-31', 'g-328', 'g-460'], ['g-576', 'g-666', 'g-608'], ['g-368', 'g-402', 'g-707'], ['g-512', 'g-594', 'g-38'], ['g-38', 'g-707', 'g-158'], ['g-392', 'g-100', 'g-707'], ['g-91', 'g-100', 'g-707'], ['g-158', 'g-38', 'g-744'], ['g-744', 'g-707', 'g-100'], ['g-654', 'g-143', 'g-377'], ['g-131', 'g-100', 'g-170'], ['g-699', 'g-235', 'g-707'], ['g-744', 'g-392', 'g-38'], ['g-682', 'g-592', 'g-707'], ['g-391', 'g-666', 'g-514'], ['g-143', 'g-231', 'g-265'], ['g-478', 'g-442', 'g-270'], ['g-608', 'g-162', 'g-11'], ['g-134', 'g-54', 'g-762'], ['g-145', 'g-201', 'g-208'], ['g-413', 'g-310', 'g-707'], ['g-744', 'g-38', 'g-100'], ['g-413', 'g-707', 'g-69'], ['g-123', 'g-731', 'g-100'], ['g-712', 'g-208', 'g-38'], ['g-731', 'g-707', 'g-100'], ['g-38', 'g-744', 'g-100'], ['g-576', 'g-452', 'g-392'], ['g-441', 'g-157', 'g-392'], ['g-596', 'g-744', 'g-707'], ['g-38', 'g-392', 'g-744'], ['g-392', 'g-69', 'g-654'], ['g-123', 'g-744', 'g-38'], ['g-417', 'g-46', 'g-181'], ['g-731', 'g-100', 'g-707'], ['g-484', 'g-707', 'g-158'], ['g-744', 'g-707', 'g-100'], ['g-100', 'g-158', 'g-707'], ['g-200', 'g-707', 'g-592'], ['g-215', 'g-392', 'g-330'], ['g-383', 'g-576', 'g-514'], ['g-689', 'g-69', 'g-100'], ['g-645', 'g-123', 'g-514'], ['g-697', 'g-200', 'g-608'], ['g-91', 'g-100', 'g-392'], ['g-38', 'g-707', 'g-158'], ['g-231', 'g-100', 'g-707'], ['g-573', 'g-127', 'g-70'], ['g-178', 'g-592', 'g-391'], ['g-368', 'g-100', 'g-707'], ['g-200', 'g-729', 'g-648'], ['g-723', 'g-731', 'g-100'], ['g-130', 'g-745', 'g-158'], ['g-208', 'g-131', 'g-100'], ['g-392', 'g-38', 'g-91'], ['g-731', 'g-744', 'g-158'], ['g-437', 'g-158', 'g-91'], ['g-707', 'g-335', 'g-116'], ['g-100', 'g-731', 'g-707'], ['g-44', 'g-714', 'g-707'], ['g-392', 'g-413', 'g-707'], ['g-65', 'g-392', 'g-158'], ['g-592', 'g-157', 'g-197'], ['g-740', 'g-762', 'g-170'], ['g-137', 'g-188', 'g-181'], ['g-270', 'g-170', 'g-100'], ['g-260', 'g-190', 'g-130'], ['g-718', 'g-722', 'g-707'], ['g-146', 'g-270', 'g-744'], ['g-505', 'g-391', 'g-38'], ['g-100', 'g-731', 'g-707'], ['g-84', 'g-65', 'g-707'], ['g-65', 'g-484', 'g-707'], ['g-328', 'g-28', 'g-392'], ['g-624', 'g-608', 'g-707'], ['g-635', 'g-158', 'g-707'], ['g-419', 'g-143', 'g-640'], ['g-744', 'g-707', 'g-100'], ['g-158', 'g-707', 'g-12'], ['g-744', 'g-707', 'g-38'], ['g-666', 'g-466', 'g-191'], ['g-38', 'g-328', 'g-417'], ['g-328', 'g-38', 'g-100'], ['g-417', 'g-392', 'g-707'], ['g-130', 'g-608', 'g-707'], ['g-380', 'g-38', 'g-707'], ['g-707', 'g-391', 'g-624'], ['g-613', 'g-330', 'g-106'], ['g-131', 'g-100', 'g-744'], ['g-181', 'g-512', 'g-270'], ['g-181', 'g-100', 'g-392'], ['g-744', 'g-417', 'g-100'], ['g-158', 'g-208', 'g-159'], ['g-88', 'g-643', 'g-436'], ['g-484', 'g-158', 'g-707'], ['g-100', 'g-744', 'g-392'], ['g-188', 'g-689', 'g-290'], ['g-158', 'g-417', 'g-11'], ['g-328', 'g-220', 'g-541'], ['g-243', 'g-259', 'g-744'], ['g-392', 'g-313', 'g-422'], ['g-707', 'g-131', 'g-123'], ['g-208', 'g-100', 'g-707'], ['g-158', 'g-417', 'g-707'], ['g-392', 'g-313', 'g-389'], ['g-16', 'g-707', 'g-100'], ['g-231', 'g-707', 'g-392'], ['g-725', 'g-712', 'g-640'], ['g-38', 'g-158', 'g-707'], ['g-201', 'g-745', 'g-599'], ['g-419', 'g-158', 'g-714'], ['g-173', 'g-596', 'g-737'], ['g-326', 'g-248', 'g-600'], ['g-131', 'g-100', 'g-158'], ['g-654', 'g-160', 'g-707'], ['g-147', 'g-731', 'g-721'], ['g-378', 'g-358', 'g-643'], ['g-100', 'g-38', 'g-744'], ['g-166', 'g-635', 'g-430'], ['g-417', 'g-38', 'g-328'], ['g-208', 'g-100', 'g-707'], ['g-38', 'g-744', 'g-100'], ['g-229', 'g-711', 'g-91'], ['g-248', 'g-38', 'g-338'], ['g-38', 'g-417', 'g-707'], ['g-731', 'g-100', 'g-707'], ['g-106', 'g-744', 'g-91'], ['g-707', 'g-624', 'g-455'], ['g-310', 'g-707', 'g-290'], ['g-131', 'g-170', 'g-158'], ['g-146', 'g-270', 'g-158'], ['g-529', 'g-707', 'g-74']]\n",
    "#prod_n_cols = [['g-431', 'g-597', 'g-489'], ['g-239', 'g-113', 'g-50'], ['g-370', 'g-431', 'g-656'], ['g-568', 'g-508', 'g-760'], ['g-370', 'g-508', 'g-37'], ['g-228', 'g-72', 'g-67'], ['g-50', 'g-37', 'g-250'], ['g-508', 'g-50', 'g-411'], ['g-128', 'g-370', 'g-429'], ['g-50', 'g-672', 'g-37'], ['g-508', 'g-37', 'g-489'], ['g-50', 'g-705', 'g-298'], ['g-771'], ['g-67', 'g-644', 'g-113'], ['g-50', 'g-37', 'g-36'], ['g-151', 'g-495', 'g-234'], ['g-276', 'g-178', 'g-428'], ['g-644', 'g-370', 'g-411'], ['g-370', 'g-568', 'g-50'], ['g-50', 'g-37', 'g-332'], ['g-375', 'g-644', 'g-271'], ['g-571', 'g-503', 'g-370'], ['g-56', 'g-161', 'g-298'], ['g-508', 'g-37', 'g-370'], ['g-537', 'g-487', 'g-719'], ['g-211', 'g-75', 'g-501'], ['g-503', 'g-477', 'g-489'], ['g-508', 'g-113', 'g-231'], ['g-113', 'g-375', 'g-75'], ['g-50', 'g-332', 'g-37'], ['g-113', 'g-75', 'g-178'], ['g-644', 'g-178', 'g-760'], ['g-50', 'g-72', 'g-37'], ['g-653', 'g-202', 'g-378'], ['g-300', 'g-247', 'g-584'], ['g-37', 'g-50', 'g-98'], ['g-50', 'g-58', 'g-332'], ['g-411', 'g-674', 'g-299'], ['g-672', 'g-50', 'g-508'], ['g-128', 'g-370', 'g-644'], ['g-37', 'g-228', 'g-202'], ['g-508', 'g-760', 'g-406'], ['g-75', 'g-113', 'g-228'], ['g-508', 'g-50', 'g-370'], ['g-72', 'g-370', 'g-50'], ['g-370', 'g-75', 'g-37'], ['g-399', 'g-644', 'g-739'], ['g-674', 'g-555', 'g-713'], ['g-610', 'g-537', 'g-323'], ['g-276', 'g-113', 'g-555'], ['g-421', 'g-612', 'g-464'], ['g-370', 'g-50', 'g-503'], ['g-508', 'g-151', 'g-267'], ['g-258', 'g-644', 'g-370'], ['g-370', 'g-276', 'g-75'], ['g-50', 'g-560', 'g-630'], ['g-332', 'g-178', 'g-508'], ['g-50', 'g-37', 'g-75'], ['g-370', 'g-558', 'g-371'], ['g-37', 'g-62', 'g-271'], ['g-75', 'g-50', 'g-375'], ['g-37', 'g-421', 'g-72'], ['g-370', 'g-684', 'g-508'], ['g-50', 'g-508', 'g-113'], ['g-50', 'g-298', 'g-37'], ['g-239', 'g-370', 'g-739'], ['g-705', 'g-50', 'g-298'], ['g-37', 'g-5', 'g-332'], ['g-508', 'g-37', 'g-72'], ['g-513', 'g-508', 'g-128'], ['g-555', 'g-281', 'g-172'], ['g-50', 'g-37', 'g-489'], ['g-370', 'g-228', 'g-644'], ['g-370', 'g-719', 'g-508'], ['g-298', 'g-477', 'g-644'], ['g-257', 'g-50', 'g-72'], ['g-75', 'g-370', 'g-672'], ['g-508', 'g-113', 'g-370'], ['g-332', 'g-58', 'g-37'], ['g-508', 'g-37', 'g-672'], ['g-50', 'g-37', 'g-672'], ['g-681', 'g-272', 'g-131'], ['g-771'], ['g-50', 'g-37', 'g-672'], ['g-370', 'g-571', 'g-438'], ['g-508', 'g-332', 'g-50'], ['g-370', 'g-400', 'g-300'], ['g-300', 'g-284', 'g-495'], ['g-234', 'g-761', 'g-555'], ['g-257', 'g-672', 'g-477'], ['g-370', 'g-227', 'g-653'], ['g-238', 'g-399', 'g-759'], ['g-508', 'g-228', 'g-656'], ['g-370', 'g-618', 'g-644'], ['g-508', 'g-228', 'g-113'], ['g-67', 'g-571', 'g-653'], ['g-37', 'g-228', 'g-489'], ['g-67', 'g-178', 'g-113'], ['g-202', 'g-370', 'g-421'], ['g-50', 'g-113', 'g-672'], ['g-370', 'g-399', 'g-98'], ['g-401', 'g-58', 'g-202'], ['g-508', 'g-370', 'g-58'], ['g-75', 'g-37', 'g-50'], ['g-300', 'g-370', 'g-568'], ['g-508', 'g-37', 'g-50'], ['g-234', 'g-271', 'g-632'], ['g-67', 'g-760', 'g-50'], ['g-113', 'g-75', 'g-489'], ['g-37', 'g-50', 'g-508'], ['g-508', 'g-67', 'g-37'], ['g-555', 'g-492', 'g-653'], ['g-113', 'g-250', 'g-325'], ['g-705', 'g-178', 'g-284'], ['g-332', 'g-50', 'g-571'], ['g-508', 'g-67', 'g-276'], ['g-375', 'g-644', 'g-113'], ['g-298', 'g-257', 'g-332'], ['g-75', 'g-50', 'g-653'], ['g-204', 'g-558', 'g-202'], ['g-587', 'g-644', 'g-17'], ['g-204', 'g-567', 'g-526'], ['g-571', 'g-568', 'g-760'], ['g-653', 'g-555', 'g-678'], ['g-202', 'g-50', 'g-760'], ['g-50', 'g-298', 'g-332'], ['g-50', 'g-37', 'g-59'], ['g-67', 'g-113', 'g-508'], ['g-75', 'g-298', 'g-508'], ['g-508', 'g-50', 'g-298'], ['g-487', 'g-285', 'g-232'], ['g-370', 'g-644', 'g-50'], ['g-370', 'g-575', 'g-477'], ['g-50', 'g-257', 'g-37'], ['g-508', 'g-644', 'g-113'], ['g-513', 'g-591', 'g-300'], ['g-375', 'g-681', 'g-492'], ['g-571', 'g-234', 'g-412'], ['g-37', 'g-58', 'g-228'], ['g-17', 'g-115', 'g-300'], ['g-323', 'g-506', 'g-168'], ['g-771'], ['g-743', 'g-497', 'g-595'], ['g-375', 'g-370', 'g-508'], ['g-50', 'g-37', 'g-568'], ['g-50', 'g-438', 'g-439'], ['g-370', 'g-67', 'g-58'], ['g-477', 'g-568', 'g-761'], ['g-370', 'g-267', 'g-705'], ['g-234', 'g-58', 'g-520'], ['g-234', 'g-508', 'g-595'], ['g-37', 'g-50', 'g-202'], ['g-37', 'g-644', 'g-489'], ['g-477', 'g-72', 'g-37'], ['g-506', 'g-719', 'g-300'], ['g-370', 'g-508', 'g-37'], ['g-508', 'g-50', 'g-37'], ['g-370', 'g-50', 'g-113'], ['g-370', 'g-300', 'g-487'], ['g-568', 'g-276', 'g-719'], ['g-421', 'g-434', 'g-644'], ['g-595', 'g-176', 'g-487'], ['g-50', 'g-672', 'g-489'], ['g-508', 'g-50', 'g-250'], ['g-250', 'g-489', 'g-439'], ['g-72', 'g-644', 'g-406'], ['g-185', 'g-37', 'g-672'], ['g-300', 'g-227', 'g-591'], ['g-332', 'g-37', 'g-370'], ['g-50', 'g-37', 'g-489'], ['g-367', 'g-438', 'g-144'], ['g-37', 'g-50', 'g-257'], ['g-276', 'g-653', 'g-291'], ['g-50', 'g-761', 'g-672'], ['g-477', 'g-571', 'g-585'], ['g-370', 'g-113', 'g-508'], ['g-508', 'g-370', 'g-332'], ['g-508', 'g-75', 'g-113'], ['g-58', 'g-186', 'g-477'], ['g-202', 'g-479', 'g-660'], ['g-477', 'g-332', 'g-36'], ['g-239', 'g-42', 'g-234'], ['g-508', 'g-370', 'g-37'], ['g-37', 'g-300', 'g-370'], ['g-370', 'g-300', 'g-96'], ['g-5', 'g-429', 'g-299'], ['g-477', 'g-497', 'g-487'], ['g-152', 'g-50', 'g-75'], ['g-375', 'g-477', 'g-585'], ['g-228', 'g-411', 'g-67'], ['g-190', 'g-475', 'g-628'], ['g-202', 'g-37', 'g-477'], ['g-595', 'g-276', 'g-75'], ['g-72', 'g-75', 'g-508'], ['g-370', 'g-508', 'g-50'], ['g-37', 'g-75', 'g-121'], ['g-503', 'g-761', 'g-50'], ['g-595', 'g-486', 'g-72'], ['g-508', 'g-67', 'g-370'], ['g-50', 'g-508', 'g-75'], ['g-508', 'g-553', 'g-72'], ['g-595', 'g-665', 'g-131'], ['g-705', 'g-375', 'g-704'], ['g-75', 'g-228', 'g-508'], ['g-508', 'g-37', 'g-644'], ['g-477', 'g-50', 'g-72']]\n",
    "# 上位500こ\n",
    "prod_cols = [['g-145', 'g-201', 'g-208'], ['g-370', 'g-508', 'g-37'], ['g-38', 'g-392', 'g-707'], ['g-328', 'g-28', 'g-392'], ['g-441', 'g-157', 'g-392'], ['g-181', 'g-100', 'g-392'], ['g-67', 'g-760', 'g-50'], ['g-731', 'g-100', 'g-707'], ['g-478', 'g-468', 'g-310'], ['g-91', 'g-145', 'g-208'], ['g-106', 'g-744', 'g-91'], ['g-131', 'g-208', 'g-392'], ['g-144', 'g-123', 'g-86'], ['g-228', 'g-72', 'g-67'], ['g-31', 'g-328', 'g-460'], ['g-392', 'g-731', 'g-100'], ['g-732', 'g-744', 'g-707'], ['g-705', 'g-375', 'g-704'], ['g-508', 'g-50', 'g-411'], ['g-234', 'g-58', 'g-520'], ['g-503', 'g-761', 'g-50'], ['g-113', 'g-75', 'g-178'], ['g-50', 'g-508', 'g-113'], ['g-113', 'g-375', 'g-75'], ['g-576', 'g-452', 'g-392'], ['g-50', 'g-37', 'g-36'], ['g-707', 'g-133', 'g-392'], ['g-484', 'g-392', 'g-544'], ['g-508', 'g-67', 'g-370'], ['g-123', 'g-731', 'g-100'], ['g-298', 'g-477', 'g-644'], ['g-72', 'g-370', 'g-50'], ['g-67', 'g-178', 'g-113'], ['g-744', 'g-608', 'g-100'], ['g-91', 'g-100', 'g-707'], ['g-37', 'g-228', 'g-202'], ['g-37', 'g-300', 'g-370'], ['g-234', 'g-508', 'g-595'], ['g-596', 'g-744', 'g-707'], ['g-300', 'g-227', 'g-591'], ['g-135', 'g-392', 'g-512'], ['g-731', 'g-744', 'g-158'], ['g-69', 'g-707', 'g-100'], ['g-276', 'g-653', 'g-291'], ['g-624', 'g-615', 'g-189'], ['g-181', 'g-707', 'g-38'], ['g-72', 'g-75', 'g-508'], ['g-231', 'g-707', 'g-392'], ['g-508', 'g-37', 'g-72'], ['g-725', 'g-712', 'g-640'], ['g-67', 'g-644', 'g-113'], ['g-508', 'g-228', 'g-656'], ['g-185', 'g-37', 'g-672'], ['g-370', 'g-50', 'g-503'], ['g-201', 'g-745', 'g-599'], ['g-332', 'g-50', 'g-571'], ['g-50', 'g-37', 'g-59'], ['g-508', 'g-113', 'g-231'], ['g-707', 'g-158', 'g-100'], ['g-257', 'g-50', 'g-72']]\n",
    "\"\"\"\n",
    "for p_cols in prod_p_cols:\n",
    "    name = \"prod-\" + \" * \".join(p_cols)\n",
    "    train_df[name] = train_df[p_cols].mean(axis=1)\n",
    "    test_df[name] = test_df[p_cols].mean(axis=1)\n",
    "    pub_test_df[name] = pub_test_df[p_cols].mean(axis=1)\n",
    "    \n",
    "for n_cols in prod_n_cols:\n",
    "    name = \"prod-\" + \" * \".join(n_cols)\n",
    "    train_df[name] = train_df[n_cols].mean(axis=1)\n",
    "    test_df[name] = test_df[n_cols].mean(axis=1)\n",
    "    pub_test_df[name] = pub_test_df[n_cols].mean(axis=1)\n",
    "\"\"\"\n",
    "    \n",
    "for cols in prod_cols:\n",
    "    name = \"prod-\" + \" * \".join(cols)\n",
    "    train_df[name] = train_df[cols].mean(axis=1)\n",
    "    test_df[name] = test_df[cols].mean(axis=1)\n",
    "    pub_test_df[name] = pub_test_df[cols].mean(axis=1)\n",
    "\n",
    "PRODS = [col for col in train_df.columns if col.startswith(\"prod-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop cols num : 67\n",
      "agg\n"
     ]
    }
   ],
   "source": [
    "#out fold preprocessing\n",
    "\n",
    "#variance threshold\n",
    "\n",
    "VAR_THRESHOLD = 0.8\n",
    "drop_cols = []\n",
    "temp = pd.concat([train_df, pub_test_df])\n",
    "for col in BIOS+PRODS:\n",
    "    if temp[col].var() <= VAR_THRESHOLD:\n",
    "        drop_cols.append(col)\n",
    "\n",
    "print(\"drop cols num : {}\".format(len(drop_cols)))\n",
    "train_df.drop(columns=drop_cols, inplace=True)\n",
    "test_df.drop(columns=drop_cols, inplace=True)\n",
    "pub_test_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "GENES_ = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "CELLS_ = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
    "BIOS_ = GENES_ + CELLS_\n",
    "        \n",
    "del temp\n",
    "\n",
    "# onehot encode of categorical feature and drop\n",
    "drop_cols = [\"cp_time\", \"cp_dose\", \"time_dose\"]\n",
    "train_df = pd.concat([pd.get_dummies(train_df[\"time_dose\"], prefix=\"onehot\", drop_first=True), train_df.drop(drop_cols, axis=1) ], axis=1)\n",
    "test_df = pd.concat([pd.get_dummies(test_df[\"time_dose\"], prefix=\"onehot\", drop_first=True), test_df.drop(drop_cols, axis=1) ], axis=1)\n",
    "pub_test_df = pd.concat([pd.get_dummies(pub_test_df[\"time_dose\"], prefix=\"onehot\", drop_first=True), pub_test_df.drop(drop_cols, axis=1) ], axis=1)\n",
    "\n",
    "# aggregation feature\n",
    "print(\"agg\")\n",
    "for df in [train_df, pub_test_df, test_df]:\n",
    "    df[\"sum-g\"] = df[GENES_].sum(axis=1)\n",
    "    df[\"mean-g\"] = df[GENES_].mean(axis=1)\n",
    "    df[\"std-g\"] = df[GENES_].std(axis=1)\n",
    "    df[\"kurt-g\"] = df[GENES_].kurt(axis=1)\n",
    "    df[\"skew-g\"] = df[GENES_].skew(axis=1)\n",
    "    df[\"sum-c\"] = df[CELLS_].sum(axis=1)\n",
    "    df[\"mean-c\"] = df[CELLS_].mean(axis=1)\n",
    "    df[\"std-c\"] = df[CELLS_].std(axis=1)\n",
    "    df[\"kurt-c\"] = df[CELLS_].kurt(axis=1)\n",
    "    df[\"skew-c\"] = df[CELLS_].skew(axis=1)\n",
    "    df[\"sum-gc\"] = df[BIOS_].sum(axis=1)\n",
    "    df[\"mean-gc\"] = df[BIOS_].mean(axis=1)\n",
    "    df[\"std-gc\"] = df[BIOS_].std(axis=1)\n",
    "    df[\"kurt-gc\"] = df[BIOS_].kurt(axis=1)\n",
    "    df[\"skew-gc\"] = df[BIOS_].skew(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(\"sig_id\", axis=1)\n",
    "y_nonv = y_nonv.drop(\"sig_id\", axis=1).values\n",
    "y = y.drop(\"sig_id\", axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dateset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoAResNetDataset:\n",
    "    def __init__(self, features1, features2, targets):\n",
    "        self.features1 = features1\n",
    "        self.features2 = features2\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features1.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x1' : torch.tensor(self.features1[idx, :], dtype=torch.float),\n",
    "            'x2' : torch.tensor(self.features2[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestResNetDataset:\n",
    "    def __init__(self, features1, features2):\n",
    "        self.features1 = features1\n",
    "        self.features2 = features2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features1.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x1' : torch.tensor(self.features1[idx, :], dtype=torch.float),\n",
    "            'x2' : torch.tensor(self.features2[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs1, inputs2, targets = data['x1'].to(device), data['x2'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs1, inputs2)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if cycle\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs1, inputs2, targets = data['x1'].to(device), data['x2'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs1, inputs2)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for data in dataloader:\n",
    "        inputs1, inputs2 = data['x1'].to(device), data['x2'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs1, inputs2)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features1, num_features2, num_targets):\n",
    "        super(Model, self).__init__()\n",
    "        self.h1_1 = 512\n",
    "        self.h1_2 = 256\n",
    "        \n",
    "        self.h2_1 = num_features2+256\n",
    "        self.h2_2 = 512\n",
    "        self.h2_3 = 256\n",
    "        \n",
    "        self.h3_1 = 256\n",
    "        \n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features1),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features1, self.h1_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h1_1),\n",
    "            nn.Linear(self.h1_1, self.h1_2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.h2_1),\n",
    "            nn.Dropout(0.30),\n",
    "            nn.Linear(self.h2_1, self.h2_2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_2),\n",
    "            nn.Linear(self.h2_2, self.h2_2),\n",
    "            nn.ELU(),            \n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_2),\n",
    "            nn.Linear(self.h2_2, self.h2_3),\n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_3),\n",
    "            nn.Linear(self.h2_3, self.h2_3),\n",
    "            nn.ELU(),            \n",
    "        )\n",
    "        self.head3 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Linear(self.h3_1, self.h3_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Linear(self.h3_1, num_targets),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(num_targets),\n",
    "            nn.Linear(num_targets, num_targets),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        input3 = self.head1(input1)\n",
    "        concat = torch.cat((input3, input2), dim=1)\n",
    "        input4 = self.head2(concat)\n",
    "        avg = torch.div(torch.add(input3, input4), 2)\n",
    "        \n",
    "        out = self.head3(avg)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, trainloader, validloader, epoch_, optimizer, scheduler, loss_fn, loss_tr, early_stopping_steps, verbose, device, fold, seed):\n",
    "    \n",
    "    early_step = 0\n",
    "    best_loss = np.inf\n",
    "    best_epoch = 0\n",
    "    \n",
    "    start = time.time()\n",
    "    t = time.time() - start\n",
    "    for epoch in range(epoch_):\n",
    "        train_loss = train_fn(model, optimizer, scheduler, loss_tr, trainloader, device)\n",
    "        valid_loss = valid_fn(model, loss_fn, validloader, device)\n",
    "        # if ReduceLROnPlateau\n",
    "        #scheduler.step(valid_loss)\n",
    "        if epoch % verbose==0:\n",
    "            t = time.time() - start\n",
    "            print(f\"EPOCH: {epoch}, train_loss: {train_loss}, valid_loss: {valid_loss}, time: {t}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'resnet_weights/{}_{}.pt'.format(seed, fold))\n",
    "            #torch.save(model, 'dnn_weights/{}_{}.pt'.format(seed, fold))\n",
    "            early_step = 0\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        elif early_stopping_steps != 0:\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                t = time.time() - start\n",
    "                print(f\"early stopping in iteration {epoch},  : best itaration is {best_epoch}, valid loss is {best_loss}, time: {t}\")\n",
    "                return model\n",
    "    t = time.time() - start \n",
    "    print(f\"training until max epoch {epoch_},  : best itaration is {best_epoch}, valid loss is {best_loss}, time: {t}\")\n",
    "    return model\n",
    "            \n",
    "    \n",
    "def predict(model, testloader, device):\n",
    "    model.to(device)\n",
    "    predictions = inference_fn(model, testloader, device)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training by Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17584\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5157809240240467, valid_loss: 0.022487346774765424, time: 7.236069917678833\n",
      "EPOCH: 5, train_loss: 0.021118846891896567, valid_loss: 0.018477434984275273, time: 25.22542428970337\n",
      "EPOCH: 10, train_loss: 0.020902400442065983, valid_loss: 0.018702561408281325, time: 44.5125527381897\n",
      "EPOCH: 15, train_loss: 0.02025813009780254, valid_loss: 0.017998580262064932, time: 63.70300054550171\n",
      "EPOCH: 20, train_loss: 0.019060827451792075, valid_loss: 0.017513463300253662, time: 84.36313128471375\n",
      "training until max epoch 25,  : best itaration is 21, valid loss is 0.01742900287998574, time: 99.6664867401123\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17565\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5172679092952587, valid_loss: 0.02196642176381179, time: 4.008731365203857\n",
      "EPOCH: 5, train_loss: 0.021267668038171574, valid_loss: 0.017999640772385257, time: 23.09534192085266\n",
      "EPOCH: 10, train_loss: 0.020945098998881605, valid_loss: 0.01780454558985574, time: 44.16589426994324\n",
      "EPOCH: 15, train_loss: 0.020397778437302932, valid_loss: 0.01745452670646565, time: 63.62241888046265\n",
      "EPOCH: 20, train_loss: 0.01924881910103081, valid_loss: 0.01690437104552984, time: 83.13883352279663\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.01680375523865223, time: 99.78519415855408\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17534\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.519586338154862, valid_loss: 0.022555439546704293, time: 4.251909017562866\n",
      "EPOCH: 5, train_loss: 0.021194098215988454, valid_loss: 0.018888069476400104, time: 21.635146379470825\n",
      "EPOCH: 10, train_loss: 0.021080004516988993, valid_loss: 0.01844980059457677, time: 42.37778449058533\n",
      "EPOCH: 15, train_loss: 0.020316437626367107, valid_loss: 0.01771283115127257, time: 61.47809457778931\n",
      "EPOCH: 20, train_loss: 0.019152484820498264, valid_loss: 0.01729245140616383, time: 82.05679559707642\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017165994590946605, time: 96.37016701698303\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17504\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.517729657866499, valid_loss: 0.02292278776211398, time: 3.406738758087158\n",
      "EPOCH: 5, train_loss: 0.02121814458137926, valid_loss: 0.018680107806410107, time: 20.75916624069214\n",
      "EPOCH: 10, train_loss: 0.02081299155457493, valid_loss: 0.018590162694454192, time: 40.66034436225891\n",
      "EPOCH: 15, train_loss: 0.020254289334201637, valid_loss: 0.01811220512858459, time: 64.43479681015015\n",
      "EPOCH: 20, train_loss: 0.019093285794095957, valid_loss: 0.01767367600862469, time: 81.60879278182983\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017614377556102616, time: 100.25521087646484\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17605\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5145795590441374, valid_loss: 0.022727180162773412, time: 3.460822820663452\n",
      "EPOCH: 5, train_loss: 0.021222461735571387, valid_loss: 0.018706345437642408, time: 24.929502487182617\n",
      "EPOCH: 10, train_loss: 0.020936937689998724, valid_loss: 0.018584422821946004, time: 44.344947814941406\n",
      "EPOCH: 15, train_loss: 0.020370667378832825, valid_loss: 0.018233923707157373, time: 65.03660249710083\n",
      "EPOCH: 20, train_loss: 0.019149229419927527, valid_loss: 0.017456435543649337, time: 85.31851077079773\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017408602651866042, time: 100.18639922142029\n",
      "seed 7 , cv score : 0.017350216449939945\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17551\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5176200827406924, valid_loss: 0.02256951028747218, time: 4.430978059768677\n",
      "EPOCH: 5, train_loss: 0.02119873920931433, valid_loss: 0.018749318484749113, time: 21.787137508392334\n",
      "EPOCH: 10, train_loss: 0.020979994513692646, valid_loss: 0.0181012969996248, time: 43.896594762802124\n",
      "EPOCH: 15, train_loss: 0.020286792372591303, valid_loss: 0.01767038498073816, time: 63.52486848831177\n",
      "EPOCH: 20, train_loss: 0.01909371122826625, valid_loss: 0.0174235035266195, time: 81.6102569103241\n",
      "training until max epoch 25,  : best itaration is 21, valid loss is 0.017164242480482372, time: 98.0711498260498\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17525\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5174147536265937, valid_loss: 0.023010906417454992, time: 4.054243326187134\n",
      "EPOCH: 5, train_loss: 0.02114016265498803, valid_loss: 0.019236989745071955, time: 20.77295470237732\n",
      "EPOCH: 10, train_loss: 0.020878564182888058, valid_loss: 0.01828612671898944, time: 42.73489570617676\n",
      "EPOCH: 15, train_loss: 0.02027864194036845, valid_loss: 0.017694196557360035, time: 66.64913415908813\n",
      "EPOCH: 20, train_loss: 0.019074329202446866, valid_loss: 0.017352944373020103, time: 88.26170921325684\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.01728459298610687, time: 103.22992014884949\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17607\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5150217701728544, valid_loss: 0.02617170097415938, time: 3.3828587532043457\n",
      "EPOCH: 5, train_loss: 0.021133363274109626, valid_loss: 0.018503065549713725, time: 23.11077070236206\n",
      "EPOCH: 10, train_loss: 0.020860672173817662, valid_loss: 0.01845945048091166, time: 43.82084274291992\n",
      "EPOCH: 15, train_loss: 0.020195626905255944, valid_loss: 0.018080402302610522, time: 63.02547764778137\n",
      "EPOCH: 20, train_loss: 0.01897590263427174, valid_loss: 0.017780213452437344, time: 86.20296669006348\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017639864592210334, time: 102.1798369884491\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17550\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5154060522760571, valid_loss: 0.022704221946852548, time: 4.946652412414551\n",
      "EPOCH: 5, train_loss: 0.02124423422191265, valid_loss: 0.018433993815311363, time: 25.90100598335266\n",
      "EPOCH: 10, train_loss: 0.020960963215597355, valid_loss: 0.018260999103741987, time: 47.35188126564026\n",
      "EPOCH: 15, train_loss: 0.02036331482503536, valid_loss: 0.017677452175744943, time: 64.47430276870728\n",
      "EPOCH: 20, train_loss: 0.01918233652347631, valid_loss: 0.017292279031659877, time: 83.19214510917664\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017189822718501092, time: 101.51118087768555\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17559\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5145959986142651, valid_loss: 0.022256245304431235, time: 3.7119743824005127\n",
      "EPOCH: 5, train_loss: 0.021245714453776387, valid_loss: 0.019212154990860392, time: 23.64850115776062\n",
      "EPOCH: 10, train_loss: 0.020999087088734564, valid_loss: 0.018044675567320416, time: 45.268359422683716\n",
      "EPOCH: 15, train_loss: 0.02043374048641128, valid_loss: 0.017642625368067197, time: 64.68631529808044\n",
      "EPOCH: 20, train_loss: 0.0192607035112642, valid_loss: 0.017261940906090397, time: 85.7083625793457\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017174556984433105, time: 102.97738575935364\n",
      "seed 8 , cv score : 0.017328291638999203\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17498\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5172064576900619, valid_loss: 0.023538247389452798, time: 4.254863023757935\n",
      "EPOCH: 5, train_loss: 0.02127348376876291, valid_loss: 0.018979076402527946, time: 24.73883891105652\n",
      "EPOCH: 10, train_loss: 0.021013631937367952, valid_loss: 0.018200510154877392, time: 43.905405044555664\n",
      "EPOCH: 15, train_loss: 0.020373202052296084, valid_loss: 0.017728812114468643, time: 65.42589044570923\n",
      "EPOCH: 20, train_loss: 0.01920206064139219, valid_loss: 0.017127704061567783, time: 85.55379319190979\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017020389065146448, time: 100.25847578048706\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17606\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5153176825711109, valid_loss: 0.022326882435556722, time: 3.1904103755950928\n",
      "EPOCH: 5, train_loss: 0.02133728726936953, valid_loss: 0.018814927843563697, time: 21.02179217338562\n",
      "EPOCH: 10, train_loss: 0.020986572927693382, valid_loss: 0.01765012237079003, time: 42.62951159477234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15, train_loss: 0.020243198033014352, valid_loss: 0.017387900912367246, time: 62.90524864196777\n",
      "EPOCH: 20, train_loss: 0.01907799240663974, valid_loss: 0.01703830123605097, time: 85.26968622207642\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.016952559844974208, time: 98.48375344276428\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17595\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5157994709256357, valid_loss: 0.023333605378866196, time: 4.474905014038086\n",
      "EPOCH: 5, train_loss: 0.02127089786486034, valid_loss: 0.01883689942104476, time: 24.51864218711853\n",
      "EPOCH: 10, train_loss: 0.021031364023576686, valid_loss: 0.018396549246140887, time: 42.397680044174194\n",
      "EPOCH: 15, train_loss: 0.020298074074361447, valid_loss: 0.017623494352613178, time: 62.70637917518616\n",
      "EPOCH: 20, train_loss: 0.01917100733785081, valid_loss: 0.016985323945326463, time: 81.05459761619568\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.016816205398312637, time: 98.01847290992737\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17512\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5181428800501368, valid_loss: 0.022373227402567863, time: 3.267810106277466\n",
      "EPOCH: 5, train_loss: 0.02111344147637925, valid_loss: 0.01896146567804473, time: 23.400591135025024\n",
      "EPOCH: 10, train_loss: 0.020908218931735438, valid_loss: 0.01854135633579322, time: 44.17073035240173\n",
      "EPOCH: 15, train_loss: 0.020208616152077037, valid_loss: 0.018135410494038037, time: 61.08744692802429\n",
      "EPOCH: 20, train_loss: 0.019038206377231023, valid_loss: 0.017665649471538408, time: 81.77941513061523\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017627249977418356, time: 98.12331795692444\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17581\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5179946554729539, valid_loss: 0.022880750255925314, time: 3.3091416358947754\n",
      "EPOCH: 5, train_loss: 0.0210452631768519, valid_loss: 0.01876852722572429, time: 24.99692153930664\n",
      "EPOCH: 10, train_loss: 0.02081191929968169, valid_loss: 0.018964164384773798, time: 44.89946222305298\n",
      "EPOCH: 15, train_loss: 0.020168057160220878, valid_loss: 0.018186199026448385, time: 64.02810335159302\n",
      "EPOCH: 20, train_loss: 0.01903008869475257, valid_loss: 0.017834235009338173, time: 84.50307750701904\n",
      "training until max epoch 25,  : best itaration is 21, valid loss is 0.017747419380715914, time: 101.96823620796204\n",
      "seed 9 , cv score : 0.017289261710760718\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17540\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5158441265242814, valid_loss: 0.02266552469560078, time: 4.313869476318359\n",
      "EPOCH: 5, train_loss: 0.02120497132087276, valid_loss: 0.018401512423796312, time: 25.758074283599854\n",
      "EPOCH: 10, train_loss: 0.021003014238102594, valid_loss: 0.018008232728711198, time: 47.055880546569824\n",
      "EPOCH: 15, train_loss: 0.020322688114251534, valid_loss: 0.017539975100329945, time: 67.02475810050964\n",
      "EPOCH: 20, train_loss: 0.019129276180463117, valid_loss: 0.01717173395944493, time: 88.20944809913635\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017171010720942702, time: 101.60563516616821\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17562\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5144032824131912, valid_loss: 0.022159396431275777, time: 3.3291947841644287\n",
      "EPOCH: 5, train_loss: 0.021259532833512684, valid_loss: 0.018184758217207022, time: 27.32616424560547\n",
      "EPOCH: 10, train_loss: 0.02091479135582047, valid_loss: 0.01794396944876228, time: 45.99603533744812\n",
      "EPOCH: 15, train_loss: 0.02028099455646355, valid_loss: 0.017537617976112026, time: 65.96873569488525\n",
      "EPOCH: 20, train_loss: 0.019100887687319386, valid_loss: 0.01726801065461976, time: 86.41786170005798\n",
      "training until max epoch 25,  : best itaration is 21, valid loss is 0.017181656882166864, time: 103.03494262695312\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17535\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5159848188187051, valid_loss: 0.022521550367985452, time: 3.6870603561401367\n",
      "EPOCH: 5, train_loss: 0.02126774230204961, valid_loss: 0.01866687647998333, time: 22.69684076309204\n",
      "EPOCH: 10, train_loss: 0.020926304147852695, valid_loss: 0.01832261559154306, time: 42.04173755645752\n",
      "EPOCH: 15, train_loss: 0.020220408955698505, valid_loss: 0.01795459653117827, time: 61.588536977767944\n",
      "EPOCH: 20, train_loss: 0.019124950337059358, valid_loss: 0.01742509116551706, time: 86.57932209968567\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017368449590035848, time: 104.86410140991211\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17562\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5180171274029426, valid_loss: 0.022663193196058272, time: 4.464687824249268\n",
      "EPOCH: 5, train_loss: 0.02113594007372421, valid_loss: 0.01868723886353629, time: 23.913195371627808\n",
      "EPOCH: 10, train_loss: 0.020933660671767527, valid_loss: 0.01816101489322526, time: 44.789066314697266\n",
      "EPOCH: 15, train_loss: 0.020232266753259367, valid_loss: 0.017777278487171446, time: 65.13328051567078\n",
      "EPOCH: 20, train_loss: 0.019033908055429042, valid_loss: 0.017343727366200514, time: 83.92395973205566\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017160983543310845, time: 101.11175274848938\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17593\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5155230261874895, valid_loss: 0.023009658445205007, time: 3.3104746341705322\n",
      "EPOCH: 5, train_loss: 0.021079496623282016, valid_loss: 0.019084262581808228, time: 22.600059270858765\n",
      "EPOCH: 10, train_loss: 0.020794019674080132, valid_loss: 0.01880449519625732, time: 44.38900184631348\n",
      "EPOCH: 15, train_loss: 0.020188270286269433, valid_loss: 0.01834599593920367, time: 66.54515266418457\n",
      "EPOCH: 20, train_loss: 0.019029099915693275, valid_loss: 0.01770391059773309, time: 88.3941080570221\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.01760291417262384, time: 105.41512036323547\n",
      "seed 10 , cv score : 0.017316657215528337\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17532\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5168448161772069, valid_loss: 0.022269328577177866, time: 3.8797190189361572\n",
      "EPOCH: 5, train_loss: 0.02125590589061818, valid_loss: 0.018381212704948018, time: 25.80278491973877\n",
      "EPOCH: 10, train_loss: 0.021006367977379876, valid_loss: 0.018339869539652554, time: 42.79934597015381\n",
      "EPOCH: 15, train_loss: 0.020295573603909683, valid_loss: 0.017720108080123153, time: 64.75561237335205\n",
      "EPOCH: 20, train_loss: 0.019080288338420147, valid_loss: 0.017257799633911677, time: 87.61843824386597\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.01718833590192454, time: 101.16940069198608\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17589\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.516242890503176, valid_loss: 0.02265971510538033, time: 3.3524863719940186\n",
      "EPOCH: 5, train_loss: 0.02118147418827471, valid_loss: 0.018935416479195867, time: 23.195675373077393\n",
      "EPOCH: 10, train_loss: 0.020803317740342043, valid_loss: 0.018363146563725813, time: 42.991804122924805\n",
      "EPOCH: 15, train_loss: 0.02024361370199353, valid_loss: 0.01768703359578337, time: 62.338157176971436\n",
      "EPOCH: 20, train_loss: 0.01901431162807628, valid_loss: 0.017330808751285075, time: 81.77312970161438\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017264157001461302, time: 97.04941654205322\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17567\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.515629455420005, valid_loss: 0.021844555863312312, time: 3.4678122997283936\n",
      "EPOCH: 5, train_loss: 0.021199148855287665, valid_loss: 0.01839991682874305, time: 21.869535207748413\n",
      "EPOCH: 10, train_loss: 0.02100416081175752, valid_loss: 0.018083663071904864, time: 42.56928586959839\n",
      "EPOCH: 15, train_loss: 0.020312662175210723, valid_loss: 0.01755376011133194, time: 62.58085918426514\n",
      "EPOCH: 20, train_loss: 0.019091018774703036, valid_loss: 0.017250654793211393, time: 84.50754141807556\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017113910296133586, time: 101.74584794044495\n",
      "======================== fold 4 ========================\n",
      "quantile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "17537\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5151938824730851, valid_loss: 0.022124314148511206, time: 3.345092535018921\n",
      "EPOCH: 5, train_loss: 0.021312667981442743, valid_loss: 0.018260086327791213, time: 26.350858449935913\n",
      "EPOCH: 10, train_loss: 0.021016779960724558, valid_loss: 0.018325651064515114, time: 48.940491914749146\n",
      "EPOCH: 15, train_loss: 0.02031373791396618, valid_loss: 0.017546936656747544, time: 65.82290482521057\n",
      "EPOCH: 20, train_loss: 0.01910446085253336, valid_loss: 0.017253820385251726, time: 87.2420494556427\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.01721846317606313, time: 103.11309695243835\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17567\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.515650103983544, valid_loss: 0.022553074359893798, time: 3.3059229850769043\n",
      "EPOCH: 5, train_loss: 0.021168055719811552, valid_loss: 0.018548175852213588, time: 26.15308117866516\n",
      "EPOCH: 10, train_loss: 0.02092467480930534, valid_loss: 0.018225023735846793, time: 45.659117221832275\n",
      "EPOCH: 15, train_loss: 0.020218270810416144, valid_loss: 0.017682834129248346, time: 67.8172550201416\n",
      "EPOCH: 20, train_loss: 0.019058356129557547, valid_loss: 0.017361103902970042, time: 90.07025957107544\n",
      "training until max epoch 25,  : best itaration is 21, valid loss is 0.01726516400064741, time: 106.99015593528748\n",
      "seed 11 , cv score : 0.01732615992052528\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17589\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5158349989920202, valid_loss: 0.02215378837926047, time: 3.5587587356567383\n",
      "EPOCH: 5, train_loss: 0.021264902526771066, valid_loss: 0.01838095962469067, time: 22.797494649887085\n",
      "EPOCH: 10, train_loss: 0.020908018247815813, valid_loss: 0.017991561362785954, time: 42.79405617713928\n",
      "EPOCH: 15, train_loss: 0.020215548670096117, valid_loss: 0.01770171115973166, time: 64.4213011264801\n",
      "EPOCH: 20, train_loss: 0.0189854504173472, valid_loss: 0.017302182343389306, time: 84.26597499847412\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017236197553575038, time: 97.71432065963745\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17558\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5181377581626612, valid_loss: 0.028599712891238076, time: 4.385509967803955\n",
      "EPOCH: 5, train_loss: 0.021289389743639604, valid_loss: 0.018801100525472847, time: 25.280940532684326\n",
      "EPOCH: 10, train_loss: 0.02094159646462785, valid_loss: 0.018879416079393457, time: 45.80866837501526\n",
      "EPOCH: 15, train_loss: 0.02025570290802169, valid_loss: 0.018161050150437015, time: 68.45679688453674\n",
      "EPOCH: 20, train_loss: 0.019048399760992856, valid_loss: 0.017759128074560846, time: 90.59795641899109\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.01765207922352212, time: 107.33061623573303\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17562\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.515914502506056, valid_loss: 0.022582052701285906, time: 4.656425476074219\n",
      "EPOCH: 5, train_loss: 0.021217049051919123, valid_loss: 0.018638321704098158, time: 25.549726247787476\n",
      "EPOCH: 10, train_loss: 0.020888132199536273, valid_loss: 0.01821170561015606, time: 47.278061628341675\n",
      "EPOCH: 15, train_loss: 0.02028358304859513, valid_loss: 0.01789267315928425, time: 66.57103419303894\n",
      "EPOCH: 20, train_loss: 0.01915076800560864, valid_loss: 0.01718025609318699, time: 87.93879866600037\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.01709855084440538, time: 106.76122832298279\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17492\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.516866130521521, valid_loss: 0.024136474888239588, time: 4.886685371398926\n",
      "EPOCH: 5, train_loss: 0.021313634221715963, valid_loss: 0.019151365011930467, time: 25.187109231948853\n",
      "EPOCH: 10, train_loss: 0.020896247451138848, valid_loss: 0.018038832609142574, time: 44.11350727081299\n",
      "EPOCH: 15, train_loss: 0.020279976210611707, valid_loss: 0.017644517895366463, time: 67.09360456466675\n",
      "EPOCH: 20, train_loss: 0.0191281250308213, valid_loss: 0.017173160878675323, time: 90.0069649219513\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017150692003113883, time: 103.27738404273987\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17591\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5173999638480209, valid_loss: 0.022478042170405388, time: 4.345499515533447\n",
      "EPOCH: 5, train_loss: 0.02128092252588185, valid_loss: 0.018309458824140683, time: 22.55082869529724\n",
      "EPOCH: 10, train_loss: 0.020960197178986822, valid_loss: 0.0183537236813988, time: 44.132352352142334\n",
      "EPOCH: 15, train_loss: 0.020262214321180853, valid_loss: 0.017436684082661358, time: 64.96570777893066\n",
      "EPOCH: 20, train_loss: 0.019142777747372643, valid_loss: 0.01706098932772875, time: 84.21836113929749\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.016943462299449104, time: 102.06936645507812\n",
      "seed 12 , cv score : 0.0172967901513506\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17573\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5149067105167974, valid_loss: 0.022317246081573622, time: 3.1848700046539307\n",
      "EPOCH: 5, train_loss: 0.02116314497144118, valid_loss: 0.018950034411890165, time: 23.099257230758667\n",
      "EPOCH: 10, train_loss: 0.020928791771731237, valid_loss: 0.01822681882019554, time: 45.09957838058472\n",
      "EPOCH: 15, train_loss: 0.02021503746237633, valid_loss: 0.018062525082911764, time: 65.73073625564575\n",
      "EPOCH: 20, train_loss: 0.019127511820436396, valid_loss: 0.01749802591013057, time: 87.85752463340759\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017438369776521412, time: 103.26944589614868\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17630\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.516285958149246, valid_loss: 0.021796212202924138, time: 3.780531644821167\n",
      "EPOCH: 5, train_loss: 0.021377189914240455, valid_loss: 0.01813058281207786, time: 25.635398387908936\n",
      "EPOCH: 10, train_loss: 0.021088423737644277, valid_loss: 0.01754843142321881, time: 47.09324336051941\n",
      "EPOCH: 15, train_loss: 0.020536020411735904, valid_loss: 0.01724584649919587, time: 65.28332090377808\n",
      "EPOCH: 20, train_loss: 0.019341477322099853, valid_loss: 0.016701167202828562, time: 86.66224074363708\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.01656696288024678, time: 103.29729676246643\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17512\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5192710958311663, valid_loss: 0.022765267587133816, time: 4.218383550643921\n",
      "EPOCH: 5, train_loss: 0.02113918327342938, valid_loss: 0.018450378626585006, time: 24.17155122756958\n",
      "EPOCH: 10, train_loss: 0.02100394414189984, valid_loss: 0.018427927153451103, time: 45.31351137161255\n",
      "EPOCH: 15, train_loss: 0.020289413110517403, valid_loss: 0.01773039552250079, time: 63.00328183174133\n",
      "EPOCH: 20, train_loss: 0.01913256659720312, valid_loss: 0.017518094527934278, time: 83.54563641548157\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.01741208287754229, time: 99.10669779777527\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17565\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5178186032975459, valid_loss: 0.022818419709801675, time: 4.737323999404907\n",
      "EPOCH: 5, train_loss: 0.021143972656152546, valid_loss: 0.01847420475844826, time: 25.79292869567871\n",
      "EPOCH: 10, train_loss: 0.02082410437075326, valid_loss: 0.018517641776374407, time: 46.970391035079956\n",
      "EPOCH: 15, train_loss: 0.020239230449291042, valid_loss: 0.018051088654569218, time: 69.30779957771301\n",
      "EPOCH: 20, train_loss: 0.019006218462094774, valid_loss: 0.017676878374602113, time: 87.08272433280945\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017667199485003948, time: 105.82197856903076\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17512\n",
      "975\n",
      "975\n",
      "EPOCH: 0, train_loss: 0.5182902216363479, valid_loss: 0.02239262525524412, time: 3.2888762950897217\n",
      "EPOCH: 5, train_loss: 0.021331476006547317, valid_loss: 0.018673557894570487, time: 23.74772596359253\n",
      "EPOCH: 10, train_loss: 0.02099087696029421, valid_loss: 0.018478970442499434, time: 44.1737334728241\n",
      "EPOCH: 15, train_loss: 0.02033393854713615, valid_loss: 0.017955110248710427, time: 65.33742713928223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20, train_loss: 0.019150475779657856, valid_loss: 0.017458457180431913, time: 83.68474197387695\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.01726364993623325, time: 101.43653917312622\n",
      "seed 13 , cv score : 0.017308827864624038\n",
      "cv score : 0.017039401927020907\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "DEVICE = ('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 25\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "\n",
    "train_preds = np.zeros((X.shape[0], y_nonv.shape[1]))\n",
    "preds = np.zeros((test_df.shape[0], y_nonv.shape[1]))\n",
    "imps = []\n",
    "imp_cols = []\n",
    "folds = []\n",
    "test_cv_preds = []\n",
    "\n",
    "for seed in seeds:\n",
    "    seed_everything(seed)\n",
    "    K = 5\n",
    "    kf = MultilabelStratifiedKFold(n_splits=K, random_state=seed, shuffle=True)\n",
    "    train_pred = np.zeros(train_preds.shape)\n",
    "    \n",
    "    \n",
    "    ###############################################################################################\n",
    "    # LOAD LIBRARIES\n",
    "    targets = SCORED_MOAS.copy()\n",
    "\n",
    "    # LOCATE DRUGS\n",
    "    vc = scored[\"drug_id\"].value_counts()\n",
    "    vc1 = vc.loc[vc<=18].index.sort_values()\n",
    "    vc2 = vc.loc[vc>18].index.sort_values()\n",
    "\n",
    "    # STRATIFY DRUGS 18X OR LESS\n",
    "    dct1 = {}; dct2 = {}\n",
    "    skf = MultilabelStratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "    tmp = scored.groupby('drug_id')[targets].mean().loc[vc1]\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.index[idxV].values} # drug id がどのフォールドに属すか格納\n",
    "        dct1.update(dd)\n",
    "\n",
    "    # STRATIFY DRUGS MORE THAN 18X\n",
    "    skf = MultilabelStratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "    tmp = scored.loc[scored[\"drug_id\"].isin(vc2)].reset_index(drop=True)\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp[\"sig_id\"][idxV].values}\n",
    "        dct2.update(dd)\n",
    "\n",
    "    # ASSIGN K\n",
    "    scored['fold'] = scored.drug_id.map(dct1)\n",
    "    scored.loc[scored[\"fold\"].isna(),'fold'] = scored.loc[scored[\"fold\"].isna(),'sig_id'].map(dct2)\n",
    "    scored[\"fold\"] = scored[\"fold\"].astype('int8')\n",
    "    ###############################################################################################\n",
    "\n",
    "    #for fold, (train_index, valid_index) in enumerate(kf.split(X, y_nonv)):    \n",
    "    for fold in range(K):\n",
    "        train_index = scored[scored[\"fold\"] != fold].index.to_list()\n",
    "        valid_index = scored[scored[\"fold\"] == fold].index.to_list()\n",
    "        print(\"======================== fold {} ========================\".format(fold+1))\n",
    "        folds.append(train_index)\n",
    "                \n",
    "        # split data\n",
    "        train_X = X.iloc[train_index]\n",
    "        train_y = y_nonv[train_index]\n",
    "        valid_X = X.iloc[valid_index]\n",
    "        valid_y = y_nonv[valid_index]\n",
    "        test_X = (test_df.drop(\"sig_id\", axis=1))\n",
    "        pub_test_X = (pub_test_df.drop(\"sig_id\", axis=1))\n",
    "        \n",
    "        \n",
    "\n",
    "        # scaler\n",
    "        print(SCALE)\n",
    "        scale_cols = BIOS_+PRODS\n",
    "        scaler = make_scaler(SCALE, seed).fit(train_X.append(pub_test_X)[scale_cols])\n",
    "        for df in [train_X, valid_X, test_X, pub_test_X]:\n",
    "            df[scale_cols] = scaler.transform(df[scale_cols])\n",
    "            \n",
    "            \n",
    "        print(\"PCA\")\n",
    "        #PCA\n",
    "        n_decom_g = 80\n",
    "        n_decom_c = 10\n",
    "        decom_g_cols = [f\"pca_g-{i}\" for i in range(n_decom_g)]\n",
    "        decom_c_cols = [f\"pca_c-{i}\" for i in range(n_decom_c)]\n",
    "        \n",
    "        pca_g = PCA(n_components = n_decom_g, random_state = seed).fit(train_X.append(pub_test_X)[GENES_])\n",
    "        pca_c = PCA(n_components = n_decom_c, random_state = seed).fit(train_X.append(pub_test_X)[CELLS_])\n",
    "        \n",
    "        for df in [train_X, valid_X, test_X, pub_test_X]:\n",
    "            df[decom_g_cols] = pca_g.transform(df[GENES_])\n",
    "            df[decom_c_cols] = pca_c.transform(df[CELLS_])\n",
    "            #df.drop(GENES_+CELLS_, axis=1, inplace=True) \n",
    "            \n",
    "        \n",
    "        print(train_X.shape[0])\n",
    "        # prepare data for training\n",
    "        train_X1 = train_X.values\n",
    "        train_X2 = train_X.values\n",
    "        valid_X1 = valid_X.values\n",
    "        valid_X2 = valid_X.values\n",
    "        test_X1 = test_X.values\n",
    "        test_X2 = test_X.values\n",
    "        print(train_X1.shape[1])\n",
    "        print(train_X2.shape[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ================================model training===========================\n",
    "        train_dataset = MoAResNetDataset(train_X1, train_X2, train_y)\n",
    "        valid_dataset = MoAResNetDataset(valid_X1, valid_X2, valid_y)\n",
    "        test_dataset = TestResNetDataset(test_X1, test_X2)\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "        model = Model(\n",
    "            num_features1=train_X1.shape[1],\n",
    "            num_features2=train_X2.shape[1],\n",
    "            num_targets=train_y.shape[1],\n",
    "        )\n",
    "\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        \n",
    "        optimizer = torch.optim.Adam( model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY,)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,pct_start=0.1, div_factor=1e3, max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader) )\n",
    "        #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode = \"min\", patience = 3, min_lr = 1e-5, factor = 0.1, eps=1e-5,verbose=True)\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss_tr = SmoothBCEwLogits(smoothing=1e-3)\n",
    "        \n",
    "        \n",
    "        # train\n",
    "        model = run_training(\n",
    "            model=model,\n",
    "            trainloader=trainloader,\n",
    "            validloader=validloader,\n",
    "            epoch_=EPOCHS,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            loss_fn=loss_fn,\n",
    "            loss_tr=loss_tr,\n",
    "            early_stopping_steps=EARLY_STOPPING_STEPS,\n",
    "            device=DEVICE,\n",
    "            verbose=5,\n",
    "            fold=fold,\n",
    "            seed=seed,)\n",
    "        #model = torch.load('dnn_weights/{}_{}.pt'.format(seed, fold))\n",
    "        model.load_state_dict(torch.load('resnet_weights/{}_{}.pt'.format(seed, fold)))\n",
    "        \n",
    "        #valid predict\n",
    "        val_preds = predict(\n",
    "            model=model,\n",
    "            testloader=validloader,\n",
    "            device=DEVICE,)\n",
    "        \n",
    "        #test predict\n",
    "        test_preds = predict(\n",
    "            model=model,\n",
    "            testloader=testloader,\n",
    "            device=DEVICE)\n",
    "        \n",
    "        # ================================model training===========================\n",
    "\n",
    "        train_pred[valid_index] +=  val_preds\n",
    "        \n",
    "        preds += test_preds / (K*len(seeds))\n",
    "        \n",
    "        #name = \"{}_{}\".format(seed, fold)\n",
    "        #model.save_model(\"tabnet_weights_inf/\"+name)\n",
    "        #imps.append(model.feature_importances_)\n",
    "\n",
    "    print(\"seed {} , cv score : {}\".format(seed, metric(y_nonv, train_pred)))\n",
    "    train_preds += train_pred/len(seeds)\n",
    "\n",
    "print(\"cv score : {}\".format(metric(y_nonv, train_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score : 0.01570424092946404\n"
     ]
    }
   ],
   "source": [
    "train_preds2 = np.zeros((TR_SIZE,  y.shape[1]))\n",
    "train_preds2[train_nonvehicle_index] = train_preds\n",
    "\n",
    "\n",
    "preds2 = np.zeros((TE_SIZE, y.shape[1]))\n",
    "preds2[test_nonvehicle_index] = preds\n",
    "\n",
    "print(\"cv score : {}\".format(metric(y, train_preds2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score : 0.01570424093729969\n"
     ]
    }
   ],
   "source": [
    "train_preds3 = np.clip(train_preds2, 1e-10, 1-1e-10)\n",
    "print(\"cv score : {}\".format(metric(y, train_preds3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../../../Data/Raw/sample_submission.csv\")\n",
    "#sub_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n",
    "cols = [col for col in sub_df.columns if col != \"sig_id\"]\n",
    "sub_df[cols] = preds2\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub = pd.read_csv(\"../../../Data/Raw/train_targets_scored.csv\")\n",
    "cols = [col for col in train_sub.columns if col != \"sig_id\"]\n",
    "train_sub[cols] = train_preds2\n",
    "train_sub.to_csv(\"train_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: resnet_weights/10_0.pt (deflated 4%)\n",
      "  adding: resnet_weights/10_1.pt (deflated 3%)\n",
      "  adding: resnet_weights/10_2.pt (deflated 4%)\n",
      "  adding: resnet_weights/10_3.pt (deflated 4%)\n",
      "  adding: resnet_weights/10_4.pt (deflated 4%)\n",
      "  adding: resnet_weights/11_0.pt (deflated 4%)\n",
      "  adding: resnet_weights/11_1.pt (deflated 4%)\n",
      "  adding: resnet_weights/11_2.pt (deflated 4%)\n",
      "  adding: resnet_weights/11_3.pt (deflated 4%)\n",
      "  adding: resnet_weights/11_4.pt (deflated 4%)\n",
      "  adding: resnet_weights/12_0.pt (deflated 4%)\n",
      "  adding: resnet_weights/12_1.pt (deflated 4%)\n",
      "  adding: resnet_weights/12_2.pt (deflated 4%)\n",
      "  adding: resnet_weights/12_3.pt (deflated 4%)\n",
      "  adding: resnet_weights/12_4.pt (deflated 3%)\n",
      "  adding: resnet_weights/13_0.pt (deflated 4%)\n",
      "  adding: resnet_weights/13_1.pt (deflated 4%)\n",
      "  adding: resnet_weights/13_2.pt (deflated 4%)\n",
      "  adding: resnet_weights/13_3.pt (deflated 4%)\n",
      "  adding: resnet_weights/13_4.pt (deflated 4%)\n",
      "  adding: resnet_weights/7_0.pt (deflated 4%)\n",
      "  adding: resnet_weights/7_1.pt (deflated 4%)\n",
      "  adding: resnet_weights/7_2.pt (deflated 4%)\n",
      "  adding: resnet_weights/7_3.pt (deflated 4%)\n",
      "  adding: resnet_weights/7_4.pt (deflated 4%)\n",
      "  adding: resnet_weights/8_0.pt (deflated 4%)\n",
      "  adding: resnet_weights/8_1.pt (deflated 4%)\n",
      "  adding: resnet_weights/8_2.pt (deflated 4%)\n",
      "  adding: resnet_weights/8_3.pt (deflated 4%)\n",
      "  adding: resnet_weights/8_4.pt (deflated 4%)\n",
      "  adding: resnet_weights/9_0.pt (deflated 4%)\n",
      "  adding: resnet_weights/9_1.pt (deflated 4%)\n",
      "  adding: resnet_weights/9_2.pt (deflated 4%)\n",
      "  adding: resnet_weights/9_3.pt (deflated 4%)\n",
      "  adding: resnet_weights/9_4.pt (deflated 4%)\n"
     ]
    }
   ],
   "source": [
    "!zip resnet_weights.zip resnet_weights/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
