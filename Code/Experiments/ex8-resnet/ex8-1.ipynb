{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを少し変えたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, random, os, sys, tqdm, time\n",
    "sys.path.append(\"../\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer, RobustScaler\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1200)\n",
    "pd.set_option(\"display.max_rows\", 1200)\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    res = []\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        y = y_true[:,i]\n",
    "        pred = y_pred[:,i]\n",
    "        print(i)\n",
    "        res.append(log_loss(y, pred))\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    res = []\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        y = y_true[:,i]\n",
    "        pred = y_pred[:,i]\n",
    "        if np.sum(pred) <= 0.0:\n",
    "            pre += 1e-15\n",
    "        res.append(log_loss(y, pred))\n",
    "    return np.mean(res)\n",
    "\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "seed_everything(42)\n",
    "        \n",
    "    \n",
    "def make_scaler(flag, seed):\n",
    "    if flag == \"quantile\":\n",
    "        return QuantileTransformer(n_quantiles=100,random_state=seed, output_distribution=\"normal\")\n",
    "    elif flag == \"gauss\":\n",
    "        return GaussRankScaler()\n",
    "    elif flag == \"standard\":\n",
    "        return StandardScaler()\n",
    "    elif flag == \"minmax\":\n",
    "        return MinMaxScaler()\n",
    "    elif flag == \"robust\":\n",
    "        return RobustScaler()\n",
    "    \n",
    "seeds = [7, 8, 9, 10, 11, 12, 13]\n",
    "SCALE = \"quantile\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g772, c100, 206クラス、402クラスの分類\n",
    "\n",
    "train_df = pd.read_csv(\"../../../Data/Raw/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../../../Data/Raw/test_features.csv\")\n",
    "#pub_test_df = pd.read_csv(\"../input/moapublictest/test_features.csv\")\n",
    "pub_test_df = pd.read_csv(\"../../../Data/Raw/test_features.csv\")\n",
    "drug_df = pd.read_csv(\"../../../Data/Raw/train_drug.csv\")#\n",
    "\n",
    "y = pd.read_csv(\"../../../Data/Raw/train_targets_scored.csv\")\n",
    "y_non = pd.read_csv(\"../../../Data/Raw/train_targets_nonscored.csv\")\n",
    "y_all = pd.concat([y, y_non.drop(\"sig_id\", axis=1)], axis=1)\n",
    "y = y.merge(drug_df, on='sig_id', how='left') #\n",
    "\n",
    "GENES = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "CELLS = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
    "BIOS = GENES + CELLS\n",
    "\n",
    "\n",
    "SCORED_MOAS = [col for col in y.columns if col != \"sig_id\" and col != \"drug_id\"]#\n",
    "NONSCORED_MOAS = [col for col in y_non.columns if col != \"sig_id\"]\n",
    "ALL_MOAS = SCORED_MOAS + NONSCORED_MOAS\n",
    "\n",
    "\n",
    "TR_SIZE = train_df.shape[0]\n",
    "TE_SIZE = test_df.shape[0]\n",
    "\n",
    "train_nonvehicle_index = train_df[train_df[\"cp_type\"] != \"ctl_vehicle\"].index\n",
    "test_nonvehicle_index = test_df[test_df[\"cp_type\"] != \"ctl_vehicle\"].index\n",
    "\n",
    "train_df[\"time_dose\"] = train_df[\"cp_time\"].astype(str) + \" * \" + train_df[\"cp_dose\"]\n",
    "test_df[\"time_dose\"] = test_df[\"cp_time\"].astype(str) + \" * \" + test_df[\"cp_dose\"]\n",
    "pub_test_df[\"time_dose\"] = pub_test_df[\"cp_time\"].astype(str) + \" * \" + pub_test_df[\"cp_dose\"]\n",
    "\n",
    "# remove cp_type = ctl_vehicle\n",
    "mask = train_df[\"cp_type\"] != \"ctl_vehicle\"\n",
    "train_df = train_df[mask].drop(\"cp_type\", axis=1).reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cp_type\"] != \"ctl_vehicle\"].drop(\"cp_type\", axis=1).reset_index(drop=True)\n",
    "pub_test_df = pub_test_df[pub_test_df[\"cp_type\"] != \"ctl_vehicle\"].drop(\"cp_type\", axis=1).reset_index(drop=True)\n",
    "y_nonv = y[mask].reset_index(drop=True)#\n",
    "\n",
    "scored = y_nonv.copy()#\n",
    "y_nonv.drop(\"drug_id\", axis=1, inplace=True)#\n",
    "y.drop(\"drug_id\", axis=1, inplace=True)#\n",
    "\n",
    "TR_NONV_SIZE = train_df.shape[0]\n",
    "TE_NONV_SHAPE = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# prod\n",
    "#prod_p_cols = [['g-722', 'g-655', 'g-707'], ['g-707', 'g-65', 'g-392'], ['g-169', 'g-484', 'g-338'], ['g-417', 'g-100', 'g-707'], ['g-38', 'g-100', 'g-707'], ['g-310', 'g-744', 'g-707'], ['g-100', 'g-0', 'g-123'], ['g-38', 'g-100', 'g-744'], ['g-328', 'g-707', 'g-158'], ['g-100', 'g-744', 'g-38'], ['g-310', 'g-744', 'g-707'], ['g-491', 'g-100', 'g-38'], ['g-135', 'g-392', 'g-512'], ['g-131', 'g-38', 'g-708'], ['g-180', 'g-624', 'g-613'], ['g-707', 'g-133', 'g-392'], ['g-69', 'g-707', 'g-100'], ['g-392', 'g-731', 'g-707'], ['g-759', 'g-392', 'g-65'], ['g-544', 'g-425', 'g-707'], ['g-69', 'g-608', 'g-417'], ['g-441', 'g-703', 'g-491'], ['g-712', 'g-310', 'g-328'], ['g-624', 'g-615', 'g-189'], ['g-57', 'g-729', 'g-130'], ['g-146', 'g-466', 'g-762'], ['g-308', 'g-495', 'g-712'], ['g-181', 'g-707', 'g-38'], ['g-392', 'g-731', 'g-131'], ['g-349', 'g-750', 'g-91'], ['g-541', 'g-748', 'g-38'], ['g-91', 'g-100', 'g-478'], ['g-635', 'g-514', 'g-302'], ['g-419', 'g-676', 'g-130'], ['g-744', 'g-131', 'g-100'], ['g-707', 'g-158', 'g-100'], ['g-127', 'g-749', 'g-380'], ['g-392', 'g-731', 'g-100'], ['g-144', 'g-123', 'g-86'], ['g-732', 'g-744', 'g-707'], ['g-744', 'g-731', 'g-100'], ['g-731', 'g-158', 'g-38'], ['g-158', 'g-100', 'g-707'], ['g-208', 'g-707', 'g-731'], ['g-38', 'g-392', 'g-707'], ['g-744', 'g-721', 'g-707'], ['g-162', 'g-157', 'g-178'], ['g-326', 'g-707', 'g-449'], ['g-504', 'g-392', 'g-707'], ['g-729', 'g-182', 'g-208'], ['g-744', 'g-608', 'g-100'], ['g-452', 'g-391', 'g-413'], ['g-714', 'g-452', 'g-658'], ['g-100', 'g-392', 'g-707'], ['g-640', 'g-266', 'g-310'], ['g-91', 'g-145', 'g-208'], ['g-744', 'g-158', 'g-392'], ['g-16', 'g-714', 'g-707'], ['g-310', 'g-13', 'g-100'], ['g-478', 'g-468', 'g-310'], ['g-689', 'g-100', 'g-707'], ['g-208', 'g-714', 'g-707'], ['g-38', 'g-158', 'g-707'], ['g-484', 'g-392', 'g-544'], ['g-392', 'g-484', 'g-74'], ['g-95', 'g-170', 'g-707'], ['g-91', 'g-130', 'g-707'], ['g-131', 'g-208', 'g-392'], ['g-417', 'g-248', 'g-744'], ['g-707', 'g-607', 'g-358'], ['g-392', 'g-707', 'g-158'], ['g-31', 'g-328', 'g-460'], ['g-576', 'g-666', 'g-608'], ['g-368', 'g-402', 'g-707'], ['g-512', 'g-594', 'g-38'], ['g-38', 'g-707', 'g-158'], ['g-392', 'g-100', 'g-707'], ['g-91', 'g-100', 'g-707'], ['g-158', 'g-38', 'g-744'], ['g-744', 'g-707', 'g-100'], ['g-654', 'g-143', 'g-377'], ['g-131', 'g-100', 'g-170'], ['g-699', 'g-235', 'g-707'], ['g-744', 'g-392', 'g-38'], ['g-682', 'g-592', 'g-707'], ['g-391', 'g-666', 'g-514'], ['g-143', 'g-231', 'g-265'], ['g-478', 'g-442', 'g-270'], ['g-608', 'g-162', 'g-11'], ['g-134', 'g-54', 'g-762'], ['g-145', 'g-201', 'g-208'], ['g-413', 'g-310', 'g-707'], ['g-744', 'g-38', 'g-100'], ['g-413', 'g-707', 'g-69'], ['g-123', 'g-731', 'g-100'], ['g-712', 'g-208', 'g-38'], ['g-731', 'g-707', 'g-100'], ['g-38', 'g-744', 'g-100'], ['g-576', 'g-452', 'g-392'], ['g-441', 'g-157', 'g-392'], ['g-596', 'g-744', 'g-707'], ['g-38', 'g-392', 'g-744'], ['g-392', 'g-69', 'g-654'], ['g-123', 'g-744', 'g-38'], ['g-417', 'g-46', 'g-181'], ['g-731', 'g-100', 'g-707'], ['g-484', 'g-707', 'g-158'], ['g-744', 'g-707', 'g-100'], ['g-100', 'g-158', 'g-707'], ['g-200', 'g-707', 'g-592'], ['g-215', 'g-392', 'g-330'], ['g-383', 'g-576', 'g-514'], ['g-689', 'g-69', 'g-100'], ['g-645', 'g-123', 'g-514'], ['g-697', 'g-200', 'g-608'], ['g-91', 'g-100', 'g-392'], ['g-38', 'g-707', 'g-158'], ['g-231', 'g-100', 'g-707'], ['g-573', 'g-127', 'g-70'], ['g-178', 'g-592', 'g-391'], ['g-368', 'g-100', 'g-707'], ['g-200', 'g-729', 'g-648'], ['g-723', 'g-731', 'g-100'], ['g-130', 'g-745', 'g-158'], ['g-208', 'g-131', 'g-100'], ['g-392', 'g-38', 'g-91'], ['g-731', 'g-744', 'g-158'], ['g-437', 'g-158', 'g-91'], ['g-707', 'g-335', 'g-116'], ['g-100', 'g-731', 'g-707'], ['g-44', 'g-714', 'g-707'], ['g-392', 'g-413', 'g-707'], ['g-65', 'g-392', 'g-158'], ['g-592', 'g-157', 'g-197'], ['g-740', 'g-762', 'g-170'], ['g-137', 'g-188', 'g-181'], ['g-270', 'g-170', 'g-100'], ['g-260', 'g-190', 'g-130'], ['g-718', 'g-722', 'g-707'], ['g-146', 'g-270', 'g-744'], ['g-505', 'g-391', 'g-38'], ['g-100', 'g-731', 'g-707'], ['g-84', 'g-65', 'g-707'], ['g-65', 'g-484', 'g-707'], ['g-328', 'g-28', 'g-392'], ['g-624', 'g-608', 'g-707'], ['g-635', 'g-158', 'g-707'], ['g-419', 'g-143', 'g-640'], ['g-744', 'g-707', 'g-100'], ['g-158', 'g-707', 'g-12'], ['g-744', 'g-707', 'g-38'], ['g-666', 'g-466', 'g-191'], ['g-38', 'g-328', 'g-417'], ['g-328', 'g-38', 'g-100'], ['g-417', 'g-392', 'g-707'], ['g-130', 'g-608', 'g-707'], ['g-380', 'g-38', 'g-707'], ['g-707', 'g-391', 'g-624'], ['g-613', 'g-330', 'g-106'], ['g-131', 'g-100', 'g-744'], ['g-181', 'g-512', 'g-270'], ['g-181', 'g-100', 'g-392'], ['g-744', 'g-417', 'g-100'], ['g-158', 'g-208', 'g-159'], ['g-88', 'g-643', 'g-436'], ['g-484', 'g-158', 'g-707'], ['g-100', 'g-744', 'g-392'], ['g-188', 'g-689', 'g-290'], ['g-158', 'g-417', 'g-11'], ['g-328', 'g-220', 'g-541'], ['g-243', 'g-259', 'g-744'], ['g-392', 'g-313', 'g-422'], ['g-707', 'g-131', 'g-123'], ['g-208', 'g-100', 'g-707'], ['g-158', 'g-417', 'g-707'], ['g-392', 'g-313', 'g-389'], ['g-16', 'g-707', 'g-100'], ['g-231', 'g-707', 'g-392'], ['g-725', 'g-712', 'g-640'], ['g-38', 'g-158', 'g-707'], ['g-201', 'g-745', 'g-599'], ['g-419', 'g-158', 'g-714'], ['g-173', 'g-596', 'g-737'], ['g-326', 'g-248', 'g-600'], ['g-131', 'g-100', 'g-158'], ['g-654', 'g-160', 'g-707'], ['g-147', 'g-731', 'g-721'], ['g-378', 'g-358', 'g-643'], ['g-100', 'g-38', 'g-744'], ['g-166', 'g-635', 'g-430'], ['g-417', 'g-38', 'g-328'], ['g-208', 'g-100', 'g-707'], ['g-38', 'g-744', 'g-100'], ['g-229', 'g-711', 'g-91'], ['g-248', 'g-38', 'g-338'], ['g-38', 'g-417', 'g-707'], ['g-731', 'g-100', 'g-707'], ['g-106', 'g-744', 'g-91'], ['g-707', 'g-624', 'g-455'], ['g-310', 'g-707', 'g-290'], ['g-131', 'g-170', 'g-158'], ['g-146', 'g-270', 'g-158'], ['g-529', 'g-707', 'g-74']]\n",
    "#prod_n_cols = [['g-431', 'g-597', 'g-489'], ['g-239', 'g-113', 'g-50'], ['g-370', 'g-431', 'g-656'], ['g-568', 'g-508', 'g-760'], ['g-370', 'g-508', 'g-37'], ['g-228', 'g-72', 'g-67'], ['g-50', 'g-37', 'g-250'], ['g-508', 'g-50', 'g-411'], ['g-128', 'g-370', 'g-429'], ['g-50', 'g-672', 'g-37'], ['g-508', 'g-37', 'g-489'], ['g-50', 'g-705', 'g-298'], ['g-771'], ['g-67', 'g-644', 'g-113'], ['g-50', 'g-37', 'g-36'], ['g-151', 'g-495', 'g-234'], ['g-276', 'g-178', 'g-428'], ['g-644', 'g-370', 'g-411'], ['g-370', 'g-568', 'g-50'], ['g-50', 'g-37', 'g-332'], ['g-375', 'g-644', 'g-271'], ['g-571', 'g-503', 'g-370'], ['g-56', 'g-161', 'g-298'], ['g-508', 'g-37', 'g-370'], ['g-537', 'g-487', 'g-719'], ['g-211', 'g-75', 'g-501'], ['g-503', 'g-477', 'g-489'], ['g-508', 'g-113', 'g-231'], ['g-113', 'g-375', 'g-75'], ['g-50', 'g-332', 'g-37'], ['g-113', 'g-75', 'g-178'], ['g-644', 'g-178', 'g-760'], ['g-50', 'g-72', 'g-37'], ['g-653', 'g-202', 'g-378'], ['g-300', 'g-247', 'g-584'], ['g-37', 'g-50', 'g-98'], ['g-50', 'g-58', 'g-332'], ['g-411', 'g-674', 'g-299'], ['g-672', 'g-50', 'g-508'], ['g-128', 'g-370', 'g-644'], ['g-37', 'g-228', 'g-202'], ['g-508', 'g-760', 'g-406'], ['g-75', 'g-113', 'g-228'], ['g-508', 'g-50', 'g-370'], ['g-72', 'g-370', 'g-50'], ['g-370', 'g-75', 'g-37'], ['g-399', 'g-644', 'g-739'], ['g-674', 'g-555', 'g-713'], ['g-610', 'g-537', 'g-323'], ['g-276', 'g-113', 'g-555'], ['g-421', 'g-612', 'g-464'], ['g-370', 'g-50', 'g-503'], ['g-508', 'g-151', 'g-267'], ['g-258', 'g-644', 'g-370'], ['g-370', 'g-276', 'g-75'], ['g-50', 'g-560', 'g-630'], ['g-332', 'g-178', 'g-508'], ['g-50', 'g-37', 'g-75'], ['g-370', 'g-558', 'g-371'], ['g-37', 'g-62', 'g-271'], ['g-75', 'g-50', 'g-375'], ['g-37', 'g-421', 'g-72'], ['g-370', 'g-684', 'g-508'], ['g-50', 'g-508', 'g-113'], ['g-50', 'g-298', 'g-37'], ['g-239', 'g-370', 'g-739'], ['g-705', 'g-50', 'g-298'], ['g-37', 'g-5', 'g-332'], ['g-508', 'g-37', 'g-72'], ['g-513', 'g-508', 'g-128'], ['g-555', 'g-281', 'g-172'], ['g-50', 'g-37', 'g-489'], ['g-370', 'g-228', 'g-644'], ['g-370', 'g-719', 'g-508'], ['g-298', 'g-477', 'g-644'], ['g-257', 'g-50', 'g-72'], ['g-75', 'g-370', 'g-672'], ['g-508', 'g-113', 'g-370'], ['g-332', 'g-58', 'g-37'], ['g-508', 'g-37', 'g-672'], ['g-50', 'g-37', 'g-672'], ['g-681', 'g-272', 'g-131'], ['g-771'], ['g-50', 'g-37', 'g-672'], ['g-370', 'g-571', 'g-438'], ['g-508', 'g-332', 'g-50'], ['g-370', 'g-400', 'g-300'], ['g-300', 'g-284', 'g-495'], ['g-234', 'g-761', 'g-555'], ['g-257', 'g-672', 'g-477'], ['g-370', 'g-227', 'g-653'], ['g-238', 'g-399', 'g-759'], ['g-508', 'g-228', 'g-656'], ['g-370', 'g-618', 'g-644'], ['g-508', 'g-228', 'g-113'], ['g-67', 'g-571', 'g-653'], ['g-37', 'g-228', 'g-489'], ['g-67', 'g-178', 'g-113'], ['g-202', 'g-370', 'g-421'], ['g-50', 'g-113', 'g-672'], ['g-370', 'g-399', 'g-98'], ['g-401', 'g-58', 'g-202'], ['g-508', 'g-370', 'g-58'], ['g-75', 'g-37', 'g-50'], ['g-300', 'g-370', 'g-568'], ['g-508', 'g-37', 'g-50'], ['g-234', 'g-271', 'g-632'], ['g-67', 'g-760', 'g-50'], ['g-113', 'g-75', 'g-489'], ['g-37', 'g-50', 'g-508'], ['g-508', 'g-67', 'g-37'], ['g-555', 'g-492', 'g-653'], ['g-113', 'g-250', 'g-325'], ['g-705', 'g-178', 'g-284'], ['g-332', 'g-50', 'g-571'], ['g-508', 'g-67', 'g-276'], ['g-375', 'g-644', 'g-113'], ['g-298', 'g-257', 'g-332'], ['g-75', 'g-50', 'g-653'], ['g-204', 'g-558', 'g-202'], ['g-587', 'g-644', 'g-17'], ['g-204', 'g-567', 'g-526'], ['g-571', 'g-568', 'g-760'], ['g-653', 'g-555', 'g-678'], ['g-202', 'g-50', 'g-760'], ['g-50', 'g-298', 'g-332'], ['g-50', 'g-37', 'g-59'], ['g-67', 'g-113', 'g-508'], ['g-75', 'g-298', 'g-508'], ['g-508', 'g-50', 'g-298'], ['g-487', 'g-285', 'g-232'], ['g-370', 'g-644', 'g-50'], ['g-370', 'g-575', 'g-477'], ['g-50', 'g-257', 'g-37'], ['g-508', 'g-644', 'g-113'], ['g-513', 'g-591', 'g-300'], ['g-375', 'g-681', 'g-492'], ['g-571', 'g-234', 'g-412'], ['g-37', 'g-58', 'g-228'], ['g-17', 'g-115', 'g-300'], ['g-323', 'g-506', 'g-168'], ['g-771'], ['g-743', 'g-497', 'g-595'], ['g-375', 'g-370', 'g-508'], ['g-50', 'g-37', 'g-568'], ['g-50', 'g-438', 'g-439'], ['g-370', 'g-67', 'g-58'], ['g-477', 'g-568', 'g-761'], ['g-370', 'g-267', 'g-705'], ['g-234', 'g-58', 'g-520'], ['g-234', 'g-508', 'g-595'], ['g-37', 'g-50', 'g-202'], ['g-37', 'g-644', 'g-489'], ['g-477', 'g-72', 'g-37'], ['g-506', 'g-719', 'g-300'], ['g-370', 'g-508', 'g-37'], ['g-508', 'g-50', 'g-37'], ['g-370', 'g-50', 'g-113'], ['g-370', 'g-300', 'g-487'], ['g-568', 'g-276', 'g-719'], ['g-421', 'g-434', 'g-644'], ['g-595', 'g-176', 'g-487'], ['g-50', 'g-672', 'g-489'], ['g-508', 'g-50', 'g-250'], ['g-250', 'g-489', 'g-439'], ['g-72', 'g-644', 'g-406'], ['g-185', 'g-37', 'g-672'], ['g-300', 'g-227', 'g-591'], ['g-332', 'g-37', 'g-370'], ['g-50', 'g-37', 'g-489'], ['g-367', 'g-438', 'g-144'], ['g-37', 'g-50', 'g-257'], ['g-276', 'g-653', 'g-291'], ['g-50', 'g-761', 'g-672'], ['g-477', 'g-571', 'g-585'], ['g-370', 'g-113', 'g-508'], ['g-508', 'g-370', 'g-332'], ['g-508', 'g-75', 'g-113'], ['g-58', 'g-186', 'g-477'], ['g-202', 'g-479', 'g-660'], ['g-477', 'g-332', 'g-36'], ['g-239', 'g-42', 'g-234'], ['g-508', 'g-370', 'g-37'], ['g-37', 'g-300', 'g-370'], ['g-370', 'g-300', 'g-96'], ['g-5', 'g-429', 'g-299'], ['g-477', 'g-497', 'g-487'], ['g-152', 'g-50', 'g-75'], ['g-375', 'g-477', 'g-585'], ['g-228', 'g-411', 'g-67'], ['g-190', 'g-475', 'g-628'], ['g-202', 'g-37', 'g-477'], ['g-595', 'g-276', 'g-75'], ['g-72', 'g-75', 'g-508'], ['g-370', 'g-508', 'g-50'], ['g-37', 'g-75', 'g-121'], ['g-503', 'g-761', 'g-50'], ['g-595', 'g-486', 'g-72'], ['g-508', 'g-67', 'g-370'], ['g-50', 'g-508', 'g-75'], ['g-508', 'g-553', 'g-72'], ['g-595', 'g-665', 'g-131'], ['g-705', 'g-375', 'g-704'], ['g-75', 'g-228', 'g-508'], ['g-508', 'g-37', 'g-644'], ['g-477', 'g-50', 'g-72']]\n",
    "# 上位500こ\n",
    "prod_cols = [['g-145', 'g-201', 'g-208'], ['g-370', 'g-508', 'g-37'], ['g-38', 'g-392', 'g-707'], ['g-328', 'g-28', 'g-392'], ['g-441', 'g-157', 'g-392'], ['g-181', 'g-100', 'g-392'], ['g-67', 'g-760', 'g-50'], ['g-731', 'g-100', 'g-707'], ['g-478', 'g-468', 'g-310'], ['g-91', 'g-145', 'g-208'], ['g-106', 'g-744', 'g-91'], ['g-131', 'g-208', 'g-392'], ['g-144', 'g-123', 'g-86'], ['g-228', 'g-72', 'g-67'], ['g-31', 'g-328', 'g-460'], ['g-392', 'g-731', 'g-100'], ['g-732', 'g-744', 'g-707'], ['g-705', 'g-375', 'g-704'], ['g-508', 'g-50', 'g-411'], ['g-234', 'g-58', 'g-520'], ['g-503', 'g-761', 'g-50'], ['g-113', 'g-75', 'g-178'], ['g-50', 'g-508', 'g-113'], ['g-113', 'g-375', 'g-75'], ['g-576', 'g-452', 'g-392'], ['g-50', 'g-37', 'g-36'], ['g-707', 'g-133', 'g-392'], ['g-484', 'g-392', 'g-544'], ['g-508', 'g-67', 'g-370'], ['g-123', 'g-731', 'g-100'], ['g-298', 'g-477', 'g-644'], ['g-72', 'g-370', 'g-50'], ['g-67', 'g-178', 'g-113'], ['g-744', 'g-608', 'g-100'], ['g-91', 'g-100', 'g-707'], ['g-37', 'g-228', 'g-202'], ['g-37', 'g-300', 'g-370'], ['g-234', 'g-508', 'g-595'], ['g-596', 'g-744', 'g-707'], ['g-300', 'g-227', 'g-591'], ['g-135', 'g-392', 'g-512'], ['g-731', 'g-744', 'g-158'], ['g-69', 'g-707', 'g-100'], ['g-276', 'g-653', 'g-291'], ['g-624', 'g-615', 'g-189'], ['g-181', 'g-707', 'g-38'], ['g-72', 'g-75', 'g-508'], ['g-231', 'g-707', 'g-392'], ['g-508', 'g-37', 'g-72'], ['g-725', 'g-712', 'g-640'], ['g-67', 'g-644', 'g-113'], ['g-508', 'g-228', 'g-656'], ['g-185', 'g-37', 'g-672'], ['g-370', 'g-50', 'g-503'], ['g-201', 'g-745', 'g-599'], ['g-332', 'g-50', 'g-571'], ['g-50', 'g-37', 'g-59'], ['g-508', 'g-113', 'g-231'], ['g-707', 'g-158', 'g-100'], ['g-257', 'g-50', 'g-72']]\n",
    "    \n",
    "for cols in prod_cols:\n",
    "    name = \"prod-\" + \" * \".join(cols)\n",
    "    train_df[name] = train_df[cols].mean(axis=1)\n",
    "    test_df[name] = test_df[cols].mean(axis=1)\n",
    "    pub_test_df[name] = pub_test_df[cols].mean(axis=1)\"\"\"\n",
    "\n",
    "PRODS = [col for col in train_df.columns if col.startswith(\"prod-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop cols num : 67\n",
      "agg\n"
     ]
    }
   ],
   "source": [
    "#out fold preprocessing\n",
    "\n",
    "#variance threshold\n",
    "\n",
    "VAR_THRESHOLD = 0.8\n",
    "drop_cols = []\n",
    "temp = pd.concat([train_df, pub_test_df])\n",
    "for col in BIOS+PRODS:\n",
    "    if temp[col].var() <= VAR_THRESHOLD:\n",
    "        drop_cols.append(col)\n",
    "\n",
    "print(\"drop cols num : {}\".format(len(drop_cols)))\n",
    "train_df.drop(columns=drop_cols, inplace=True)\n",
    "test_df.drop(columns=drop_cols, inplace=True)\n",
    "pub_test_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "GENES_ = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "CELLS_ = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
    "BIOS_ = GENES_ + CELLS_\n",
    "        \n",
    "del temp\n",
    "\n",
    "# onehot encode of categorical feature and drop\n",
    "drop_cols = [\"cp_time\", \"cp_dose\", \"time_dose\"]\n",
    "train_df = pd.concat([pd.get_dummies(train_df[\"time_dose\"], prefix=\"onehot\", drop_first=True), train_df.drop(drop_cols, axis=1) ], axis=1)\n",
    "test_df = pd.concat([pd.get_dummies(test_df[\"time_dose\"], prefix=\"onehot\", drop_first=True), test_df.drop(drop_cols, axis=1) ], axis=1)\n",
    "pub_test_df = pd.concat([pd.get_dummies(pub_test_df[\"time_dose\"], prefix=\"onehot\", drop_first=True), pub_test_df.drop(drop_cols, axis=1) ], axis=1)\n",
    "\n",
    "# aggregation feature\n",
    "print(\"agg\")\n",
    "for df in [train_df, pub_test_df, test_df]:\n",
    "    df[\"sum-g\"] = df[GENES_].sum(axis=1)\n",
    "    df[\"mean-g\"] = df[GENES_].mean(axis=1)\n",
    "    df[\"std-g\"] = df[GENES_].std(axis=1)\n",
    "    df[\"kurt-g\"] = df[GENES_].kurt(axis=1)\n",
    "    df[\"skew-g\"] = df[GENES_].skew(axis=1)\n",
    "    df[\"sum-c\"] = df[CELLS_].sum(axis=1)\n",
    "    df[\"mean-c\"] = df[CELLS_].mean(axis=1)\n",
    "    df[\"std-c\"] = df[CELLS_].std(axis=1)\n",
    "    df[\"kurt-c\"] = df[CELLS_].kurt(axis=1)\n",
    "    df[\"skew-c\"] = df[CELLS_].skew(axis=1)\n",
    "    df[\"sum-gc\"] = df[BIOS_].sum(axis=1)\n",
    "    df[\"mean-gc\"] = df[BIOS_].mean(axis=1)\n",
    "    df[\"std-gc\"] = df[BIOS_].std(axis=1)\n",
    "    df[\"kurt-gc\"] = df[BIOS_].kurt(axis=1)\n",
    "    df[\"skew-gc\"] = df[BIOS_].skew(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(\"sig_id\", axis=1)\n",
    "y_nonv = y_nonv.drop(\"sig_id\", axis=1).values\n",
    "y = y.drop(\"sig_id\", axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dateset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoAResNetDataset:\n",
    "    def __init__(self, features1, features2, targets):\n",
    "        self.features1 = features1\n",
    "        self.features2 = features2\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features1.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x1' : torch.tensor(self.features1[idx, :], dtype=torch.float),\n",
    "            'x2' : torch.tensor(self.features2[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestResNetDataset:\n",
    "    def __init__(self, features1, features2):\n",
    "        self.features1 = features1\n",
    "        self.features2 = features2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features1.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x1' : torch.tensor(self.features1[idx, :], dtype=torch.float),\n",
    "            'x2' : torch.tensor(self.features2[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs1, inputs2, targets = data['x1'].to(device), data['x2'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs1, inputs2)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if cycle\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs1, inputs2, targets = data['x1'].to(device), data['x2'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs1, inputs2)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for data in dataloader:\n",
    "        inputs1, inputs2 = data['x1'].to(device), data['x2'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs1, inputs2)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class Model(nn.Module):\n",
    "    def __init__(self, num_features1, num_features2, num_targets):\n",
    "        super(Model, self).__init__()\n",
    "        self.h1_1 = 512\n",
    "        self.h1_2 = 256\n",
    "        \n",
    "        self.h2_1 = num_features2+self.h1_2\n",
    "        self.h2_2 = 512\n",
    "        self.h2_3 = 256\n",
    "        \n",
    "        self.h3_1 = 256\n",
    "        \n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features1),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features1, self.h1_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h1_1),\n",
    "            nn.Linear(self.h1_1, self.h1_2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.h2_1),\n",
    "            nn.Dropout(0.30),\n",
    "            nn.Linear(self.h2_1, self.h2_2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_2),\n",
    "            nn.Linear(self.h2_2, self.h2_2),\n",
    "            nn.ELU(),            \n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_2),\n",
    "            nn.Linear(self.h2_2, self.h2_3),\n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_3),\n",
    "            nn.Linear(self.h2_3, self.h2_3),\n",
    "            nn.ELU(),            \n",
    "        )\n",
    "        self.head3 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Linear(self.h3_1, self.h3_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Linear(self.h3_1, num_targets),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(num_targets),\n",
    "            nn.Linear(num_targets, num_targets),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        input3 = self.head1(input1)\n",
    "        concat = torch.cat((input3, input2), dim=1)\n",
    "        input4 = self.head2(concat)\n",
    "        avg = torch.div(torch.add(input3, input4), 2)\n",
    "        \n",
    "        out = self.head3(avg)\n",
    "        \n",
    "        return out\n",
    "    \"\"\"\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features1, num_features2, num_targets):\n",
    "        super(Model, self).__init__()\n",
    "        self.h1_1 = 1024\n",
    "        self.h1_2 = 512  #\n",
    "        \n",
    "        self.h2_1 = num_features2+self.h1_2\n",
    "        self.h2_2 = 1024\n",
    "        self.h2_3 = 512  #\n",
    "        \n",
    "        self.h3_1 = 512\n",
    "        \n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features1),\n",
    "            nn.Linear(num_features1, self.h1_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h1_1),\n",
    "            nn.Dropout(0.45),\n",
    "            nn.Linear(self.h1_1, self.h1_2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.h2_1),\n",
    "            nn.Linear(self.h2_1, self.h2_2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_2),\n",
    "            nn.Dropout(0.45),\n",
    "            nn.Linear(self.h2_2, self.h2_2),\n",
    "            nn.ELU(),            \n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_2),\n",
    "            nn.Dropout(0.45),\n",
    "            nn.Linear(self.h2_2, self.h2_3),\n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_3),\n",
    "            nn.Dropout(0.45),\n",
    "            nn.Linear(self.h2_3, self.h2_3),\n",
    "            nn.ELU(),            \n",
    "        )\n",
    "        self.head3 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Dropout(0.45),\n",
    "            nn.Linear(self.h3_1, self.h3_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Linear(self.h3_1, self.h3_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Linear(self.h3_1, num_targets),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        input3 = self.head1(input1)\n",
    "        concat = torch.cat((input3, input2), dim=1)\n",
    "        input4 = self.head2(concat)\n",
    "        avg = torch.div(torch.add(input3, input4), 2)\n",
    "        \n",
    "        out = self.head3(avg)\n",
    "        \n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, trainloader, validloader, epoch_, optimizer, scheduler, loss_fn, loss_tr, early_stopping_steps, verbose, device, fold, seed):\n",
    "    \n",
    "    early_step = 0\n",
    "    best_loss = np.inf\n",
    "    best_epoch = 0\n",
    "    \n",
    "    start = time.time()\n",
    "    t = time.time() - start\n",
    "    for epoch in range(epoch_):\n",
    "        train_loss = train_fn(model, optimizer, scheduler, loss_tr, trainloader, device)\n",
    "        valid_loss = valid_fn(model, loss_fn, validloader, device)\n",
    "        # if ReduceLROnPlateau\n",
    "        #scheduler.step(valid_loss)\n",
    "        if epoch % verbose==0:\n",
    "            t = time.time() - start\n",
    "            print(f\"EPOCH: {epoch}, train_loss: {train_loss}, valid_loss: {valid_loss}, time: {t}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'resnet_weights/{}_{}.pt'.format(seed, fold))\n",
    "            #torch.save(model, 'dnn_weights/{}_{}.pt'.format(seed, fold))\n",
    "            early_step = 0\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        elif early_stopping_steps != 0:\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                t = time.time() - start\n",
    "                print(f\"early stopping in iteration {epoch},  : best itaration is {best_epoch}, valid loss is {best_loss}, time: {t}\")\n",
    "                return model\n",
    "    t = time.time() - start \n",
    "    print(f\"training until max epoch {epoch_},  : best itaration is {best_epoch}, valid loss is {best_loss}, time: {t}\")\n",
    "    return model\n",
    "            \n",
    "    \n",
    "def predict(model, testloader, device):\n",
    "    model.to(device)\n",
    "    predictions = inference_fn(model, testloader, device)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training by Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17584\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4694377307229451, valid_loss: 0.021487450546451976, time: 5.856710910797119\n",
      "EPOCH: 5, train_loss: 0.021223246534592913, valid_loss: 0.01839931370424373, time: 24.223227739334106\n",
      "EPOCH: 10, train_loss: 0.021200454297618274, valid_loss: 0.01835889361266579, time: 41.74117588996887\n",
      "EPOCH: 15, train_loss: 0.02046806350295996, valid_loss: 0.017957312054932117, time: 59.15132522583008\n",
      "EPOCH: 20, train_loss: 0.019242459962511584, valid_loss: 0.017561373274241177, time: 76.91962194442749\n",
      "training until max epoch 25,  : best itaration is 21, valid loss is 0.017340123653411865, time: 90.86381435394287\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17565\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4692256659486868, valid_loss: 0.02058689266975437, time: 3.302098274230957\n",
      "EPOCH: 5, train_loss: 0.021403426331651473, valid_loss: 0.017949399831039565, time: 21.009947299957275\n",
      "EPOCH: 10, train_loss: 0.021306372376797843, valid_loss: 0.018012854110981736, time: 38.667863607406616\n",
      "EPOCH: 15, train_loss: 0.020708776317047376, valid_loss: 0.017452070276652062, time: 56.73400568962097\n",
      "EPOCH: 20, train_loss: 0.01947193414679844, valid_loss: 0.016901760335479465, time: 74.35360765457153\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.016809548756905966, time: 88.58365058898926\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17534\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4712859012789148, valid_loss: 0.021662431742463795, time: 3.2421257495880127\n",
      "EPOCH: 5, train_loss: 0.02125932800802676, valid_loss: 0.01819866866405521, time: 20.69000816345215\n",
      "EPOCH: 10, train_loss: 0.02118789274519419, valid_loss: 0.01817194851381438, time: 38.56749773025513\n",
      "EPOCH: 15, train_loss: 0.02061103785629658, valid_loss: 0.017814418088112557, time: 55.939945697784424\n",
      "EPOCH: 20, train_loss: 0.019333328859990135, valid_loss: 0.017230587585696153, time: 73.22308850288391\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017090464622846673, time: 87.46518445014954\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17504\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4708253156037672, valid_loss: 0.021754877641797066, time: 3.309967041015625\n",
      "EPOCH: 5, train_loss: 0.021329883554512086, valid_loss: 0.01895992894257818, time: 21.218886375427246\n",
      "EPOCH: 10, train_loss: 0.021206731825847838, valid_loss: 0.01881822044295924, time: 38.54792046546936\n",
      "EPOCH: 15, train_loss: 0.02057321879136212, valid_loss: 0.01839404877807413, time: 55.83923816680908\n",
      "EPOCH: 20, train_loss: 0.019400177468710086, valid_loss: 0.017713450507393907, time: 73.42839574813843\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.01766529700585774, time: 87.52509832382202\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17605\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4687086659599177, valid_loss: 0.0216203047620023, time: 3.3309481143951416\n",
      "EPOCH: 5, train_loss: 0.02127755688924859, valid_loss: 0.01866001816576018, time: 21.020754098892212\n",
      "EPOCH: 10, train_loss: 0.021138459593601472, valid_loss: 0.018926634343669695, time: 38.5785858631134\n",
      "EPOCH: 15, train_loss: 0.020492517273791516, valid_loss: 0.018063041381537914, time: 56.323673725128174\n",
      "EPOCH: 20, train_loss: 0.019281600635961023, valid_loss: 0.017387141747509733, time: 73.80418372154236\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017322272719705805, time: 88.73236060142517\n",
      "seed 7 , cv score : 0.017310820237025657\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17551\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.46944651680651805, valid_loss: 0.02105767833335059, time: 3.298433542251587\n",
      "EPOCH: 5, train_loss: 0.02127952153121468, valid_loss: 0.019124229571649005, time: 20.983144998550415\n",
      "EPOCH: 10, train_loss: 0.021202231723352942, valid_loss: 0.018083505119596208, time: 39.19789242744446\n",
      "EPOCH: 15, train_loss: 0.020557787133394366, valid_loss: 0.01762633967612471, time: 56.79872107505798\n",
      "EPOCH: 20, train_loss: 0.019285621787727313, valid_loss: 0.017146977143628256, time: 74.51657152175903\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017083118962390082, time: 88.92782020568848\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17525\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47172962030505433, valid_loss: 0.021906103140541484, time: 4.083932638168335\n",
      "EPOCH: 5, train_loss: 0.021245977444135967, valid_loss: 0.018224230674760682, time: 21.724042415618896\n",
      "EPOCH: 10, train_loss: 0.021157576195786103, valid_loss: 0.01819078799869333, time: 39.17475724220276\n",
      "EPOCH: 15, train_loss: 0.02067099982763038, valid_loss: 0.017918294348887035, time: 56.930909633636475\n",
      "EPOCH: 20, train_loss: 0.019361024078748682, valid_loss: 0.01739503044102873, time: 75.42332053184509\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017288826991404806, time: 89.02957963943481\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17607\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47019439446230005, valid_loss: 0.021373755134203854, time: 3.2577173709869385\n",
      "EPOCH: 5, train_loss: 0.021201252665397893, valid_loss: 0.018787755384383834, time: 21.13531494140625\n",
      "EPOCH: 10, train_loss: 0.02119252397032985, valid_loss: 0.018642184708048317, time: 38.73504424095154\n",
      "EPOCH: 15, train_loss: 0.020507753398405375, valid_loss: 0.018294454141355613, time: 57.13083863258362\n",
      "EPOCH: 20, train_loss: 0.019283782378056624, valid_loss: 0.017836527734556618, time: 75.12609148025513\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017685517367413816, time: 89.33547186851501\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17550\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.46885219155164964, valid_loss: 0.020880934542843274, time: 3.6686911582946777\n",
      "EPOCH: 5, train_loss: 0.021296249294694324, valid_loss: 0.018396143934556415, time: 21.502641201019287\n",
      "EPOCH: 10, train_loss: 0.021224292144723184, valid_loss: 0.01833310568971293, time: 39.2192485332489\n",
      "EPOCH: 15, train_loss: 0.020596250021544686, valid_loss: 0.01779512491609369, time: 57.05319952964783\n",
      "EPOCH: 20, train_loss: 0.019350334743622445, valid_loss: 0.017287905115102017, time: 75.00924468040466\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017152047742690357, time: 89.53291940689087\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17559\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4694511750645011, valid_loss: 0.0210341500384467, time: 3.3534724712371826\n",
      "EPOCH: 5, train_loss: 0.021378591004079277, valid_loss: 0.018496993556618692, time: 20.98338222503662\n",
      "EPOCH: 10, train_loss: 0.02123892599594419, valid_loss: 0.01820531375706196, time: 38.80748128890991\n",
      "EPOCH: 15, train_loss: 0.020640072215647592, valid_loss: 0.01797733610229833, time: 55.750330209732056\n",
      "EPOCH: 20, train_loss: 0.019414714517167014, valid_loss: 0.017282359168997834, time: 73.76423382759094\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017131852677890233, time: 87.7878999710083\n",
      "seed 8 , cv score : 0.017305934699156054\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17498\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47245985837927196, valid_loss: 0.020943352952599525, time: 3.321072578430176\n",
      "EPOCH: 5, train_loss: 0.0213585017961176, valid_loss: 0.018361131314720426, time: 21.794846057891846\n",
      "EPOCH: 10, train_loss: 0.021243182476609945, valid_loss: 0.018023458548954555, time: 39.035062313079834\n",
      "EPOCH: 15, train_loss: 0.020674175952615982, valid_loss: 0.01761575931949275, time: 56.57636761665344\n",
      "EPOCH: 20, train_loss: 0.019503036390661317, valid_loss: 0.017252284261797157, time: 74.2046115398407\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017094005990241256, time: 88.52364015579224\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17606\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4697719915042611, valid_loss: 0.023495429633733106, time: 3.3049299716949463\n",
      "EPOCH: 5, train_loss: 0.021439896801309866, valid_loss: 0.01813866214498001, time: 20.22691559791565\n",
      "EPOCH: 10, train_loss: 0.021364052066185177, valid_loss: 0.018479371826876614, time: 37.64499616622925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15, train_loss: 0.020641604152909162, valid_loss: 0.017445248332532012, time: 55.13194251060486\n",
      "EPOCH: 20, train_loss: 0.01942501819427431, valid_loss: 0.01704418325029752, time: 72.9765989780426\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.016940455911133218, time: 87.92011094093323\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17595\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4694569824929655, valid_loss: 0.021489183232188225, time: 3.3637495040893555\n",
      "EPOCH: 5, train_loss: 0.0213659369543086, valid_loss: 0.018591551748769624, time: 21.21135187149048\n",
      "EPOCH: 10, train_loss: 0.021316560352370686, valid_loss: 0.01851958403629916, time: 39.44395923614502\n",
      "EPOCH: 15, train_loss: 0.020708528694010127, valid_loss: 0.01780521007520812, time: 57.203413248062134\n",
      "EPOCH: 20, train_loss: 0.019376850802532947, valid_loss: 0.017000470363668033, time: 75.02630710601807\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.01685239768454007, time: 89.50521755218506\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17512\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47189341281431124, valid_loss: 0.02247228505355971, time: 3.547865867614746\n",
      "EPOCH: 5, train_loss: 0.02122228194082923, valid_loss: 0.01929189184946673, time: 21.469597101211548\n",
      "EPOCH: 10, train_loss: 0.021056217908420983, valid_loss: 0.018583583565694946, time: 38.49018049240112\n",
      "EPOCH: 15, train_loss: 0.020535062888965887, valid_loss: 0.018324543961456843, time: 55.78070330619812\n",
      "EPOCH: 20, train_loss: 0.019333062679780758, valid_loss: 0.017690124522362436, time: 73.16668605804443\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017551537443484578, time: 87.50290942192078\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17581\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.46981456108989506, valid_loss: 0.02253809885254928, time: 3.4307374954223633\n",
      "EPOCH: 5, train_loss: 0.021302247120842447, valid_loss: 0.01893513442150184, time: 20.72258472442627\n",
      "EPOCH: 10, train_loss: 0.021033836039204667, valid_loss: 0.018794553593865462, time: 37.94888639450073\n",
      "EPOCH: 15, train_loss: 0.02050146686225912, valid_loss: 0.018421225914997712, time: 55.69646739959717\n",
      "EPOCH: 20, train_loss: 0.019277860757208217, valid_loss: 0.01795145563249077, time: 73.2614676952362\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017833692474024637, time: 87.52959823608398\n",
      "seed 9 , cv score : 0.017312496612136345\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17540\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4699239867338299, valid_loss: 0.021563552053911344, time: 3.480708599090576\n",
      "EPOCH: 5, train_loss: 0.021324563676314634, valid_loss: 0.018545219461832727, time: 21.099311113357544\n",
      "EPOCH: 10, train_loss: 0.021303809445052252, valid_loss: 0.018120596132108143, time: 39.04904794692993\n",
      "EPOCH: 15, train_loss: 0.020454675054354388, valid_loss: 0.017902313518737042, time: 56.286715030670166\n",
      "EPOCH: 20, train_loss: 0.01938331336544378, valid_loss: 0.01719528412712472, time: 73.84949350357056\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017094821935253485, time: 87.60376214981079\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17562\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.46787769333833323, valid_loss: 0.020841438163604054, time: 3.4570038318634033\n",
      "EPOCH: 5, train_loss: 0.021357743327852584, valid_loss: 0.018615231796034745, time: 21.770533084869385\n",
      "EPOCH: 10, train_loss: 0.021168794482946396, valid_loss: 0.018185047964964594, time: 39.58043909072876\n",
      "EPOCH: 15, train_loss: 0.02055785130627834, valid_loss: 0.01770940651851041, time: 57.354069232940674\n",
      "EPOCH: 20, train_loss: 0.019290627449424596, valid_loss: 0.017287579817431314, time: 75.39602899551392\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017261018444384848, time: 89.61332654953003\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17535\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.46956028865979, valid_loss: 0.020893811753817968, time: 3.82949161529541\n",
      "EPOCH: 5, train_loss: 0.02121943362769397, valid_loss: 0.01850307248532772, time: 21.37199592590332\n",
      "EPOCH: 10, train_loss: 0.021177461329738006, valid_loss: 0.018234784581831524, time: 39.11963176727295\n",
      "EPOCH: 15, train_loss: 0.020510030417319608, valid_loss: 0.017952062961246285, time: 57.355242013931274\n",
      "EPOCH: 20, train_loss: 0.01929862708236803, valid_loss: 0.01746750721441848, time: 75.57835984230042\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017352598692689625, time: 89.87789583206177\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17562\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.46975227461679137, valid_loss: 0.020802024166498866, time: 3.4609789848327637\n",
      "EPOCH: 5, train_loss: 0.02124307387556038, valid_loss: 0.019041114593190807, time: 21.7037136554718\n",
      "EPOCH: 10, train_loss: 0.02115188075406273, valid_loss: 0.018285842266465936, time: 39.3249249458313\n",
      "EPOCH: 15, train_loss: 0.020566539213496403, valid_loss: 0.017897919113082545, time: 57.19063711166382\n",
      "EPOCH: 20, train_loss: 0.01925888804406145, valid_loss: 0.017237902565726212, time: 75.23653054237366\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017111051880887577, time: 90.02939319610596\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17593\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.46881195092505784, valid_loss: 0.022037727385759355, time: 3.3138530254364014\n",
      "EPOCH: 5, train_loss: 0.02125147515296066, valid_loss: 0.019144005195370743, time: 21.216689825057983\n",
      "EPOCH: 10, train_loss: 0.021110205863514087, valid_loss: 0.018977032149476665, time: 39.11121988296509\n",
      "EPOCH: 15, train_loss: 0.02052098822637196, valid_loss: 0.01841311806014606, time: 56.85862755775452\n",
      "EPOCH: 20, train_loss: 0.019358261250448924, valid_loss: 0.017833466748041767, time: 73.95922708511353\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.017657050703253064, time: 88.35690379142761\n",
      "seed 10 , cv score : 0.01730548604342763\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17532\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4716296408955446, valid_loss: 0.021654798462986947, time: 3.6588551998138428\n",
      "EPOCH: 5, train_loss: 0.02135112081818721, valid_loss: 0.01854720091713326, time: 20.539958238601685\n",
      "EPOCH: 10, train_loss: 0.02115907785756623, valid_loss: 0.018350196150796753, time: 38.17548990249634\n",
      "EPOCH: 15, train_loss: 0.02062636404298246, valid_loss: 0.01776567218559129, time: 55.67029023170471\n",
      "EPOCH: 20, train_loss: 0.019419868586256224, valid_loss: 0.017362882010638715, time: 73.01206874847412\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017175900882908275, time: 87.82541346549988\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17589\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47012097249827245, valid_loss: 0.021114692145160267, time: 3.3481082916259766\n",
      "EPOCH: 5, train_loss: 0.021211938878154233, valid_loss: 0.018695519199328763, time: 21.284842014312744\n",
      "EPOCH: 10, train_loss: 0.021153805423935836, valid_loss: 0.018236300695155347, time: 39.52972745895386\n",
      "EPOCH: 15, train_loss: 0.020503001817821585, valid_loss: 0.017908656623746667, time: 57.6187949180603\n",
      "EPOCH: 20, train_loss: 0.019241630079319876, valid_loss: 0.017384908986943108, time: 75.87239074707031\n",
      "training until max epoch 25,  : best itaration is 22, valid loss is 0.01721930205821991, time: 90.23235177993774\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17567\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4694025454376518, valid_loss: 0.020808380522898264, time: 3.9492218494415283\n",
      "EPOCH: 5, train_loss: 0.02134977732479137, valid_loss: 0.018526660384876388, time: 22.1021511554718\n",
      "EPOCH: 10, train_loss: 0.02122221592079549, valid_loss: 0.01830945004309927, time: 38.90956974029541\n",
      "EPOCH: 15, train_loss: 0.020619893541736323, valid_loss: 0.01773716990969011, time: 56.64951682090759\n",
      "EPOCH: 20, train_loss: 0.01938885518342909, valid_loss: 0.017307441628405026, time: 74.70006847381592\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017189691056098258, time: 88.92524361610413\n",
      "======================== fold 4 ========================\n",
      "quantile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "17537\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47038447586343674, valid_loss: 0.020970758742519788, time: 3.315481185913086\n",
      "EPOCH: 5, train_loss: 0.021296065912520798, valid_loss: 0.018257283685462814, time: 21.65800952911377\n",
      "EPOCH: 10, train_loss: 0.021222781743446405, valid_loss: 0.01825995503791741, time: 39.029476165771484\n",
      "EPOCH: 15, train_loss: 0.020570263552078364, valid_loss: 0.01780661360493728, time: 57.07944917678833\n",
      "EPOCH: 20, train_loss: 0.019320333063819983, valid_loss: 0.01727658249437809, time: 75.51666569709778\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017168763226696422, time: 90.55651021003723\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17567\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47028640336798927, valid_loss: 0.02151911681784051, time: 3.3170018196105957\n",
      "EPOCH: 5, train_loss: 0.021289461135973027, valid_loss: 0.01863963593329702, time: 22.045066595077515\n",
      "EPOCH: 10, train_loss: 0.021260988293555532, valid_loss: 0.018322679001305783, time: 40.58185338973999\n",
      "EPOCH: 15, train_loss: 0.020648621974417764, valid_loss: 0.01801661319498505, time: 58.905386209487915\n",
      "EPOCH: 20, train_loss: 0.019514428274909946, valid_loss: 0.01742673223572118, time: 76.83837699890137\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017287612679813588, time: 91.42620062828064\n",
      "seed 11 , cv score : 0.01732474034587053\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17589\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4707476357881823, valid_loss: 0.020887012407183648, time: 3.8309237957000732\n",
      "EPOCH: 5, train_loss: 0.021283111038760547, valid_loss: 0.01861422048615558, time: 21.586501121520996\n",
      "EPOCH: 10, train_loss: 0.021188805913076782, valid_loss: 0.01812726855278015, time: 39.95713424682617\n",
      "EPOCH: 15, train_loss: 0.020610641552148944, valid_loss: 0.017934186730001654, time: 57.83187651634216\n",
      "EPOCH: 20, train_loss: 0.01935247964069356, valid_loss: 0.017354806911732468, time: 76.07301259040833\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.017234369340751853, time: 90.39585185050964\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17558\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4684020538209346, valid_loss: 0.022365824399249893, time: 3.4016408920288086\n",
      "EPOCH: 5, train_loss: 0.02135208595788827, valid_loss: 0.01899079882672855, time: 21.92463183403015\n",
      "EPOCH: 10, train_loss: 0.021128719074338893, valid_loss: 0.018547960264342172, time: 40.15045189857483\n",
      "EPOCH: 15, train_loss: 0.020611612765240844, valid_loss: 0.018095834659678595, time: 57.84092140197754\n",
      "EPOCH: 20, train_loss: 0.019295046364303924, valid_loss: 0.01776450201869011, time: 76.22309517860413\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017645637637802532, time: 90.96644496917725\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17562\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47097992795064064, valid_loss: 0.0213440938187497, time: 3.2752509117126465\n",
      "EPOCH: 5, train_loss: 0.02131139034282987, valid_loss: 0.018279275138463294, time: 21.875277280807495\n",
      "EPOCH: 10, train_loss: 0.021363631788178954, valid_loss: 0.018374685464160784, time: 39.383031129837036\n",
      "EPOCH: 15, train_loss: 0.02072693113863033, valid_loss: 0.017896703843559538, time: 56.78740668296814\n",
      "EPOCH: 20, train_loss: 0.019431552611780863, valid_loss: 0.017315745327089516, time: 73.87633037567139\n",
      "training until max epoch 25,  : best itaration is 24, valid loss is 0.01714748931782586, time: 88.66268610954285\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17492\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47214203526485055, valid_loss: 0.02072246910205909, time: 4.057483911514282\n",
      "EPOCH: 5, train_loss: 0.021301727961091435, valid_loss: 0.01817678492516279, time: 21.718540906906128\n",
      "EPOCH: 10, train_loss: 0.021209623404395056, valid_loss: 0.01825197147471564, time: 40.10648989677429\n",
      "EPOCH: 15, train_loss: 0.020592372152296937, valid_loss: 0.01790789089032582, time: 58.276588916778564\n",
      "EPOCH: 20, train_loss: 0.019410434836412176, valid_loss: 0.017319955437311105, time: 76.45109677314758\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017173933424055578, time: 90.87239575386047\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17591\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.46971478318646004, valid_loss: 0.02126171152506556, time: 3.6765336990356445\n",
      "EPOCH: 5, train_loss: 0.0213021155392384, valid_loss: 0.018092814487005983, time: 22.073567152023315\n",
      "EPOCH: 10, train_loss: 0.021188633516430855, valid_loss: 0.018141877092421054, time: 40.28277325630188\n",
      "EPOCH: 15, train_loss: 0.02059609453826055, valid_loss: 0.017795510084501334, time: 57.839393854141235\n",
      "EPOCH: 20, train_loss: 0.01933725087148865, valid_loss: 0.017108786372201784, time: 76.26700901985168\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.01691804996558598, time: 91.21965980529785\n",
      "seed 12 , cv score : 0.017300591219918608\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "17573\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4691837276909908, valid_loss: 0.02085088182772909, time: 3.357579231262207\n",
      "EPOCH: 5, train_loss: 0.021229642191833823, valid_loss: 0.018612012586423327, time: 21.92131233215332\n",
      "EPOCH: 10, train_loss: 0.021174974277289243, valid_loss: 0.018477750409926687, time: 40.258283376693726\n",
      "EPOCH: 15, train_loss: 0.020575151119354, valid_loss: 0.018340341267841204, time: 58.80544638633728\n",
      "EPOCH: 20, train_loss: 0.01933717854103468, valid_loss: 0.017578345856496265, time: 77.08752870559692\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.0174538128344076, time: 91.5482566356659\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "17630\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.4704998589807401, valid_loss: 0.020348309867960566, time: 3.8537979125976562\n",
      "EPOCH: 5, train_loss: 0.021416891855697562, valid_loss: 0.01831402087255436, time: 22.284712314605713\n",
      "EPOCH: 10, train_loss: 0.021292927967262093, valid_loss: 0.01798723775016911, time: 40.1005756855011\n",
      "EPOCH: 15, train_loss: 0.020663720657573128, valid_loss: 0.017245231196284294, time: 57.92248558998108\n",
      "EPOCH: 20, train_loss: 0.01945837625186809, valid_loss: 0.01676675507470089, time: 76.35521578788757\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.01658440614119172, time: 90.74217748641968\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "17512\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47099592306596394, valid_loss: 0.021264110665236202, time: 3.2970035076141357\n",
      "EPOCH: 5, train_loss: 0.021293651079759, valid_loss: 0.019048803565757614, time: 21.70989990234375\n",
      "EPOCH: 10, train_loss: 0.02113205147907138, valid_loss: 0.01849469111434051, time: 39.65138125419617\n",
      "EPOCH: 15, train_loss: 0.020574605092406273, valid_loss: 0.01808027672980513, time: 57.60090208053589\n",
      "EPOCH: 20, train_loss: 0.019370087819612202, valid_loss: 0.01760319795991693, time: 74.72765779495239\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.017403975581484182, time: 89.48438835144043\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "17565\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47024980361444235, valid_loss: 0.02183589371187346, time: 3.366933822631836\n",
      "EPOCH: 5, train_loss: 0.02127164746396733, valid_loss: 0.019062759727239607, time: 21.04669761657715\n",
      "EPOCH: 10, train_loss: 0.02105717401761208, valid_loss: 0.01872735396027565, time: 38.750003814697266\n",
      "EPOCH: 15, train_loss: 0.020490695280532767, valid_loss: 0.01832051846597876, time: 55.8718044757843\n",
      "EPOCH: 20, train_loss: 0.019179713443247943, valid_loss: 0.017777912292097298, time: 73.45577454566956\n",
      "training until max epoch 25,  : best itaration is 21, valid loss is 0.01768894943275622, time: 88.35017466545105\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "17512\n",
      "915\n",
      "915\n",
      "EPOCH: 0, train_loss: 0.47121093272888925, valid_loss: 0.021101658152682442, time: 3.1692872047424316\n",
      "EPOCH: 5, train_loss: 0.021230151602888808, valid_loss: 0.018213476559945516, time: 20.631686449050903\n",
      "EPOCH: 10, train_loss: 0.021268916535465157, valid_loss: 0.018732101576668877, time: 38.28666567802429\n",
      "EPOCH: 15, train_loss: 0.020675121587427223, valid_loss: 0.018123600871435233, time: 55.49418640136719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20, train_loss: 0.019373996607849702, valid_loss: 0.01738066521606275, time: 73.2342803478241\n",
      "training until max epoch 25,  : best itaration is 23, valid loss is 0.01723500868039472, time: 87.19083499908447\n",
      "seed 13 , cv score : 0.0173115250690438\n",
      "cv score : 0.017054597698718785\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "DEVICE = ('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 25\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "\n",
    "train_preds = np.zeros((X.shape[0], y_nonv.shape[1]))\n",
    "preds = np.zeros((test_df.shape[0], y_nonv.shape[1]))\n",
    "imps = []\n",
    "imp_cols = []\n",
    "folds = []\n",
    "test_cv_preds = []\n",
    "\n",
    "for seed in seeds:\n",
    "    seed_everything(seed)\n",
    "    K = 5\n",
    "    kf = MultilabelStratifiedKFold(n_splits=K, random_state=seed, shuffle=True)\n",
    "    train_pred = np.zeros(train_preds.shape)\n",
    "    \n",
    "    \n",
    "    ###############################################################################################\n",
    "    # LOAD LIBRARIES\n",
    "    targets = SCORED_MOAS.copy()\n",
    "\n",
    "    # LOCATE DRUGS\n",
    "    vc = scored[\"drug_id\"].value_counts()\n",
    "    vc1 = vc.loc[vc<=18].index.sort_values()\n",
    "    vc2 = vc.loc[vc>18].index.sort_values()\n",
    "\n",
    "    # STRATIFY DRUGS 18X OR LESS\n",
    "    dct1 = {}; dct2 = {}\n",
    "    skf = MultilabelStratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "    tmp = scored.groupby('drug_id')[targets].mean().loc[vc1]\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.index[idxV].values} # drug id がどのフォールドに属すか格納\n",
    "        dct1.update(dd)\n",
    "\n",
    "    # STRATIFY DRUGS MORE THAN 18X\n",
    "    skf = MultilabelStratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "    tmp = scored.loc[scored[\"drug_id\"].isin(vc2)].reset_index(drop=True)\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp[\"sig_id\"][idxV].values}\n",
    "        dct2.update(dd)\n",
    "\n",
    "    # ASSIGN K\n",
    "    scored['fold'] = scored.drug_id.map(dct1)\n",
    "    scored.loc[scored[\"fold\"].isna(),'fold'] = scored.loc[scored[\"fold\"].isna(),'sig_id'].map(dct2)\n",
    "    scored[\"fold\"] = scored[\"fold\"].astype('int8')\n",
    "    ###############################################################################################\n",
    "\n",
    "    #for fold, (train_index, valid_index) in enumerate(kf.split(X, y_nonv)):    \n",
    "    for fold in range(K):\n",
    "        train_index = scored[scored[\"fold\"] != fold].index.to_list()\n",
    "        valid_index = scored[scored[\"fold\"] == fold].index.to_list()\n",
    "        print(\"======================== fold {} ========================\".format(fold+1))\n",
    "        folds.append(train_index)\n",
    "                \n",
    "        # split data\n",
    "        train_X = X.iloc[train_index]\n",
    "        train_y = y_nonv[train_index]\n",
    "        valid_X = X.iloc[valid_index]\n",
    "        valid_y = y_nonv[valid_index]\n",
    "        test_X = (test_df.drop(\"sig_id\", axis=1))\n",
    "        pub_test_X = (pub_test_df.drop(\"sig_id\", axis=1))\n",
    "        \n",
    "        \n",
    "\n",
    "        # scaler\n",
    "        print(SCALE)\n",
    "        scale_cols = BIOS_+PRODS\n",
    "        scaler = make_scaler(SCALE, seed).fit(train_X.append(pub_test_X)[scale_cols])\n",
    "        for df in [train_X, valid_X, test_X, pub_test_X]:\n",
    "            df[scale_cols] = scaler.transform(df[scale_cols])\n",
    "            \n",
    "            \n",
    "        print(\"PCA\")\n",
    "        #PCA\n",
    "        n_decom_g = 80\n",
    "        n_decom_c = 10\n",
    "        decom_g_cols = [f\"pca_g-{i}\" for i in range(n_decom_g)]\n",
    "        decom_c_cols = [f\"pca_c-{i}\" for i in range(n_decom_c)]\n",
    "        \n",
    "        pca_g = PCA(n_components = n_decom_g, random_state = seed).fit(train_X.append(pub_test_X)[GENES_])\n",
    "        pca_c = PCA(n_components = n_decom_c, random_state = seed).fit(train_X.append(pub_test_X)[CELLS_])\n",
    "        \n",
    "        for df in [train_X, valid_X, test_X, pub_test_X]:\n",
    "            df[decom_g_cols] = pca_g.transform(df[GENES_])\n",
    "            df[decom_c_cols] = pca_c.transform(df[CELLS_])\n",
    "            #df.drop(GENES_+CELLS_, axis=1, inplace=True) \n",
    "            \n",
    "        \n",
    "        print(train_X.shape[0])\n",
    "        # prepare data for training\n",
    "        train_X1 = train_X.values\n",
    "        train_X2 = train_X.values\n",
    "        valid_X1 = valid_X.values\n",
    "        valid_X2 = valid_X.values\n",
    "        test_X1 = test_X.values\n",
    "        test_X2 = test_X.values\n",
    "        print(train_X1.shape[1])\n",
    "        print(train_X2.shape[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ================================model training===========================\n",
    "        train_dataset = MoAResNetDataset(train_X1, train_X2, train_y)\n",
    "        valid_dataset = MoAResNetDataset(valid_X1, valid_X2, valid_y)\n",
    "        test_dataset = TestResNetDataset(test_X1, test_X2)\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "        model = Model(\n",
    "            num_features1=train_X1.shape[1],\n",
    "            num_features2=train_X2.shape[1],\n",
    "            num_targets=train_y.shape[1],\n",
    "        )\n",
    "\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        \n",
    "        optimizer = torch.optim.Adam( model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY,)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,pct_start=0.1, div_factor=1e3, max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader) )\n",
    "        #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode = \"min\", patience = 3, min_lr = 1e-5, factor = 0.1, eps=1e-5)\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss_tr = SmoothBCEwLogits(smoothing=1e-3)\n",
    "        \n",
    "        \n",
    "        # train\n",
    "        model = run_training(\n",
    "            model=model,\n",
    "            trainloader=trainloader,\n",
    "            validloader=validloader,\n",
    "            epoch_=EPOCHS,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            loss_fn=loss_fn,\n",
    "            loss_tr=loss_tr,\n",
    "            early_stopping_steps=EARLY_STOPPING_STEPS,\n",
    "            device=DEVICE,\n",
    "            verbose=5,\n",
    "            fold=fold,\n",
    "            seed=seed,)\n",
    "        #model = torch.load('dnn_weights/{}_{}.pt'.format(seed, fold))\n",
    "        model.load_state_dict(torch.load('resnet_weights/{}_{}.pt'.format(seed, fold)))\n",
    "        \n",
    "        #valid predict\n",
    "        val_preds = predict(\n",
    "            model=model,\n",
    "            testloader=validloader,\n",
    "            device=DEVICE,)\n",
    "        \n",
    "        #test predict\n",
    "        test_preds = predict(\n",
    "            model=model,\n",
    "            testloader=testloader,\n",
    "            device=DEVICE)\n",
    "        \n",
    "        # ================================model training===========================\n",
    "\n",
    "        train_pred[valid_index] +=  val_preds\n",
    "        \n",
    "        preds += test_preds / (K*len(seeds))\n",
    "        \n",
    "        #name = \"{}_{}\".format(seed, fold)\n",
    "        #model.save_model(\"tabnet_weights_inf/\"+name)\n",
    "        #imps.append(model.feature_importances_)\n",
    "\n",
    "    print(\"seed {} , cv score : {}\".format(seed, metric(y_nonv, train_pred)))\n",
    "    train_preds += train_pred/len(seeds)\n",
    "\n",
    "print(\"cv score : {}\".format(metric(y_nonv, train_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score : 0.01571824600199386\n"
     ]
    }
   ],
   "source": [
    "train_preds2 = np.zeros((TR_SIZE,  y.shape[1]))\n",
    "train_preds2[train_nonvehicle_index] = train_preds\n",
    "\n",
    "\n",
    "preds2 = np.zeros((TE_SIZE, y.shape[1]))\n",
    "preds2[test_nonvehicle_index] = preds\n",
    "\n",
    "print(\"cv score : {}\".format(metric(y, train_preds2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../../../Data/Raw/sample_submission.csv\")\n",
    "#sub_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n",
    "cols = [col for col in sub_df.columns if col != \"sig_id\"]\n",
    "sub_df[cols] = preds2\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub = pd.read_csv(\"../../../Data/Raw/train_targets_scored.csv\")\n",
    "cols = [col for col in train_sub.columns if col != \"sig_id\"]\n",
    "train_sub[cols] = train_preds2\n",
    "train_sub.to_csv(\"train_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: resnet_weights/10_0.pt (deflated 3%)\n",
      "updating: resnet_weights/10_1.pt (deflated 3%)\n",
      "updating: resnet_weights/10_2.pt (deflated 3%)\n",
      "updating: resnet_weights/10_3.pt (deflated 3%)\n",
      "updating: resnet_weights/10_4.pt (deflated 3%)\n",
      "updating: resnet_weights/11_0.pt (deflated 3%)\n",
      "updating: resnet_weights/11_1.pt (deflated 3%)\n",
      "updating: resnet_weights/11_2.pt (deflated 3%)\n",
      "updating: resnet_weights/11_3.pt (deflated 3%)\n",
      "updating: resnet_weights/11_4.pt (deflated 3%)\n",
      "updating: resnet_weights/12_0.pt (deflated 3%)\n",
      "updating: resnet_weights/12_1.pt (deflated 3%)\n",
      "updating: resnet_weights/12_2.pt (deflated 3%)\n",
      "updating: resnet_weights/12_3.pt (deflated 3%)\n",
      "updating: resnet_weights/12_4.pt (deflated 3%)\n",
      "updating: resnet_weights/13_0.pt (deflated 3%)\n",
      "updating: resnet_weights/13_1.pt (deflated 3%)\n",
      "updating: resnet_weights/13_2.pt (deflated 3%)\n",
      "updating: resnet_weights/13_3.pt (deflated 3%)\n",
      "updating: resnet_weights/13_4.pt (deflated 3%)\n",
      "updating: resnet_weights/7_0.pt (deflated 3%)\n",
      "updating: resnet_weights/7_1.pt (deflated 3%)\n",
      "updating: resnet_weights/7_2.pt (deflated 3%)\n",
      "updating: resnet_weights/7_3.pt (deflated 3%)\n",
      "updating: resnet_weights/7_4.pt (deflated 3%)\n",
      "updating: resnet_weights/8_0.pt (deflated 3%)\n",
      "updating: resnet_weights/8_1.pt (deflated 3%)\n",
      "updating: resnet_weights/8_2.pt (deflated 3%)\n",
      "updating: resnet_weights/8_3.pt (deflated 3%)\n",
      "updating: resnet_weights/8_4.pt (deflated 3%)\n",
      "updating: resnet_weights/9_0.pt (deflated 3%)\n",
      "updating: resnet_weights/9_1.pt (deflated 3%)\n",
      "updating: resnet_weights/9_2.pt (deflated 3%)\n",
      "updating: resnet_weights/9_3.pt (deflated 3%)\n",
      "updating: resnet_weights/9_4.pt (deflated 3%)\n"
     ]
    }
   ],
   "source": [
    "!zip resnet_weights.zip resnet_weights/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
