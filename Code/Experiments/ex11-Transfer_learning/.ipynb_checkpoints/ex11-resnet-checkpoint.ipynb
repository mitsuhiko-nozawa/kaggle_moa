{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, random, os, sys, tqdm, time\n",
    "sys.path.append(\"../\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer, RobustScaler\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1200)\n",
    "pd.set_option(\"display.max_rows\", 1200)\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    res = []\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        y = y_true[:,i]\n",
    "        pred = y_pred[:,i]\n",
    "        print(i)\n",
    "        res.append(log_loss(y, pred))\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    res = []\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        y = y_true[:,i]\n",
    "        pred = y_pred[:,i]\n",
    "        if np.sum(pred) <= 0.0:\n",
    "            pre += 1e-15\n",
    "        res.append(log_loss(y, pred))\n",
    "    return np.mean(res)\n",
    "\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "seed_everything(42)\n",
    "        \n",
    "    \n",
    "def make_scaler(flag, seed):\n",
    "    if flag == \"quantile\":\n",
    "        return QuantileTransformer(n_quantiles=100,random_state=seed, output_distribution=\"normal\")\n",
    "    elif flag == \"gauss\":\n",
    "        return GaussRankScaler()\n",
    "    elif flag == \"standard\":\n",
    "        return StandardScaler()\n",
    "    elif flag == \"minmax\":\n",
    "        return MinMaxScaler()\n",
    "    elif flag == \"robust\":\n",
    "        return RobustScaler()\n",
    "    \n",
    "seeds = [7, 8, 9, 10, 110, 12, 13]\n",
    "SCALE = \"quantile\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g772, c100, 206クラス、402クラスの分類\n",
    "\n",
    "train_df = pd.read_csv(\"../../../Data/Raw/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../../../Data/Raw/test_features.csv\")\n",
    "#pub_test_df = pd.read_csv(\"../input/moapublictest/test_features.csv\")\n",
    "pub_test_df = pd.read_csv(\"../../../Data/Raw/test_features.csv\")\n",
    "drug_df = pd.read_csv(\"../../../Data/Raw/train_drug.csv\")#\n",
    "\n",
    "y = pd.read_csv(\"../../../Data/Raw/train_targets_scored.csv\")\n",
    "y_non = pd.read_csv(\"../../../Data/Raw/train_targets_nonscored.csv\")\n",
    "y_all = pd.concat([y, y_non.drop(\"sig_id\", axis=1)], axis=1)\n",
    "y = y.merge(drug_df, on='sig_id', how='left') #\n",
    "\n",
    "GENES = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "CELLS = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
    "BIOS = GENES + CELLS\n",
    "\n",
    "\n",
    "SCORED_MOAS = [col for col in y.columns if col != \"sig_id\" and col != \"drug_id\"]#\n",
    "NONSCORED_MOAS = [col for col in y_non.columns if col != \"sig_id\"]\n",
    "ALL_MOAS = SCORED_MOAS + NONSCORED_MOAS\n",
    "\n",
    "\n",
    "TR_SIZE = train_df.shape[0]\n",
    "TE_SIZE = test_df.shape[0]\n",
    "\n",
    "train_nonvehicle_index = train_df[train_df[\"cp_type\"] != \"ctl_vehicle\"].index\n",
    "test_nonvehicle_index = test_df[test_df[\"cp_type\"] != \"ctl_vehicle\"].index\n",
    "\n",
    "train_df[\"time_dose\"] = train_df[\"cp_time\"].astype(str) + \" * \" + train_df[\"cp_dose\"]\n",
    "test_df[\"time_dose\"] = test_df[\"cp_time\"].astype(str) + \" * \" + test_df[\"cp_dose\"]\n",
    "pub_test_df[\"time_dose\"] = pub_test_df[\"cp_time\"].astype(str) + \" * \" + pub_test_df[\"cp_dose\"]\n",
    "\n",
    "# remove cp_type = ctl_vehicle\n",
    "mask = train_df[\"cp_type\"] != \"ctl_vehicle\"\n",
    "train_df = train_df[mask].drop(\"cp_type\", axis=1).reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cp_type\"] != \"ctl_vehicle\"].drop(\"cp_type\", axis=1).reset_index(drop=True)\n",
    "pub_test_df = pub_test_df[pub_test_df[\"cp_type\"] != \"ctl_vehicle\"].drop(\"cp_type\", axis=1).reset_index(drop=True)\n",
    "y_nonv = y[mask].reset_index(drop=True)#\n",
    "y_all_nonv = y_all[mask].reset_index(drop=True)\n",
    "\n",
    "scored = y_nonv.copy()#\n",
    "y_nonv.drop(\"drug_id\", axis=1, inplace=True)#\n",
    "y.drop(\"drug_id\", axis=1, inplace=True)#\n",
    "\n",
    "TR_NONV_SIZE = train_df.shape[0]\n",
    "TE_NONV_SHAPE = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# prod\n",
    "# 上位500こ\n",
    "prod_cols = [['g-145', 'g-201', 'g-208'], ['g-370', 'g-508', 'g-37'], ['g-38', 'g-392', 'g-707'], ['g-328', 'g-28', 'g-392'], ['g-441', 'g-157', 'g-392'], ['g-181', 'g-100', 'g-392'], ['g-67', 'g-760', 'g-50'], ['g-731', 'g-100', 'g-707'], ['g-478', 'g-468', 'g-310'], ['g-91', 'g-145', 'g-208'], ['g-106', 'g-744', 'g-91'], ['g-131', 'g-208', 'g-392'], ['g-144', 'g-123', 'g-86'], ['g-228', 'g-72', 'g-67'], ['g-31', 'g-328', 'g-460'], ['g-392', 'g-731', 'g-100'], ['g-732', 'g-744', 'g-707'], ['g-705', 'g-375', 'g-704'], ['g-508', 'g-50', 'g-411'], ['g-234', 'g-58', 'g-520'], ['g-503', 'g-761', 'g-50'], ['g-113', 'g-75', 'g-178'], ['g-50', 'g-508', 'g-113'], ['g-113', 'g-375', 'g-75'], ['g-576', 'g-452', 'g-392'], ['g-50', 'g-37', 'g-36'], ['g-707', 'g-133', 'g-392'], ['g-484', 'g-392', 'g-544'], ['g-508', 'g-67', 'g-370'], ['g-123', 'g-731', 'g-100'], ['g-298', 'g-477', 'g-644'], ['g-72', 'g-370', 'g-50'], ['g-67', 'g-178', 'g-113'], ['g-744', 'g-608', 'g-100'], ['g-91', 'g-100', 'g-707'], ['g-37', 'g-228', 'g-202'], ['g-37', 'g-300', 'g-370'], ['g-234', 'g-508', 'g-595'], ['g-596', 'g-744', 'g-707'], ['g-300', 'g-227', 'g-591'], ['g-135', 'g-392', 'g-512'], ['g-731', 'g-744', 'g-158'], ['g-69', 'g-707', 'g-100'], ['g-276', 'g-653', 'g-291'], ['g-624', 'g-615', 'g-189'], ['g-181', 'g-707', 'g-38'], ['g-72', 'g-75', 'g-508'], ['g-231', 'g-707', 'g-392'], ['g-508', 'g-37', 'g-72'], ['g-725', 'g-712', 'g-640'], ['g-67', 'g-644', 'g-113'], ['g-508', 'g-228', 'g-656'], ['g-185', 'g-37', 'g-672'], ['g-370', 'g-50', 'g-503'], ['g-201', 'g-745', 'g-599'], ['g-332', 'g-50', 'g-571'], ['g-50', 'g-37', 'g-59'], ['g-508', 'g-113', 'g-231'], ['g-707', 'g-158', 'g-100'], ['g-257', 'g-50', 'g-72']]\n",
    "\n",
    "for cols in prod_cols:\n",
    "    name = \"prod-\" + \" * \".join(cols)\n",
    "    train_df[name] = train_df[cols].mean(axis=1)\n",
    "    test_df[name] = test_df[cols].mean(axis=1)\n",
    "    pub_test_df[name] = pub_test_df[cols].mean(axis=1)\"\"\"\n",
    "\n",
    "PRODS = [col for col in train_df.columns if col.startswith(\"prod-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop cols num : 67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# aggregation feature\\nprint(\"agg\")\\nfor df in [train_df, pub_test_df, test_df]:\\n    df[\"sum-g\"] = df[GENES_].sum(axis=1)\\n    df[\"mean-g\"] = df[GENES_].mean(axis=1)\\n    df[\"std-g\"] = df[GENES_].std(axis=1)\\n    df[\"kurt-g\"] = df[GENES_].kurt(axis=1)\\n    df[\"skew-g\"] = df[GENES_].skew(axis=1)\\n    df[\"sum-c\"] = df[CELLS_].sum(axis=1)\\n    df[\"mean-c\"] = df[CELLS_].mean(axis=1)\\n    df[\"std-c\"] = df[CELLS_].std(axis=1)\\n    df[\"kurt-c\"] = df[CELLS_].kurt(axis=1)\\n    df[\"skew-c\"] = df[CELLS_].skew(axis=1)\\n    df[\"sum-gc\"] = df[BIOS_].sum(axis=1)\\n    df[\"mean-gc\"] = df[BIOS_].mean(axis=1)\\n    df[\"std-gc\"] = df[BIOS_].std(axis=1)\\n    df[\"kurt-gc\"] = df[BIOS_].kurt(axis=1)\\n    df[\"skew-gc\"] = df[BIOS_].skew(axis=1)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out fold preprocessing\n",
    "\n",
    "#variance threshold\n",
    "\n",
    "VAR_THRESHOLD = 0.8\n",
    "drop_cols = []\n",
    "temp = pd.concat([train_df, pub_test_df])\n",
    "for col in BIOS+PRODS:\n",
    "    if temp[col].var() <= VAR_THRESHOLD:\n",
    "        drop_cols.append(col)\n",
    "\n",
    "print(\"drop cols num : {}\".format(len(drop_cols)))\n",
    "train_df.drop(columns=drop_cols, inplace=True)\n",
    "test_df.drop(columns=drop_cols, inplace=True)\n",
    "pub_test_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "GENES_ = [col for col in train_df.columns if col.startswith(\"g-\")]\n",
    "CELLS_ = [col for col in train_df.columns if col.startswith(\"c-\")]\n",
    "BIOS_ = GENES_ + CELLS_\n",
    "        \n",
    "del temp\n",
    "\n",
    "# onehot encode of categorical feature and drop\n",
    "drop_cols = [\"cp_time\", \"cp_dose\", \"time_dose\"]\n",
    "train_df = pd.concat([pd.get_dummies(train_df[\"time_dose\"], prefix=\"onehot\", drop_first=True), train_df.drop(drop_cols, axis=1) ], axis=1)\n",
    "test_df = pd.concat([pd.get_dummies(test_df[\"time_dose\"], prefix=\"onehot\", drop_first=True), test_df.drop(drop_cols, axis=1) ], axis=1)\n",
    "pub_test_df = pd.concat([pd.get_dummies(pub_test_df[\"time_dose\"], prefix=\"onehot\", drop_first=True), pub_test_df.drop(drop_cols, axis=1) ], axis=1)\n",
    "\"\"\"\n",
    "# aggregation feature\n",
    "print(\"agg\")\n",
    "for df in [train_df, pub_test_df, test_df]:\n",
    "    df[\"sum-g\"] = df[GENES_].sum(axis=1)\n",
    "    df[\"mean-g\"] = df[GENES_].mean(axis=1)\n",
    "    df[\"std-g\"] = df[GENES_].std(axis=1)\n",
    "    df[\"kurt-g\"] = df[GENES_].kurt(axis=1)\n",
    "    df[\"skew-g\"] = df[GENES_].skew(axis=1)\n",
    "    df[\"sum-c\"] = df[CELLS_].sum(axis=1)\n",
    "    df[\"mean-c\"] = df[CELLS_].mean(axis=1)\n",
    "    df[\"std-c\"] = df[CELLS_].std(axis=1)\n",
    "    df[\"kurt-c\"] = df[CELLS_].kurt(axis=1)\n",
    "    df[\"skew-c\"] = df[CELLS_].skew(axis=1)\n",
    "    df[\"sum-gc\"] = df[BIOS_].sum(axis=1)\n",
    "    df[\"mean-gc\"] = df[BIOS_].mean(axis=1)\n",
    "    df[\"std-gc\"] = df[BIOS_].std(axis=1)\n",
    "    df[\"kurt-gc\"] = df[BIOS_].kurt(axis=1)\n",
    "    df[\"skew-gc\"] = df[BIOS_].skew(axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(\"sig_id\", axis=1)\n",
    "y_nonv = y_nonv.drop(\"sig_id\", axis=1).values\n",
    "y = y.drop(\"sig_id\", axis=1).values\n",
    "y_all_nonv = y_all_nonv.drop(\"sig_id\", axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dateset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoAResNetDataset:\n",
    "    def __init__(self, features1, features2, targets):\n",
    "        self.features1 = features1\n",
    "        self.features2 = features2\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features1.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x1' : torch.tensor(self.features1[idx, :], dtype=torch.float),\n",
    "            'x2' : torch.tensor(self.features2[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestResNetDataset:\n",
    "    def __init__(self, features1, features2):\n",
    "        self.features1 = features1\n",
    "        self.features2 = features2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features1.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x1' : torch.tensor(self.features1[idx, :], dtype=torch.float),\n",
    "            'x2' : torch.tensor(self.features2[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs1, inputs2, targets = data['x1'].to(device), data['x2'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs1, inputs2)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if cycle\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs1, inputs2, targets = data['x1'].to(device), data['x2'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs1, inputs2)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for data in dataloader:\n",
    "        inputs1, inputs2 = data['x1'].to(device), data['x2'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs1, inputs2)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features1, num_features2, num_targets):\n",
    "        super(Model, self).__init__()\n",
    "        self.h1_1 = 1500\n",
    "        self.h1_2 = 750\n",
    "        \n",
    "        self.h2_1 = num_features2+self.h1_2\n",
    "        self.h2_2 = 1500\n",
    "        self.h2_3 = 750\n",
    "        \n",
    "        self.h3_1 = 750\n",
    "        \n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features1),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features1, self.h1_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h1_1),\n",
    "            nn.Linear(self.h1_1, self.h1_2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.h2_1),\n",
    "            nn.Dropout(0.30),\n",
    "            nn.Linear(self.h2_1, self.h2_2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_2),\n",
    "            nn.Linear(self.h2_2, self.h2_2),\n",
    "            nn.ELU(),            \n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_2),\n",
    "            nn.Linear(self.h2_2, self.h2_3),\n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            nn.BatchNorm1d(self.h2_3),\n",
    "            nn.Linear(self.h2_3, self.h2_3),\n",
    "            nn.ELU(),            \n",
    "        )\n",
    "        self.head3 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Linear(self.h3_1, self.h3_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Linear(self.h3_1, self.h3_1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(self.h3_1),\n",
    "            nn.Linear(self.h3_1, num_targets),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        input3 = self.head1(input1)\n",
    "        concat = torch.cat((input3, input2), dim=1)\n",
    "        input4 = self.head2(concat)\n",
    "        avg = torch.add(input3, input4)\n",
    "        #avg = torch.div(torch.add(input3, input4), 2)\n",
    "        \n",
    "        out = self.head3(avg)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, trainloader, validloader, tag, epochs, optimizer, scheduler, fine_tune_scheduler, loss_fn, loss_tr, early_stopping_steps, verbose, device, fold, seed):\n",
    "    \n",
    "    early_step = 0\n",
    "    best_loss = np.inf\n",
    "    best_epoch = 0\n",
    "    weight_path = 'resnet_weights2/{}_{}_{}.pt'.format(tag, seed, fold)\n",
    "    \n",
    "    start = time.time()\n",
    "    t = time.time() - start\n",
    "    for epoch in range(epochs):\n",
    "        # fine tune \n",
    "        if fine_tune_scheduler is not None:\n",
    "            fine_tune_scheduler.step(epoch, model)\n",
    "            \n",
    "        train_loss = train_fn(model, optimizer, scheduler, loss_tr, trainloader, device)\n",
    "        valid_loss = valid_fn(model, loss_fn, validloader, device)\n",
    "\n",
    "        if epoch % verbose==0:\n",
    "            t = time.time() - start\n",
    "            print(f\"EPOCH: {epoch}, train_loss: {train_loss}, valid_loss: {valid_loss}, time: {t}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(),weight_path)\n",
    "            early_step = 0\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        elif early_stopping_steps != 0:\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                t = time.time() - start\n",
    "                print(f\"early stopping in iteration {epoch},  : best itaration is {best_epoch}, valid loss is {best_loss}, time: {t}\")\n",
    "                return model\n",
    "            \n",
    "    print(f\"training until max epoch {epochs},  : best itaration is {best_epoch}, valid loss is {best_loss}, time: {t}\")\n",
    "    return model\n",
    "            \n",
    "    \n",
    "def predict(model, testloader, device):\n",
    "    model.to(device)\n",
    "    predictions = inference_fn(model, testloader, device)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneScheduler:\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "        self.epochs_per_step = 0\n",
    "        self.frozen_layers = []\n",
    "        self.cnt=0\n",
    "\n",
    "    def copy_without_top(self, model, num_features, num_targets, num_targets_new):\n",
    "        model_new = Model(num_features, num_features, num_targets)\n",
    "        model_new.load_state_dict(model.state_dict())\n",
    "\n",
    "        # Freeze all weights\n",
    "        for name, param in model_new.named_parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        #self.epochs_per_step = self.epochs // len(self.frozen_layers)+1  # 24 // 4 = 6\n",
    "        #self.epochs_per_step = self.epochs // (len(self.frozen_layers)+1)  # 24 // 4 = 6\n",
    "        self.epochs_per_step = 4\n",
    "        \n",
    "        # Replace the top layers with another ones, 最後に追加されてく\n",
    "        model_new.head3[-2] == nn.BatchNorm1d(model.h3_1)\n",
    "        model_new.head3[-1] = nn.Linear(model.h3_1, 206)\n",
    "        model_new.to(DEVICE)\n",
    "        return model_new\n",
    "\n",
    "    def step(self, epoch, model):\n",
    "        if epoch == 0:\n",
    "            return\n",
    "\n",
    "        if epoch % self.epochs_per_step == 0:\n",
    "            self.cnt+=1\n",
    "            \n",
    "            if self.cnt == 1:\n",
    "                for name, param in model.head3.named_parameters():\n",
    "                    param.requires_grad = True\n",
    "                \n",
    "            elif self.cnt == 2:\n",
    "                for name, param in model.head2.named_parameters():\n",
    "                    l_num = int(name[0:2].replace('.', \"\"))\n",
    "                    if l_num in [7, 8, 10, 11]:\n",
    "                        param.requires_grad = True\n",
    "                for name, param in model.head1.named_parameters():\n",
    "                    l_num = int(name[0:2].replace('.', \"\"))\n",
    "                    if l_num in [4, 5]:\n",
    "                        param.requires_grad = True\n",
    "\n",
    "            elif self.cnt == 3:\n",
    "                for name, param in model.head2.named_parameters():\n",
    "                    l_num = int(name[0:2].replace('.', \"\"))\n",
    "                    if l_num in [0, 2, 4, 5]:\n",
    "                        param.requires_grad = True\n",
    "                for name, param in model.head1.named_parameters():\n",
    "                    l_num = int(name[0:2].replace('.', \"\"))\n",
    "                    if l_num in [0, 2]:\n",
    "                        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training by Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4340013805979296, valid_loss: 0.01069300046988896, time: 6.35381817817688\n",
      "EPOCH: 5, train_loss: 0.013122130698267963, valid_loss: 0.010098876005836895, time: 25.15514063835144\n",
      "EPOCH: 10, train_loss: 0.013083131639691799, valid_loss: 0.010149232617446354, time: 43.585336446762085\n",
      "EPOCH: 15, train_loss: 0.012732728195471176, valid_loss: 0.009554882267756122, time: 61.797035217285156\n",
      "EPOCH: 20, train_loss: 0.012245868548642899, valid_loss: 0.00935284129476973, time: 80.76892590522766\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009284629273627486, time: 80.76892590522766\n",
      "EPOCH: 0, train_loss: 0.24736583952292585, valid_loss: 0.026441891012447222, time: 2.1323156356811523\n",
      "EPOCH: 5, train_loss: 0.02009248544556507, valid_loss: 0.017633314510541304, time: 13.868730068206787\n",
      "EPOCH: 10, train_loss: 0.019658282561146694, valid_loss: 0.017586714667933327, time: 26.472619771957397\n",
      "EPOCH: 15, train_loss: 0.01924966051634671, valid_loss: 0.017627260913806304, time: 43.664047956466675\n",
      "EPOCH: 20, train_loss: 0.018158692272676937, valid_loss: 0.01766595393419266, time: 62.60150933265686\n",
      "early stopping in iteration 21,  : best itaration is 11, valid loss is 0.017494638290788445, time: 66.3122022151947\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4338674580178939, valid_loss: 0.010408574236290796, time: 3.323620319366455\n",
      "EPOCH: 5, train_loss: 0.01341949102293322, valid_loss: 0.010450691357254982, time: 22.255868434906006\n",
      "EPOCH: 10, train_loss: 0.013302169045082468, valid_loss: 0.009928150594766651, time: 41.032604932785034\n",
      "EPOCH: 15, train_loss: 0.012910113447224316, valid_loss: 0.00954504699579307, time: 59.94568610191345\n",
      "EPOCH: 20, train_loss: 0.012382149608616812, valid_loss: 0.009195539501628705, time: 78.63334441184998\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009115786318268095, time: 78.63334441184998\n",
      "EPOCH: 0, train_loss: 0.2480707171548536, valid_loss: 0.02613153878067221, time: 1.8291740417480469\n",
      "EPOCH: 5, train_loss: 0.020301320374119972, valid_loss: 0.017027603036590986, time: 13.12235140800476\n",
      "EPOCH: 10, train_loss: 0.019874388756959335, valid_loss: 0.016985877390418735, time: 26.43807029724121\n",
      "EPOCH: 15, train_loss: 0.01932260955589405, valid_loss: 0.01701324281415769, time: 43.95892786979675\n",
      "EPOCH: 20, train_loss: 0.018158604350426922, valid_loss: 0.016805135511926243, time: 63.09117078781128\n",
      "training until max epoch 24,  : best itaration is 19, valid loss is 0.01678150753889765, time: 63.09117078781128\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43540445036751074, valid_loss: 0.010686015550579344, time: 3.5830159187316895\n",
      "EPOCH: 5, train_loss: 0.0130294904072028, valid_loss: 0.010391123300152166, time: 22.593496084213257\n",
      "EPOCH: 10, train_loss: 0.013054913637248705, valid_loss: 0.01010637671819755, time: 41.51592254638672\n",
      "EPOCH: 15, train_loss: 0.012709109438923153, valid_loss: 0.009880490813936505, time: 58.86672592163086\n",
      "EPOCH: 20, train_loss: 0.012170553098629862, valid_loss: 0.009485715787325587, time: 78.46826529502869\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009423790739050933, time: 78.46826529502869\n",
      "EPOCH: 0, train_loss: 0.2508297326845409, valid_loss: 0.026200617317642484, time: 2.243669033050537\n",
      "EPOCH: 5, train_loss: 0.01999116907861546, valid_loss: 0.01755377442709037, time: 13.023722887039185\n",
      "EPOCH: 10, train_loss: 0.019689854261648917, valid_loss: 0.01740347681833165, time: 25.687746286392212\n",
      "EPOCH: 15, train_loss: 0.01920504959123413, valid_loss: 0.017331090569496155, time: 43.09062838554382\n",
      "EPOCH: 20, train_loss: 0.017983684316277504, valid_loss: 0.017288470960089137, time: 62.0018036365509\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.01721708338175501, time: 62.0018036365509\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43513780467239394, valid_loss: 0.010423366113432817, time: 3.7874691486358643\n",
      "EPOCH: 5, train_loss: 0.013107520976804034, valid_loss: 0.010033923999539443, time: 22.499730348587036\n",
      "EPOCH: 10, train_loss: 0.013120797591922927, valid_loss: 0.0099951852911285, time: 40.90809965133667\n",
      "EPOCH: 15, train_loss: 0.012725378067171486, valid_loss: 0.009613485714154584, time: 59.019983768463135\n",
      "EPOCH: 20, train_loss: 0.012223759339782444, valid_loss: 0.009363252935664994, time: 78.07752466201782\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009306226803788117, time: 78.07752466201782\n",
      "EPOCH: 0, train_loss: 0.2506528535218787, valid_loss: 0.026469981989690236, time: 2.198965549468994\n",
      "EPOCH: 5, train_loss: 0.01990375859513335, valid_loss: 0.017878610773810318, time: 13.467551946640015\n",
      "EPOCH: 10, train_loss: 0.01956687898912134, valid_loss: 0.01783687522900956, time: 26.626814603805542\n",
      "EPOCH: 15, train_loss: 0.01910054319313843, valid_loss: 0.01769921359206949, time: 44.46671009063721\n",
      "EPOCH: 20, train_loss: 0.01796801295131445, valid_loss: 0.017784546368888446, time: 62.639124631881714\n",
      "training until max epoch 24,  : best itaration is 15, valid loss is 0.01769921359206949, time: 62.639124631881714\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4346249527837811, valid_loss: 0.010390732245629324, time: 3.644440174102783\n",
      "EPOCH: 5, train_loss: 0.01326266780792587, valid_loss: 0.009822051889975281, time: 23.06568717956543\n",
      "EPOCH: 10, train_loss: 0.013195311265957096, valid_loss: 0.009821295272558928, time: 40.72548151016235\n",
      "EPOCH: 15, train_loss: 0.012839951403978943, valid_loss: 0.00939431698883281, time: 59.459394216537476\n",
      "EPOCH: 20, train_loss: 0.012272637310451355, valid_loss: 0.00912278619430521, time: 77.95152401924133\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009041858152212465, time: 77.95152401924133\n",
      "EPOCH: 0, train_loss: 0.24534478025051995, valid_loss: 0.02642053984762991, time: 2.0331828594207764\n",
      "EPOCH: 5, train_loss: 0.019835253205636273, valid_loss: 0.01763024734442725, time: 12.817454099655151\n",
      "EPOCH: 10, train_loss: 0.019456218374704105, valid_loss: 0.017691198352943447, time: 25.933680772781372\n",
      "EPOCH: 15, train_loss: 0.018794513213029808, valid_loss: 0.017602934063795733, time: 43.92044258117676\n",
      "early stopping in iteration 17,  : best itaration is 7, valid loss is 0.017514923779184326, time: 51.370929479599\n",
      "seed 7 , cv score : 0.017404947577861124\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4338642155913555, valid_loss: 0.010862415337136814, time: 3.6371119022369385\n",
      "EPOCH: 5, train_loss: 0.013213895956405264, valid_loss: 0.010360932403377125, time: 23.22347068786621\n",
      "EPOCH: 10, train_loss: 0.01295732760100045, valid_loss: 0.010239198324935778, time: 42.32318377494812\n",
      "EPOCH: 15, train_loss: 0.012657579027818165, valid_loss: 0.009905962326696941, time: 60.94507813453674\n",
      "EPOCH: 20, train_loss: 0.012068046587586834, valid_loss: 0.009479126573673316, time: 80.34218740463257\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009432431949036462, time: 80.34218740463257\n",
      "EPOCH: 0, train_loss: 0.24657076697094718, valid_loss: 0.02610851190984249, time: 2.2358717918395996\n",
      "EPOCH: 5, train_loss: 0.019600944175128487, valid_loss: 0.017309213828827653, time: 13.39425539970398\n",
      "EPOCH: 10, train_loss: 0.01909726634081723, valid_loss: 0.017545964914773192, time: 26.380779027938843\n",
      "EPOCH: 15, train_loss: 0.01858770651607842, valid_loss: 0.0173556137830019, time: 44.298295736312866\n",
      "early stopping in iteration 17,  : best itaration is 7, valid loss is 0.017275586059050902, time: 51.70881915092468\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43634615244384667, valid_loss: 0.010383621470204421, time: 3.6454410552978516\n",
      "EPOCH: 5, train_loss: 0.013192481096208531, valid_loss: 0.00999713646514075, time: 22.134697437286377\n",
      "EPOCH: 10, train_loss: 0.013190742622870599, valid_loss: 0.009790225007704326, time: 41.47556471824646\n",
      "EPOCH: 15, train_loss: 0.012814067956739969, valid_loss: 0.009459189644881657, time: 60.33492684364319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20, train_loss: 0.012301127752629074, valid_loss: 0.009160971308925321, time: 78.94689297676086\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009096625912934541, time: 78.94689297676086\n",
      "EPOCH: 0, train_loss: 0.24629050294739485, valid_loss: 0.02626347744039127, time: 2.1840856075286865\n",
      "EPOCH: 5, train_loss: 0.0201434152214414, valid_loss: 0.01768411985997643, time: 13.177754402160645\n",
      "EPOCH: 10, train_loss: 0.01980576465708496, valid_loss: 0.017634844141347066, time: 26.84462308883667\n",
      "EPOCH: 15, train_loss: 0.019403204145113918, valid_loss: 0.017425556374447686, time: 44.22876977920532\n",
      "EPOCH: 20, train_loss: 0.018346348063625992, valid_loss: 0.017433884127863817, time: 62.96764779090881\n",
      "training until max epoch 24,  : best itaration is 18, valid loss is 0.01741960399917194, time: 62.96764779090881\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43383523700353893, valid_loss: 0.01073170020518934, time: 3.695509433746338\n",
      "EPOCH: 5, train_loss: 0.013076806434200726, valid_loss: 0.010420494904632078, time: 22.35614585876465\n",
      "EPOCH: 10, train_loss: 0.013086210274933905, valid_loss: 0.010211237761027673, time: 41.38419246673584\n",
      "EPOCH: 15, train_loss: 0.012720434055866106, valid_loss: 0.009763061835923615, time: 60.16177177429199\n",
      "EPOCH: 20, train_loss: 0.012234799077977304, valid_loss: 0.009481429478482288, time: 78.51533555984497\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009437981335555805, time: 78.51533555984497\n",
      "EPOCH: 0, train_loss: 0.2501388411240085, valid_loss: 0.02658407872214037, time: 2.196065664291382\n",
      "EPOCH: 5, train_loss: 0.020101357359385143, valid_loss: 0.01811394314555561, time: 13.303731918334961\n",
      "EPOCH: 10, train_loss: 0.019743002708191456, valid_loss: 0.01784724692868836, time: 26.709062576293945\n",
      "EPOCH: 15, train_loss: 0.019270696528795837, valid_loss: 0.01783977046280223, time: 44.508819580078125\n",
      "EPOCH: 20, train_loss: 0.01809186938529213, valid_loss: 0.017812879153472537, time: 62.624327421188354\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.017764802994754386, time: 62.624327421188354\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4353329952522788, valid_loss: 0.010407033083694322, time: 3.6951212882995605\n",
      "EPOCH: 5, train_loss: 0.013720105219956326, valid_loss: 0.010390427043395383, time: 22.74656844139099\n",
      "EPOCH: 10, train_loss: 0.013142925660139408, valid_loss: 0.01002084245639188, time: 41.99058485031128\n",
      "EPOCH: 15, train_loss: 0.012671479206208302, valid_loss: 0.009470770228654146, time: 60.345712423324585\n",
      "EPOCH: 20, train_loss: 0.012076435725380114, valid_loss: 0.009144240604447467, time: 79.93959665298462\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009080566186457872, time: 79.93959665298462\n",
      "EPOCH: 0, train_loss: 0.25127074193965265, valid_loss: 0.02539782454924924, time: 2.104057788848877\n",
      "EPOCH: 5, train_loss: 0.01940750225406626, valid_loss: 0.017598953151277134, time: 13.254714012145996\n",
      "EPOCH: 10, train_loss: 0.018961554217705692, valid_loss: 0.017728075997105668, time: 26.614485502243042\n",
      "EPOCH: 15, train_loss: 0.01838355134848667, valid_loss: 0.017611978016793726, time: 44.47607207298279\n",
      "early stopping in iteration 16,  : best itaration is 6, valid loss is 0.017537547993872846, time: 48.25314259529114\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43466271276491275, valid_loss: 0.010553421106721673, time: 3.502842664718628\n",
      "EPOCH: 5, train_loss: 0.013184382782682129, valid_loss: 0.009992979733007295, time: 22.1485378742218\n",
      "EPOCH: 10, train_loss: 0.013163331538384808, valid_loss: 0.009968580092702593, time: 41.64239978790283\n",
      "EPOCH: 15, train_loss: 0.012795506375909283, valid_loss: 0.009541822145027773, time: 60.70220947265625\n",
      "EPOCH: 20, train_loss: 0.012275981615580942, valid_loss: 0.009261804473187243, time: 79.78458857536316\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009190715370433672, time: 79.78458857536316\n",
      "EPOCH: 0, train_loss: 0.24436124001184237, valid_loss: 0.026078770522560392, time: 2.2427966594696045\n",
      "EPOCH: 5, train_loss: 0.02016900105914776, valid_loss: 0.017521797439881734, time: 13.895125150680542\n",
      "EPOCH: 10, train_loss: 0.019873866554943546, valid_loss: 0.017354210891893932, time: 27.689945220947266\n",
      "EPOCH: 15, train_loss: 0.019416866999497448, valid_loss: 0.017253079797540392, time: 45.58621859550476\n",
      "EPOCH: 20, train_loss: 0.018301804630976658, valid_loss: 0.01727882048913411, time: 64.35676312446594\n",
      "training until max epoch 24,  : best itaration is 16, valid loss is 0.01724276053053992, time: 64.35676312446594\n",
      "seed 8 , cv score : 0.017486841787367324\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43731334988354115, valid_loss: 0.010420729911753109, time: 3.5183463096618652\n",
      "EPOCH: 5, train_loss: 0.0131290979737783, valid_loss: 0.009911329219383853, time: 22.445237398147583\n",
      "EPOCH: 10, train_loss: 0.01312386602108931, valid_loss: 0.009899068224642957, time: 41.28234934806824\n",
      "EPOCH: 15, train_loss: 0.012776327856483251, valid_loss: 0.009634385550660747, time: 59.97148561477661\n",
      "EPOCH: 20, train_loss: 0.012262958897291308, valid_loss: 0.009295751606779439, time: 78.78113961219788\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009262688750667231, time: 78.78113961219788\n",
      "EPOCH: 0, train_loss: 0.24745720710578192, valid_loss: 0.0261518303837095, time: 1.9778575897216797\n",
      "EPOCH: 5, train_loss: 0.020132544552431488, valid_loss: 0.017286789550312927, time: 13.746966361999512\n",
      "EPOCH: 10, train_loss: 0.01984080502314724, valid_loss: 0.017296485123889788, time: 27.0575110912323\n",
      "EPOCH: 15, train_loss: 0.01939680368850266, valid_loss: 0.017201875895261766, time: 44.64506411552429\n",
      "EPOCH: 20, train_loss: 0.018223947743429756, valid_loss: 0.01728229754205261, time: 63.66515803337097\n",
      "training until max epoch 24,  : best itaration is 15, valid loss is 0.017201875895261766, time: 63.66515803337097\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43530744131303567, valid_loss: 0.01013728283236132, time: 3.612337350845337\n",
      "EPOCH: 5, train_loss: 0.013243555320777756, valid_loss: 0.009858748848166536, time: 22.354952096939087\n",
      "EPOCH: 10, train_loss: 0.013213126285784487, valid_loss: 0.009704182992744096, time: 41.33198571205139\n",
      "EPOCH: 15, train_loss: 0.01288916053844319, valid_loss: 0.00917727782336228, time: 60.046263217926025\n",
      "EPOCH: 20, train_loss: 0.012372911880737629, valid_loss: 0.00889249496600207, time: 79.51154112815857\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.008834258680615355, time: 79.51154112815857\n",
      "EPOCH: 0, train_loss: 0.24582832837072405, valid_loss: 0.02610690469908364, time: 2.155418872833252\n",
      "EPOCH: 5, train_loss: 0.020217320949271107, valid_loss: 0.01725475928362678, time: 13.182839632034302\n",
      "EPOCH: 10, train_loss: 0.01986965781374686, valid_loss: 0.017306202556937933, time: 26.64531707763672\n",
      "EPOCH: 15, train_loss: 0.019449061187713043, valid_loss: 0.017183702274718705, time: 44.74474859237671\n",
      "EPOCH: 20, train_loss: 0.01823616691230648, valid_loss: 0.017254454439834636, time: 63.65684676170349\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.01716856620110133, time: 63.65684676170349\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4342293159874237, valid_loss: 0.010755744124097483, time: 3.686676263809204\n",
      "EPOCH: 5, train_loss: 0.013158894258726767, valid_loss: 0.011869765631854535, time: 23.188353538513184\n",
      "EPOCH: 10, train_loss: 0.013140862132760061, valid_loss: 0.010172026338321823, time: 42.006797790527344\n",
      "EPOCH: 15, train_loss: 0.012785285724785881, valid_loss: 0.009777366103870528, time: 60.7708625793457\n",
      "EPOCH: 20, train_loss: 0.012287860020887161, valid_loss: 0.009398129555795874, time: 80.08920383453369\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.00933829660394362, time: 80.08920383453369\n",
      "EPOCH: 0, train_loss: 0.2523266660940388, valid_loss: 0.026506302771823746, time: 2.1743323802948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5, train_loss: 0.020191427536200787, valid_loss: 0.01769583033663886, time: 13.104014873504639\n",
      "EPOCH: 10, train_loss: 0.019877927020138155, valid_loss: 0.017509432536150726, time: 26.966150522232056\n",
      "EPOCH: 15, train_loss: 0.019390680543754413, valid_loss: 0.017259053273924758, time: 45.55992293357849\n",
      "EPOCH: 20, train_loss: 0.018346232928983543, valid_loss: 0.017001296087567296, time: 64.56409406661987\n",
      "training until max epoch 24,  : best itaration is 21, valid loss is 0.016988489484148366, time: 64.56409406661987\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43534644128904293, valid_loss: 0.010540581095431533, time: 3.4921422004699707\n",
      "EPOCH: 5, train_loss: 0.013088061331506194, valid_loss: 0.010682850810033935, time: 21.832183837890625\n",
      "EPOCH: 10, train_loss: 0.013061343746626899, valid_loss: 0.010152138317269938, time: 39.12446689605713\n",
      "EPOCH: 15, train_loss: 0.01270381441462214, valid_loss: 0.009728668736560003, time: 58.44748663902283\n",
      "EPOCH: 20, train_loss: 0.012178563254538678, valid_loss: 0.00940460344510419, time: 77.65563106536865\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.00934726226010493, time: 77.65563106536865\n",
      "EPOCH: 0, train_loss: 0.24459967979767028, valid_loss: 0.026380275722060885, time: 2.108628273010254\n",
      "EPOCH: 5, train_loss: 0.019912059534422672, valid_loss: 0.0178985741521631, time: 13.733593940734863\n",
      "EPOCH: 10, train_loss: 0.019569221081851173, valid_loss: 0.017783505309905325, time: 27.96887993812561\n",
      "EPOCH: 15, train_loss: 0.019197511629466594, valid_loss: 0.017714745444910866, time: 45.72025156021118\n",
      "EPOCH: 20, train_loss: 0.017972262256717594, valid_loss: 0.017745970987847873, time: 64.05319929122925\n",
      "training until max epoch 24,  : best itaration is 18, valid loss is 0.017635403467076167, time: 64.05319929122925\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4343648669714837, valid_loss: 0.010898676381579467, time: 3.753418445587158\n",
      "EPOCH: 5, train_loss: 0.013090081418446009, valid_loss: 0.010533924613680159, time: 22.353269338607788\n",
      "EPOCH: 10, train_loss: 0.013020572745227728, valid_loss: 0.010337680658059461, time: 41.40735197067261\n",
      "EPOCH: 15, train_loss: 0.01267741546979633, valid_loss: 0.01003655463989292, time: 60.80556035041809\n",
      "EPOCH: 20, train_loss: 0.01213718459442042, valid_loss: 0.009649572441620485, time: 79.67655825614929\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009571992526096957, time: 79.67655825614929\n",
      "EPOCH: 0, train_loss: 0.2437815061783877, valid_loss: 0.02662768177688122, time: 2.0269219875335693\n",
      "EPOCH: 5, train_loss: 0.019927175067689106, valid_loss: 0.01808120294341019, time: 12.949098587036133\n",
      "EPOCH: 10, train_loss: 0.019520135758363682, valid_loss: 0.01794346600238766, time: 27.111025094985962\n",
      "EPOCH: 15, train_loss: 0.019054088970997196, valid_loss: 0.01788096989371947, time: 45.09069347381592\n",
      "EPOCH: 20, train_loss: 0.017881400032859783, valid_loss: 0.017903125073228564, time: 63.91322207450867\n",
      "training until max epoch 24,  : best itaration is 18, valid loss is 0.017851536854037217, time: 63.91322207450867\n",
      "seed 9 , cv score : 0.01743834849163971\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43377969085333357, valid_loss: 0.010401949020368713, time: 3.7547385692596436\n",
      "EPOCH: 5, train_loss: 0.01333138313603358, valid_loss: 0.011039685058806623, time: 21.94994330406189\n",
      "EPOCH: 10, train_loss: 0.013252548212050528, valid_loss: 0.010236021849725928, time: 40.93238282203674\n",
      "EPOCH: 15, train_loss: 0.013018823053309883, valid_loss: 0.009333169486905848, time: 59.66153860092163\n",
      "EPOCH: 20, train_loss: 0.012404093525601902, valid_loss: 0.009173336598489965, time: 78.31892967224121\n",
      "training until max epoch 24,  : best itaration is 21, valid loss is 0.009082926596914018, time: 78.31892967224121\n",
      "EPOCH: 0, train_loss: 0.25077784518994717, valid_loss: 0.026499367345656666, time: 2.2147490978240967\n",
      "EPOCH: 5, train_loss: 0.02038074327983718, valid_loss: 0.017859448652182308, time: 13.267391443252563\n",
      "EPOCH: 10, train_loss: 0.02014948627439098, valid_loss: 0.017521059992057938, time: 26.74550771713257\n",
      "EPOCH: 15, train_loss: 0.019602643528386303, valid_loss: 0.017301512961941105, time: 44.83471727371216\n",
      "EPOCH: 20, train_loss: 0.018639220248745834, valid_loss: 0.017256225219794682, time: 63.23652768135071\n",
      "training until max epoch 24,  : best itaration is 16, valid loss is 0.017162455166024822, time: 63.23652768135071\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4350686976753607, valid_loss: 0.010505676322749683, time: 3.565545082092285\n",
      "EPOCH: 5, train_loss: 0.013258018335192532, valid_loss: 0.010301468281873635, time: 22.31490731239319\n",
      "EPOCH: 10, train_loss: 0.013099667987367813, valid_loss: 0.010054595422531877, time: 41.398462772369385\n",
      "EPOCH: 15, train_loss: 0.012723507778044197, valid_loss: 0.00976604228573186, time: 60.17779183387756\n",
      "EPOCH: 20, train_loss: 0.01217802771218661, valid_loss: 0.00943886861205101, time: 78.95533084869385\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009374885473932539, time: 78.95533084869385\n",
      "EPOCH: 0, train_loss: 0.24526369463706363, valid_loss: 0.026083891998444284, time: 2.225458860397339\n",
      "EPOCH: 5, train_loss: 0.019952388183362244, valid_loss: 0.01736219684992518, time: 13.512653589248657\n",
      "EPOCH: 10, train_loss: 0.01960513997229113, valid_loss: 0.017348970765514032, time: 26.819199085235596\n",
      "EPOCH: 15, train_loss: 0.019054006319493055, valid_loss: 0.017336973574544702, time: 44.469335317611694\n",
      "EPOCH: 20, train_loss: 0.01765600907062923, valid_loss: 0.01742242598640067, time: 63.28832530975342\n",
      "training until max epoch 24,  : best itaration is 14, valid loss is 0.017223803353096756, time: 63.28832530975342\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4352286379294891, valid_loss: 0.010315236449241639, time: 3.4972546100616455\n",
      "EPOCH: 5, train_loss: 0.013156776826312073, valid_loss: 0.009747441139604364, time: 22.935024738311768\n",
      "EPOCH: 10, train_loss: 0.013143272703363948, valid_loss: 0.009620591173214572, time: 41.30621886253357\n",
      "EPOCH: 15, train_loss: 0.012785797401664465, valid_loss: 0.009545582293399742, time: 59.956666469573975\n",
      "EPOCH: 20, train_loss: 0.012268448826333466, valid_loss: 0.009145831316709518, time: 79.0387749671936\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009098198530929429, time: 79.0387749671936\n",
      "EPOCH: 0, train_loss: 0.2477266770264093, valid_loss: 0.026346326672605107, time: 2.2568576335906982\n",
      "EPOCH: 5, train_loss: 0.01998492036640209, valid_loss: 0.01774316970258951, time: 13.663118839263916\n",
      "EPOCH: 10, train_loss: 0.0196466573588822, valid_loss: 0.01777270936540195, time: 26.996424674987793\n",
      "EPOCH: 15, train_loss: 0.019229067693444065, valid_loss: 0.017582472573433604, time: 44.47707200050354\n",
      "EPOCH: 20, train_loss: 0.018171832849183223, valid_loss: 0.017544300800987653, time: 63.29057788848877\n",
      "training until max epoch 24,  : best itaration is 18, valid loss is 0.017511621144201073, time: 63.29057788848877\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4341200610919707, valid_loss: 0.010576742514967919, time: 3.763106346130371\n",
      "EPOCH: 5, train_loss: 0.013317109119363022, valid_loss: 0.010345444695225784, time: 23.257772207260132\n",
      "EPOCH: 10, train_loss: 0.013214580147810604, valid_loss: 0.010028176195919513, time: 41.871837854385376\n",
      "EPOCH: 15, train_loss: 0.012860242837527092, valid_loss: 0.00978592179183449, time: 60.77346324920654\n",
      "EPOCH: 20, train_loss: 0.012342634077683308, valid_loss: 0.009335141043577876, time: 79.92980790138245\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009254777750798634, time: 79.92980790138245\n",
      "EPOCH: 0, train_loss: 0.24823987262620442, valid_loss: 0.0262267782752003, time: 2.10036039352417\n",
      "EPOCH: 5, train_loss: 0.02016874466199374, valid_loss: 0.017516279167362623, time: 13.28846549987793\n",
      "EPOCH: 10, train_loss: 0.019641237630360367, valid_loss: 0.01733187772333622, time: 26.617416858673096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15, train_loss: 0.01894451940999083, valid_loss: 0.01739955392799207, time: 44.95643591880798\n",
      "EPOCH: 20, train_loss: 0.017536941679545504, valid_loss: 0.01728220387761082, time: 63.14128518104553\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.017218319566122124, time: 63.14128518104553\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43437114170334046, valid_loss: 0.010941381406571185, time: 3.765695571899414\n",
      "EPOCH: 5, train_loss: 0.013023793947059607, valid_loss: 0.010724165556686266, time: 22.956011056900024\n",
      "EPOCH: 10, train_loss: 0.013008975376631472, valid_loss: 0.010287851999912943, time: 40.97979164123535\n",
      "EPOCH: 15, train_loss: 0.012659749556062878, valid_loss: 0.009841969369777612, time: 60.20433187484741\n",
      "EPOCH: 20, train_loss: 0.01218324058783659, valid_loss: 0.009573350234755447, time: 79.53020191192627\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009548833593726158, time: 79.53020191192627\n",
      "EPOCH: 0, train_loss: 0.24607961838120135, valid_loss: 0.026598247566393445, time: 2.0995609760284424\n",
      "EPOCH: 5, train_loss: 0.019989835678775242, valid_loss: 0.01810709669121674, time: 12.725417375564575\n",
      "EPOCH: 10, train_loss: 0.01961325601661119, valid_loss: 0.017956780163305146, time: 26.62730383872986\n",
      "EPOCH: 15, train_loss: 0.019281257443345974, valid_loss: 0.017900172541184086, time: 44.42097568511963\n",
      "EPOCH: 20, train_loss: 0.018336289359823517, valid_loss: 0.01786896676889488, time: 63.006386280059814\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.01781149080821446, time: 63.006386280059814\n",
      "seed 10 , cv score : 0.017402442186455626\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4354875766379881, valid_loss: 0.010257090042744364, time: 3.68949031829834\n",
      "EPOCH: 5, train_loss: 0.013504047769318968, valid_loss: 0.009930841252207756, time: 22.639389276504517\n",
      "EPOCH: 10, train_loss: 0.013041149525746813, valid_loss: 0.009567518053310258, time: 41.22767472267151\n",
      "EPOCH: 15, train_loss: 0.012560169205722147, valid_loss: 0.009201390243002346, time: 60.44475865364075\n",
      "EPOCH: 20, train_loss: 0.011879215554001123, valid_loss: 0.008921311236917973, time: 79.31273031234741\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.008875992228942258, time: 79.31273031234741\n",
      "EPOCH: 0, train_loss: 0.2453405880607175, valid_loss: 0.02504242467028754, time: 1.9342930316925049\n",
      "EPOCH: 5, train_loss: 0.018833664239105517, valid_loss: 0.017238052748143672, time: 12.948214292526245\n",
      "EPOCH: 10, train_loss: 0.018245579185385774, valid_loss: 0.017287286637084825, time: 26.69327211380005\n",
      "early stopping in iteration 14,  : best itaration is 4, valid loss is 0.01717385442129203, time: 40.70065879821777\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4358039730887887, valid_loss: 0.010601246809320791, time: 3.7537903785705566\n",
      "EPOCH: 5, train_loss: 0.01433242224564735, valid_loss: 0.010518262375678334, time: 22.439160346984863\n",
      "EPOCH: 10, train_loss: 0.012989902481382345, valid_loss: 0.00992262243692364, time: 41.72461771965027\n",
      "EPOCH: 15, train_loss: 0.012509624820447316, valid_loss: 0.00966160978589739, time: 60.38745975494385\n",
      "EPOCH: 20, train_loss: 0.011825315661075777, valid_loss: 0.009313048927911691, time: 79.53550624847412\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.00928857536720378, time: 79.53550624847412\n",
      "EPOCH: 0, train_loss: 0.24078054504509824, valid_loss: 0.025061572928513798, time: 2.333310842514038\n",
      "EPOCH: 5, train_loss: 0.01869254152759583, valid_loss: 0.018007859906979968, time: 13.29367971420288\n",
      "EPOCH: 10, train_loss: 0.018259823981699716, valid_loss: 0.01818893418780395, time: 26.58363175392151\n",
      "EPOCH: 15, train_loss: 0.01767868936116243, valid_loss: 0.018175311971987997, time: 44.33887028694153\n",
      "early stopping in iteration 18,  : best itaration is 8, valid loss is 0.017981783646558013, time: 55.49139332771301\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43381997253205895, valid_loss: 0.010974267031997442, time: 3.6202392578125\n",
      "EPOCH: 5, train_loss: 0.013209372853347357, valid_loss: 0.010525233386194004, time: 23.00956392288208\n",
      "EPOCH: 10, train_loss: 0.013035201724024786, valid_loss: 0.01020036029684193, time: 42.241445779800415\n",
      "EPOCH: 15, train_loss: 0.012688264163022024, valid_loss: 0.009913876077488941, time: 60.63582801818848\n",
      "EPOCH: 20, train_loss: 0.01217775729795297, valid_loss: 0.009506097939961097, time: 79.68231153488159\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.00943913050543736, time: 79.68231153488159\n",
      "EPOCH: 0, train_loss: 0.24622200584659973, valid_loss: 0.026576367754708317, time: 1.9893324375152588\n",
      "EPOCH: 5, train_loss: 0.01999993691139895, valid_loss: 0.017637912266175535, time: 13.543224811553955\n",
      "EPOCH: 10, train_loss: 0.01961376538257236, valid_loss: 0.0178611944155658, time: 27.34520936012268\n",
      "EPOCH: 15, train_loss: 0.01902268030613229, valid_loss: 0.0174760467318051, time: 44.84673810005188\n",
      "EPOCH: 20, train_loss: 0.01741058081118525, valid_loss: 0.017705803682260653, time: 63.54995918273926\n",
      "training until max epoch 24,  : best itaration is 15, valid loss is 0.0174760467318051, time: 63.54995918273926\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4342379924247338, valid_loss: 0.010806044749915599, time: 3.568931818008423\n",
      "EPOCH: 5, train_loss: 0.013118293952952692, valid_loss: 0.010199259327990668, time: 22.326879024505615\n",
      "EPOCH: 10, train_loss: 0.013145181856563559, valid_loss: 0.010234372690320015, time: 40.870980739593506\n",
      "EPOCH: 15, train_loss: 0.012710379382622415, valid_loss: 0.00973979216068983, time: 59.12888693809509\n",
      "EPOCH: 20, train_loss: 0.01222463151898937, valid_loss: 0.009465507710618631, time: 78.43280339241028\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009404877386987209, time: 78.43280339241028\n",
      "EPOCH: 0, train_loss: 0.24949314233347558, valid_loss: 0.026284651032515934, time: 2.1367015838623047\n",
      "EPOCH: 5, train_loss: 0.020203221629819145, valid_loss: 0.017422256618738176, time: 13.073445796966553\n",
      "EPOCH: 10, train_loss: 0.01980061839888061, valid_loss: 0.017279968703431743, time: 26.217026233673096\n",
      "EPOCH: 15, train_loss: 0.019378444328364254, valid_loss: 0.01718313949448722, time: 44.02102065086365\n",
      "EPOCH: 20, train_loss: 0.01830507071175869, valid_loss: 0.01725807919033936, time: 63.13059878349304\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.017157206391649586, time: 63.13059878349304\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4342978410557776, valid_loss: 0.010545648288513933, time: 3.895765542984009\n",
      "EPOCH: 5, train_loss: 0.013195839751025906, valid_loss: 0.009866504530821527, time: 23.093314170837402\n",
      "EPOCH: 10, train_loss: 0.013200262676168611, valid_loss: 0.00976593957415649, time: 41.55486822128296\n",
      "EPOCH: 15, train_loss: 0.012760119910851337, valid_loss: 0.009415384967412267, time: 60.3993558883667\n",
      "EPOCH: 20, train_loss: 0.012227435096882391, valid_loss: 0.009117755160800049, time: 79.7988600730896\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009035408523465906, time: 79.7988600730896\n",
      "EPOCH: 0, train_loss: 0.2534357248063105, valid_loss: 0.02633146084845066, time: 2.0833117961883545\n",
      "EPOCH: 5, train_loss: 0.020039553295119084, valid_loss: 0.017508176235216003, time: 12.966962575912476\n",
      "EPOCH: 10, train_loss: 0.019638153170977814, valid_loss: 0.01751687178122146, time: 26.44231343269348\n",
      "EPOCH: 15, train_loss: 0.019269153151823128, valid_loss: 0.01744077711233071, time: 44.70305347442627\n",
      "EPOCH: 20, train_loss: 0.018040209536211216, valid_loss: 0.017483866906591823, time: 63.407796144485474\n",
      "training until max epoch 24,  : best itaration is 16, valid loss is 0.01738264478210892, time: 63.407796144485474\n",
      "seed 110 , cv score : 0.01747834245140425\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43448491945214895, valid_loss: 0.010436888597905637, time: 3.7942702770233154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5, train_loss: 0.013098471993715435, valid_loss: 0.01016149896063975, time: 22.65220332145691\n",
      "EPOCH: 10, train_loss: 0.013108203720733307, valid_loss: 0.010071503131517343, time: 41.31143546104431\n",
      "EPOCH: 15, train_loss: 0.012778731893100168, valid_loss: 0.009718786472720758, time: 60.26016092300415\n",
      "EPOCH: 20, train_loss: 0.012220086178917816, valid_loss: 0.00931091901979276, time: 79.62376952171326\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009231965469994715, time: 79.62376952171326\n",
      "EPOCH: 0, train_loss: 0.2532251123608886, valid_loss: 0.02619465733213084, time: 2.043818473815918\n",
      "EPOCH: 5, train_loss: 0.02000932898912309, valid_loss: 0.01752994850810085, time: 13.634782314300537\n",
      "EPOCH: 10, train_loss: 0.019669862356090893, valid_loss: 0.017473053533051695, time: 27.354305028915405\n",
      "EPOCH: 15, train_loss: 0.019188451445728973, valid_loss: 0.017406568569796426, time: 45.962541341781616\n",
      "EPOCH: 20, train_loss: 0.01811024713991345, valid_loss: 0.017408124836427823, time: 64.3038637638092\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.017322572826274803, time: 64.3038637638092\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4344117173223176, valid_loss: 0.010708598047494888, time: 4.297706127166748\n",
      "EPOCH: 5, train_loss: 0.013102272005778725, valid_loss: 0.0107081515448434, time: 23.03021001815796\n",
      "EPOCH: 10, train_loss: 0.013095015322492607, valid_loss: 0.01041700267898185, time: 41.389694929122925\n",
      "EPOCH: 15, train_loss: 0.012726594343025616, valid_loss: 0.00992164776793548, time: 60.48033595085144\n",
      "EPOCH: 20, train_loss: 0.01219079329672715, valid_loss: 0.009645379334688186, time: 79.25250720977783\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009571400311376368, time: 79.25250720977783\n",
      "EPOCH: 0, train_loss: 0.24909204416030992, valid_loss: 0.026543834752270155, time: 2.3152647018432617\n",
      "EPOCH: 5, train_loss: 0.020054501386872238, valid_loss: 0.018017863003270965, time: 13.619042873382568\n",
      "EPOCH: 10, train_loss: 0.019713738069370174, valid_loss: 0.018021990438657147, time: 27.398627519607544\n",
      "EPOCH: 15, train_loss: 0.01925078356989484, valid_loss: 0.01776927337050438, time: 45.53905391693115\n",
      "EPOCH: 20, train_loss: 0.01816923792163531, valid_loss: 0.01788320956485612, time: 63.837751150131226\n",
      "training until max epoch 24,  : best itaration is 15, valid loss is 0.01776927337050438, time: 63.837751150131226\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4350674296256857, valid_loss: 0.010708640569022723, time: 3.6215503215789795\n",
      "EPOCH: 5, train_loss: 0.013071017063128344, valid_loss: 0.010495338189814771, time: 22.06648564338684\n",
      "EPOCH: 10, train_loss: 0.012965309447136478, valid_loss: 0.010151770604508264, time: 40.66313457489014\n",
      "EPOCH: 15, train_loss: 0.012638925041571476, valid_loss: 0.009749095674071994, time: 59.6320219039917\n",
      "EPOCH: 20, train_loss: 0.012111212849023117, valid_loss: 0.009520462288388183, time: 78.23688411712646\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009432697216314928, time: 78.23688411712646\n",
      "EPOCH: 0, train_loss: 0.24610423725908218, valid_loss: 0.026470997131296567, time: 2.3392109870910645\n",
      "EPOCH: 5, train_loss: 0.019740243631320587, valid_loss: 0.01749658105628831, time: 13.414690256118774\n",
      "EPOCH: 10, train_loss: 0.019360409050747967, valid_loss: 0.017365088367036412, time: 27.039501190185547\n",
      "EPOCH: 15, train_loss: 0.018784262489635443, valid_loss: 0.017236898014588015, time: 44.335896253585815\n",
      "EPOCH: 20, train_loss: 0.017050464003198387, valid_loss: 0.01733117907174996, time: 63.19633078575134\n",
      "training until max epoch 24,  : best itaration is 15, valid loss is 0.017236898014588015, time: 63.19633078575134\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4357429061723995, valid_loss: 0.010116832117949214, time: 3.3284759521484375\n",
      "EPOCH: 5, train_loss: 0.013157433245575776, valid_loss: 0.009899408183991909, time: 21.693129301071167\n",
      "EPOCH: 10, train_loss: 0.013155681291853424, valid_loss: 0.009636181486504419, time: 40.563260555267334\n",
      "EPOCH: 15, train_loss: 0.012786740335180376, valid_loss: 0.009385200536676816, time: 59.04106140136719\n",
      "EPOCH: 20, train_loss: 0.012259293170849773, valid_loss: 0.009058256686798164, time: 77.71818995475769\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.008995847989405904, time: 77.71818995475769\n",
      "EPOCH: 0, train_loss: 0.25058142354127266, valid_loss: 0.026333239035946983, time: 2.187241315841675\n",
      "EPOCH: 5, train_loss: 0.019985247131464254, valid_loss: 0.017512356995471885, time: 14.250179052352905\n",
      "EPOCH: 10, train_loss: 0.019590196587199713, valid_loss: 0.01742908571447645, time: 27.75344944000244\n",
      "EPOCH: 15, train_loss: 0.019129568683731293, valid_loss: 0.01732926789138998, time: 45.76302146911621\n",
      "EPOCH: 20, train_loss: 0.017947028323083463, valid_loss: 0.017344611537243638, time: 64.33089327812195\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.017222741405878747, time: 64.33089327812195\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4349444578671693, valid_loss: 0.009998649545013904, time: 3.5948331356048584\n",
      "EPOCH: 5, train_loss: 0.013203215495129858, valid_loss: 0.009806175370301519, time: 23.03015661239624\n",
      "EPOCH: 10, train_loss: 0.013181614109139511, valid_loss: 0.009566352795809507, time: 41.859633684158325\n",
      "EPOCH: 15, train_loss: 0.012831198078566704, valid_loss: 0.009159940561013562, time: 60.58467173576355\n",
      "EPOCH: 20, train_loss: 0.012265274591366018, valid_loss: 0.008897466851132256, time: 79.68552851676941\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.008873067862753357, time: 79.68552851676941\n",
      "EPOCH: 0, train_loss: 0.24779554963975714, valid_loss: 0.02628567224102361, time: 2.155580759048462\n",
      "EPOCH: 5, train_loss: 0.01997707020221413, valid_loss: 0.017395368138594287, time: 12.78758192062378\n",
      "EPOCH: 10, train_loss: 0.019594560687740643, valid_loss: 0.01725379784724542, time: 25.948004484176636\n",
      "EPOCH: 15, train_loss: 0.01917618374083785, valid_loss: 0.017221637628972532, time: 43.915475606918335\n",
      "EPOCH: 20, train_loss: 0.018029548268279304, valid_loss: 0.01722264462815864, time: 62.648749113082886\n",
      "training until max epoch 24,  : best itaration is 18, valid loss is 0.017210373575133938, time: 62.648749113082886\n",
      "seed 12 , cv score : 0.01739685755242758\n",
      "======================== fold 1 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4351644425963362, valid_loss: 0.010664633847773075, time: 3.6075568199157715\n",
      "EPOCH: 5, train_loss: 0.013095070385252651, valid_loss: 0.010377240127750806, time: 23.05922770500183\n",
      "EPOCH: 10, train_loss: 0.013123861136103886, valid_loss: 0.010241004319063255, time: 41.84765028953552\n",
      "EPOCH: 15, train_loss: 0.012749596694619328, valid_loss: 0.00998158236699445, time: 60.52110743522644\n",
      "EPOCH: 20, train_loss: 0.012249432470433521, valid_loss: 0.009570558395768916, time: 80.25718283653259\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009516460608158793, time: 80.25718283653259\n",
      "EPOCH: 0, train_loss: 0.24340144669016203, valid_loss: 0.026312113500067166, time: 2.141695022583008\n",
      "EPOCH: 5, train_loss: 0.020164142889173134, valid_loss: 0.01766009357358728, time: 13.2415132522583\n",
      "EPOCH: 10, train_loss: 0.019786565551075382, valid_loss: 0.017668693353022846, time: 26.374272346496582\n",
      "EPOCH: 15, train_loss: 0.01931105685028909, valid_loss: 0.017634040649448124, time: 44.78835940361023\n",
      "EPOCH: 20, train_loss: 0.01817652096539952, valid_loss: 0.01755890944706542, time: 63.26841950416565\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.0175436956807971, time: 63.26841950416565\n",
      "======================== fold 2 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.4355267565899893, valid_loss: 0.010361389257013798, time: 3.733818769454956\n",
      "EPOCH: 5, train_loss: 0.01322569797301422, valid_loss: 0.00991987793103737, time: 22.401238918304443\n",
      "EPOCH: 10, train_loss: 0.013216234466897837, valid_loss: 0.009728787329924457, time: 40.73145818710327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15, train_loss: 0.012804606335534565, valid_loss: 0.009477746563360971, time: 59.99393391609192\n",
      "EPOCH: 20, train_loss: 0.012296723228865776, valid_loss: 0.00911999324007946, time: 79.3207905292511\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.009062352645046571, time: 79.3207905292511\n",
      "EPOCH: 0, train_loss: 0.24389820436582618, valid_loss: 0.025776458191959298, time: 2.02762508392334\n",
      "EPOCH: 5, train_loss: 0.020280963970699173, valid_loss: 0.017105550998274016, time: 13.356502056121826\n",
      "EPOCH: 10, train_loss: 0.0199093631050293, valid_loss: 0.016913929132415968, time: 27.01883101463318\n",
      "EPOCH: 15, train_loss: 0.019512814847563488, valid_loss: 0.0168936052633559, time: 44.735431432724\n",
      "EPOCH: 20, train_loss: 0.01840503532709419, valid_loss: 0.016777705291614813, time: 63.56040978431702\n",
      "training until max epoch 24,  : best itaration is 19, valid loss is 0.01676813217208666, time: 63.56040978431702\n",
      "======================== fold 3 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43637850842554204, valid_loss: 0.010496929926531656, time: 3.4578182697296143\n",
      "EPOCH: 5, train_loss: 0.013141968450678962, valid_loss: 0.010308880039623805, time: 22.515714168548584\n",
      "EPOCH: 10, train_loss: 0.013118726031406082, valid_loss: 0.009913468360900879, time: 41.21081471443176\n",
      "EPOCH: 15, train_loss: 0.012777860222017243, valid_loss: 0.009659596027008124, time: 60.58687162399292\n",
      "EPOCH: 20, train_loss: 0.012278243362305373, valid_loss: 0.009263549292726176, time: 79.37007665634155\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009210625237652233, time: 79.37007665634155\n",
      "EPOCH: 0, train_loss: 0.24540726824180922, valid_loss: 0.026336352899670602, time: 1.9705140590667725\n",
      "EPOCH: 5, train_loss: 0.020093728414308416, valid_loss: 0.01765681430697441, time: 12.829681873321533\n",
      "EPOCH: 10, train_loss: 0.019773850258249435, valid_loss: 0.017567859377179827, time: 26.81636667251587\n",
      "EPOCH: 15, train_loss: 0.019315526120527816, valid_loss: 0.017506491179977143, time: 45.2375910282135\n",
      "EPOCH: 20, train_loss: 0.018215441614063115, valid_loss: 0.017544990511877197, time: 63.4396390914917\n",
      "training until max epoch 24,  : best itaration is 14, valid loss is 0.017480241028325898, time: 63.4396390914917\n",
      "======================== fold 4 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43453673249029595, valid_loss: 0.010569561166422707, time: 3.7972517013549805\n",
      "EPOCH: 5, train_loss: 0.013075201589938091, valid_loss: 0.010087701678276061, time: 22.231373071670532\n",
      "EPOCH: 10, train_loss: 0.01307801041158213, valid_loss: 0.010110629323337759, time: 41.074140787124634\n",
      "EPOCH: 15, train_loss: 0.012712141330205444, valid_loss: 0.009690809808671475, time: 59.95861577987671\n",
      "EPOCH: 20, train_loss: 0.01220125449227466, valid_loss: 0.009386481397918292, time: 79.0977246761322\n",
      "training until max epoch 24,  : best itaration is 23, valid loss is 0.009294399140136583, time: 79.0977246761322\n",
      "EPOCH: 0, train_loss: 0.2512368355081349, valid_loss: 0.02656172870525292, time: 2.1824111938476562\n",
      "EPOCH: 5, train_loss: 0.01994214432341033, valid_loss: 0.018088937258081778, time: 13.952867269515991\n",
      "EPOCH: 10, train_loss: 0.019524855093787544, valid_loss: 0.01807727837668998, time: 27.9351646900177\n",
      "EPOCH: 15, train_loss: 0.01919574711633765, valid_loss: 0.017825193383863996, time: 46.36560368537903\n",
      "EPOCH: 20, train_loss: 0.018023586757751047, valid_loss: 0.01792336484151227, time: 64.67745733261108\n",
      "training until max epoch 24,  : best itaration is 14, valid loss is 0.017785822147769588, time: 64.67745733261108\n",
      "======================== fold 5 ========================\n",
      "quantile\n",
      "PCA\n",
      "900\n",
      "900\n",
      "EPOCH: 0, train_loss: 0.43514706067958453, valid_loss: 0.010523449975465025, time: 3.5452916622161865\n",
      "EPOCH: 5, train_loss: 0.013125969783613717, valid_loss: 0.010303220472165517, time: 22.08898091316223\n",
      "EPOCH: 10, train_loss: 0.013118444826372349, valid_loss: 0.010050179596458162, time: 41.05829906463623\n",
      "EPOCH: 15, train_loss: 0.012754364986054218, valid_loss: 0.009557623309748513, time: 59.46105241775513\n",
      "EPOCH: 20, train_loss: 0.012247484592027473, valid_loss: 0.009290543145367078, time: 78.04210186004639\n",
      "training until max epoch 24,  : best itaration is 22, valid loss is 0.00925105945872409, time: 78.04210186004639\n",
      "EPOCH: 0, train_loss: 0.24808997974941766, valid_loss: 0.02638883755675384, time: 2.0775537490844727\n",
      "EPOCH: 5, train_loss: 0.020038221357730184, valid_loss: 0.017645607409732682, time: 13.262982368469238\n",
      "EPOCH: 10, train_loss: 0.019706461864122508, valid_loss: 0.017696778369801384, time: 26.937806844711304\n",
      "EPOCH: 15, train_loss: 0.019192302422801944, valid_loss: 0.017597974331251213, time: 44.169947147369385\n",
      "EPOCH: 20, train_loss: 0.01812645771887398, valid_loss: 0.017617254544581684, time: 62.81778645515442\n",
      "training until max epoch 24,  : best itaration is 17, valid loss is 0.01745423169008323, time: 62.81778645515442\n",
      "seed 13 , cv score : 0.017440878087656063\n",
      "cv score : 0.01703195597230051\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "DEVICE = ('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 24\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "\n",
    "train_preds = np.zeros((X.shape[0], y_nonv.shape[1]))\n",
    "preds = np.zeros((test_df.shape[0], y_nonv.shape[1]))\n",
    "imps = []\n",
    "imp_cols = []\n",
    "folds = []\n",
    "test_cv_preds = []\n",
    "\n",
    "for seed in seeds:\n",
    "    seed_everything(seed)\n",
    "    K = 5\n",
    "    kf = MultilabelStratifiedKFold(n_splits=K, random_state=seed, shuffle=True)\n",
    "    train_pred = np.zeros(train_preds.shape)\n",
    "    \n",
    "    \n",
    "    ###############################################################################################\n",
    "    # LOAD LIBRARIES\n",
    "    targets = SCORED_MOAS.copy()\n",
    "\n",
    "    # LOCATE DRUGS\n",
    "    vc = scored[\"drug_id\"].value_counts()\n",
    "    vc1 = vc.loc[vc<=18].index.sort_values()\n",
    "    vc2 = vc.loc[vc>18].index.sort_values()\n",
    "\n",
    "    # STRATIFY DRUGS 18X OR LESS\n",
    "    dct1 = {}; dct2 = {}\n",
    "    skf = MultilabelStratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "    tmp = scored.groupby('drug_id')[targets].mean().loc[vc1]\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.index[idxV].values} # drug id がどのフォールドに属すか格納\n",
    "        dct1.update(dd)\n",
    "\n",
    "    # STRATIFY DRUGS MORE THAN 18X\n",
    "    skf = MultilabelStratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "    tmp = scored.loc[scored[\"drug_id\"].isin(vc2)].reset_index(drop=True)\n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp[\"sig_id\"][idxV].values}\n",
    "        dct2.update(dd)\n",
    "\n",
    "    # ASSIGN K\n",
    "    scored['fold'] = scored.drug_id.map(dct1)\n",
    "    scored.loc[scored[\"fold\"].isna(),'fold'] = scored.loc[scored[\"fold\"].isna(),'sig_id'].map(dct2)\n",
    "    scored[\"fold\"] = scored[\"fold\"].astype('int8')\n",
    "    ###############################################################################################\n",
    "\n",
    "    #for fold, (train_index, valid_index) in enumerate(kf.split(X, y_nonv)):    \n",
    "    for fold in range(K):\n",
    "        train_index = scored[scored[\"fold\"] != fold].index.to_list()\n",
    "        valid_index = scored[scored[\"fold\"] == fold].index.to_list()\n",
    "        print(\"======================== fold {} ========================\".format(fold+1))\n",
    "        folds.append(train_index)\n",
    "                \n",
    "        # split data\n",
    "        train_X = X.iloc[train_index]\n",
    "        train_y = y_nonv[train_index]\n",
    "        train_y_all = y_all_nonv[train_index]\n",
    "        valid_X = X.iloc[valid_index]\n",
    "        valid_y = y_nonv[valid_index]\n",
    "        valid_y_all = y_all_nonv[valid_index]\n",
    "        test_X = (test_df.drop(\"sig_id\", axis=1))\n",
    "        pub_test_X = (pub_test_df.drop(\"sig_id\", axis=1))\n",
    "\n",
    "        \n",
    "        ### scaler ##########\n",
    "        # validの分布を知らせてはいけない\n",
    "        print(SCALE)\n",
    "        scale_cols = BIOS_+PRODS\n",
    "        scaler = make_scaler(SCALE, seed).fit(train_X.append(pub_test_X)[scale_cols])\n",
    "        for df in [train_X, valid_X, test_X, pub_test_X]:\n",
    "            df[scale_cols] = scaler.transform(df[scale_cols])\n",
    "\n",
    "    \n",
    "        ### PCA ##########\n",
    "        # validの分布を知らせてはいけない\n",
    "        print(\"PCA\")\n",
    "        n_decom_g = 80 # 80\n",
    "        n_decom_c = 10 # 10\n",
    "        decom_g_cols = [f\"pca_g-{i}\" for i in range(n_decom_g)]\n",
    "        decom_c_cols = [f\"pca_c-{i}\" for i in range(n_decom_c)]\n",
    "        \n",
    "        pca_g = PCA(n_components = n_decom_g, random_state = seed).fit(train_X.append(pub_test_X)[GENES_])\n",
    "        pca_c = PCA(n_components = n_decom_c, random_state = seed).fit(train_X.append(pub_test_X)[CELLS_])\n",
    "        for df in [train_X, valid_X, test_X, pub_test_X]:\n",
    "            df[decom_g_cols] = pca_g.transform(df[GENES_])\n",
    "            df[decom_c_cols] = pca_c.transform(df[CELLS_])\n",
    "\n",
    "\n",
    "        # prepare data for training\n",
    "        train_X1 = train_X.values\n",
    "        train_X2 = train_X.values\n",
    "        valid_X1 = valid_X.values\n",
    "        valid_X2 = valid_X.values\n",
    "        test_X1 = test_X.values\n",
    "        test_X2 = test_X.values\n",
    "        print(train_X1.shape[1])\n",
    "        print(train_X2.shape[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ================================model training===========================\n",
    "        train_dataset = MoAResNetDataset(train_X1, train_X2, train_y_all)\n",
    "        valid_dataset = MoAResNetDataset(valid_X1, valid_X2, valid_y_all)\n",
    "        test_dataset = TestResNetDataset(test_X1, test_X2)\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "        model = Model(\n",
    "            num_features1=train_X1.shape[1],\n",
    "            num_features2=train_X2.shape[1],\n",
    "            num_targets=train_y_all.shape[1],\n",
    "        )\n",
    "\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        optimizer = torch.optim.Adam( model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY,)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,pct_start=0.1, div_factor=1e3, max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader) )\n",
    "        fine_tune_scheduler = FineTuneScheduler(EPOCHS)\n",
    "    \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss_tr = SmoothBCEwLogits(smoothing=1e-3)\n",
    "        \n",
    "        # train\n",
    "        model = run_training(\n",
    "            model=model,\n",
    "            trainloader=trainloader,\n",
    "            validloader=validloader,\n",
    "            tag=\"ALL\",\n",
    "            epochs=EPOCHS,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            fine_tune_scheduler=None,\n",
    "            loss_fn=loss_fn,\n",
    "            loss_tr=loss_tr,\n",
    "            early_stopping_steps=EARLY_STOPPING_STEPS,\n",
    "            device=DEVICE,\n",
    "            verbose=5,\n",
    "            fold=fold,\n",
    "            seed=seed,)\n",
    "        model.load_state_dict(torch.load('resnet_weights2/ALL_{}_{}.pt'.format(seed, fold)))\n",
    "        \n",
    "        model = fine_tune_scheduler.copy_without_top(model, train_X.shape[1], train_y_all.shape[1], train_y.shape[1])\n",
    "        \n",
    "        # train\n",
    "        optimizer = torch.optim.Adam( model.parameters(), lr=LEARNING_RATE, weight_decay=3e-6, eps=1e-6)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,pct_start=0.1, div_factor=1e2, max_lr=3e-3, epochs=EPOCHS, steps_per_epoch=len(trainloader) )\n",
    "        train_dataset = MoAResNetDataset(train_X1, train_X2, train_y)\n",
    "        valid_dataset = MoAResNetDataset(valid_X1, valid_X2, valid_y)\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        \n",
    "        model = run_training(\n",
    "            model=model,\n",
    "            trainloader=trainloader,\n",
    "            validloader=validloader,\n",
    "            tag=\"SCORED\",\n",
    "            epochs=EPOCHS,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            fine_tune_scheduler=fine_tune_scheduler,\n",
    "            loss_fn=loss_fn,\n",
    "            loss_tr=loss_tr,\n",
    "            early_stopping_steps=EARLY_STOPPING_STEPS,\n",
    "            device=DEVICE,\n",
    "            verbose=5,\n",
    "            fold=fold,\n",
    "            seed=seed,)\n",
    "        \n",
    "        model.load_state_dict(torch.load('resnet_weights2/SCORED_{}_{}.pt'.format(seed, fold)))\n",
    "        #valid predict\n",
    "        val_preds = predict(\n",
    "            model=model,\n",
    "            testloader=validloader,\n",
    "            device=DEVICE,)\n",
    "        \n",
    "        #test predict\n",
    "        test_preds = predict(\n",
    "            model=model,\n",
    "            testloader=testloader,\n",
    "            device=DEVICE)\n",
    "        \n",
    "        # ================================model training===========================\n",
    "\n",
    "        train_pred[valid_index] +=  val_preds\n",
    "        preds += test_preds / (K*len(seeds))\n",
    "\n",
    "\n",
    "    print(\"seed {} , cv score : {}\".format(seed, metric(y_nonv, train_pred)))\n",
    "    train_preds += train_pred/len(seeds)\n",
    "\n",
    "print(\"cv score : {}\".format(metric(y_nonv, train_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score : 0.015697378419419396\n"
     ]
    }
   ],
   "source": [
    "train_preds2 = np.zeros((TR_SIZE,  y.shape[1]))\n",
    "train_preds2[train_nonvehicle_index] = train_preds\n",
    "\n",
    "\n",
    "preds2 = np.zeros((TE_SIZE, y.shape[1]))\n",
    "preds2[test_nonvehicle_index] = preds\n",
    "\n",
    "print(\"cv score : {}\".format(metric(y, train_preds2)))\n",
    "#cv score : 0.015684400394041592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../../../Data/Raw/sample_submission.csv\")\n",
    "#sub_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n",
    "cols = [col for col in sub_df.columns if col != \"sig_id\"]\n",
    "sub_df[cols] = preds2\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip resnet_weights2.zip resnet_weights2/SCORED*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
