{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, random\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "#from Functions import prepro\n",
    "from Models.DNN import DNN_model\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "%matplotlib inline\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    res = []\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        y = y_true[:,i]\n",
    "        pred = y_pred[:,i]\n",
    "        res.append(log_loss(y, pred))\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 207)\n",
      "(23814, 402)\n",
      "(23814, 608)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../Data/Raw/train_features.csv\")\n",
    "#train_df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"../Data/Raw/test_features.csv\")\n",
    "#test_df = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "\n",
    "y = pd.read_csv(\"../Data/Raw/train_targets_scored.csv\")\n",
    "#y = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "tag_size = y.shape[1]-1\n",
    "print(y.shape)\n",
    "\n",
    "y_non = pd.read_csv(\"../Data/Raw/train_targets_nonscored.csv\").drop(\"sig_id\", axis=1)\n",
    "print(y_non.shape)\n",
    "#y = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "\n",
    "y = pd.concat([y, y_non], axis=1)\n",
    "y = y.drop(\"sig_id\", axis=1).values\n",
    "print(y.shape)\n",
    "\n",
    "# g772, c100, 206クラス、402クラスの分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"cp_type\"] = train_df[\"cp_type\"].map(lambda x : 1 if x == \"trt_cp\" else 0)\n",
    "test_df[\"cp_type\"] = test_df[\"cp_type\"].map(lambda x : 1 if x == \"trt_cp\" else 0)\n",
    "\n",
    "di = {\n",
    "    24 : 0, \n",
    "    48 : 1,\n",
    "    72 : 2,\n",
    "}\n",
    "train_df[\"cp_time\"] = train_df[\"cp_time\"].map(lambda x : di[x])\n",
    "test_df[\"cp_time\"] = test_df[\"cp_time\"].map(lambda x : di[x])\n",
    "\n",
    "train_df[\"cp_dose\"] = train_df[\"cp_dose\"].map(lambda x : 1 if x == \"D1\" else 0)\n",
    "test_df[\"cp_dose\"] = test_df[\"cp_dose\"].map(lambda x : 1 if x == \"D1\" else 0)\n",
    "\n",
    "cols = [col for col in train_df.columns if \"g-\" in col or \"c-\" in col]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([train_df[cols], test_df[cols]]))\n",
    "train_df[cols] = scaler.transform(train_df[cols])\n",
    "test_df[cols] = scaler.transform(test_df[cols])\n",
    "\n",
    "X = train_df.drop(\"sig_id\", axis=1)\n",
    "test_X = test_df.drop(\"sig_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/ML/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=6385 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== fold 1 ========================\n",
      "(15876, 875)\n",
      "(15876, 608)\n",
      "Train on 15876 samples, validate on 7938 samples\n",
      "Epoch 1/10\n",
      "15876/15876 [==============================] - 5s 296us/sample - loss: 0.3063 - val_loss: 0.0324\n",
      "Epoch 2/10\n",
      "15876/15876 [==============================] - 2s 114us/sample - loss: 0.0205 - val_loss: 0.0145\n",
      "Epoch 3/10\n",
      "15876/15876 [==============================] - 2s 108us/sample - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 4/10\n",
      "15876/15876 [==============================] - 2s 104us/sample - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 5/10\n",
      "15876/15876 [==============================] - 2s 123us/sample - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "15876/15876 [==============================] - 2s 113us/sample - loss: 0.0117 - val_loss: 0.0098\n",
      "======================== fold 2 ========================\n",
      "(15876, 875)\n",
      "(15876, 608)\n",
      "Train on 15876 samples, validate on 7938 samples\n",
      "Epoch 1/10\n",
      "15876/15876 [==============================] - 4s 272us/sample - loss: 0.3082 - val_loss: 0.0346\n",
      "Epoch 2/10\n",
      "15876/15876 [==============================] - 2s 109us/sample - loss: 0.0206 - val_loss: 0.0147\n",
      "Epoch 3/10\n",
      "15876/15876 [==============================] - 2s 98us/sample - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 4/10\n",
      "15876/15876 [==============================] - 1s 92us/sample - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 5/10\n",
      "15876/15876 [==============================] - 2s 109us/sample - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "15876/15876 [==============================] - 2s 98us/sample - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "15876/15876 [==============================] - 2s 107us/sample - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "15876/15876 [==============================] - 2s 100us/sample - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "15876/15876 [==============================] - 2s 107us/sample - loss: 0.0082 - val_loss: 0.0090\n",
      "======================== fold 3 ========================\n",
      "(15876, 875)\n",
      "(15876, 608)\n",
      "Train on 15876 samples, validate on 7938 samples\n",
      "Epoch 1/10\n",
      "15876/15876 [==============================] - 4s 273us/sample - loss: 0.3073 - val_loss: 0.0323\n",
      "Epoch 2/10\n",
      "15876/15876 [==============================] - 2s 122us/sample - loss: 0.0205 - val_loss: 0.0143\n",
      "Epoch 3/10\n",
      "15876/15876 [==============================] - 2s 107us/sample - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 4/10\n",
      "15876/15876 [==============================] - 2s 113us/sample - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "15876/15876 [==============================] - 2s 106us/sample - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "15876/15876 [==============================] - 2s 102us/sample - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "15876/15876 [==============================] - 2s 104us/sample - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "15876/15876 [==============================] - 2s 102us/sample - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 9/10\n",
      "15876/15876 [==============================] - 2s 101us/sample - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 10/10\n",
      "15876/15876 [==============================] - 2s 101us/sample - loss: 0.0084 - val_loss: 0.0084\n",
      "cv score : 0.017647989626354943\n"
     ]
    }
   ],
   "source": [
    "random.seed(random.randint(0, 10000))\n",
    "K = 3\n",
    "#kf = KFold(n_splits=K, random_state=random.randint(0, 10000))\n",
    "kf = MultilabelStratifiedKFold(n_splits=K, random_state=random.randint(0, 10000), shuffle=True)\n",
    "\n",
    "\n",
    "models = []\n",
    "train_pred = []\n",
    "folds = []\n",
    "\n",
    "for itr, (train_index, valid_index) in enumerate(kf.split(X, y)):\n",
    "    print(\"======================== fold {} ========================\".format(itr+1))\n",
    "    folds.append(valid_index)\n",
    "    train_X = X.iloc[train_index].values\n",
    "    train_y = y[train_index]\n",
    "    valid_X = X.iloc[valid_index].values\n",
    "    valid_y = y[valid_index]\n",
    "    print(train_X.shape)\n",
    "    print(train_y.shape)\n",
    "\n",
    "    \n",
    "    model = DNN_model(input_size=train_X.shape[1], output_size=train_y.shape[1])\n",
    "    cb = EarlyStopping(monitor='val_loss', patience=1)\n",
    "    model.fit(\n",
    "        train_X, \n",
    "        train_y,\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=[cb],\n",
    "        validation_data=(valid_X, valid_y),\n",
    "    )\n",
    "\n",
    "    \n",
    "    pred = model.predict(valid_X)\n",
    "    train_pred.append(pred)\n",
    "    models.append(model)\n",
    "    \n",
    "    \n",
    "\n",
    "train_preds = np.empty(y.shape)\n",
    "for i, fold in enumerate(folds):\n",
    "    train_preds[fold] = train_pred[i]\n",
    "\n",
    "print(\"cv score : {}\".format(metric(y[:,:tag_size], train_preds[:,:tag_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i in range(K):\n",
    "    model = models[i]\n",
    "    pred = model.predict(test_X.values, batch_size=128)\n",
    "    preds.append(pred)\n",
    "    \n",
    "preds = np.array(preds)\n",
    "preds = np.mean(preds, axis=0)[:,:tag_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_df = pd.read_csv(\"../Data/Raw/sample_submission.csv\")\n",
    "sub_df = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n",
    "cols = [col for col in sub_df.columns if col != \"sig_id\"]\n",
    "sub_df[cols] = preds\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
